{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6c384b",
   "metadata": {},
   "source": [
    "## Test new parserr changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # EnergyPlus Selective Parsing Test\n",
    "# This notebook tests the new selective parsing functionality\n",
    "\n",
    "# %% Import required modules\n",
    "# %% Import required modules\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "import traceback\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Union, List, Dict, Optional, Any, Tuple, Set  # Add typing imports\n",
    "\n",
    "\n",
    "# Add the project directory to Python path\n",
    "project_dir = r\"D:\\Documents\\daily\\E_Plus_2040_py\"\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "# Import the parsing modules\n",
    "from parserr.energyplus_analyzer_main import EnergyPlusAnalyzer\n",
    "from parserr.helpers import prepare_selective_file_pairs, get_parsed_data_info\n",
    "\n",
    "# %% Set up paths\n",
    "job_id = \"cd66cc37-c691-4635-83a0-686a3716c8d5\"\n",
    "job_output_dir = os.path.join(project_dir, \"output\", job_id)\n",
    "idf_dir = os.path.join(job_output_dir, \"output_IDFs\")\n",
    "sql_dir = os.path.join(job_output_dir, \"Sim_Results\")\n",
    "\n",
    "print(f\"Job output directory: {job_output_dir}\")\n",
    "print(f\"IDF directory exists: {os.path.exists(idf_dir)}\")\n",
    "print(f\"SQL directory exists: {os.path.exists(sql_dir)}\")\n",
    "\n",
    "# %% List available files\n",
    "print(\"\\nAvailable IDF files:\")\n",
    "if os.path.exists(idf_dir):\n",
    "    idf_files = [f for f in os.listdir(idf_dir) if f.endswith('.idf')]\n",
    "    for f in idf_files[:5]:  # Show first 5\n",
    "        print(f\"  - {f}\")\n",
    "    if len(idf_files) > 5:\n",
    "        print(f\"  ... and {len(idf_files) - 5} more\")\n",
    "\n",
    "print(\"\\nAvailable SQL files:\")\n",
    "if os.path.exists(sql_dir):\n",
    "    for root, dirs, files in os.walk(sql_dir):\n",
    "        sql_files = [f for f in files if f.endswith('.sql')]\n",
    "        if sql_files:\n",
    "            print(f\"  In {os.path.relpath(root, sql_dir)}:\")\n",
    "            for f in sql_files[:5]:\n",
    "                print(f\"    - {f}\")\n",
    "\n",
    "# %% Test 1: Parse everything (simplest config)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 1: Parse Everything\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config_all = {\n",
    "    \"perform_parsing\": True,\n",
    "    \"parse_mode\": \"all\"\n",
    "}\n",
    "\n",
    "# Create analyzer\n",
    "analyzer = EnergyPlusAnalyzer(os.path.join(job_output_dir, \"parsed_data_test1\"))\n",
    "\n",
    "# Prepare file pairs\n",
    "file_pairs = prepare_selective_file_pairs(\n",
    "    job_output_dir=job_output_dir,\n",
    "    parse_mode=\"all\",\n",
    "    parse_types={\"idf\": True, \"sql\": True},\n",
    "    building_selection={},\n",
    "    idf_map_csv=os.path.join(job_output_dir, \"extracted_idf_buildings.csv\")\n",
    ")\n",
    "\n",
    "print(f\"Found {len(file_pairs)} file pairs\")\n",
    "\n",
    "# Uncomment to run (this will parse everything)\n",
    "# analyzer.analyze_project_selective(file_pairs)\n",
    "\n",
    "# %% Test 2: Parse single building\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 2: Parse Single Building\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get first building ID from available files\n",
    "if idf_files:\n",
    "    first_idf = idf_files[0]\n",
    "    # Extract building ID from filename\n",
    "    import re\n",
    "    match = re.search(r'building_(\\d+)', first_idf)\n",
    "    if match:\n",
    "        building_id = int(match.group(1))\n",
    "        print(f\"Parsing building ID: {building_id}\")\n",
    "        \n",
    "        config_single = {\n",
    "            \"parse_mode\": \"selective\",\n",
    "            \"building_selection\": {\n",
    "                \"mode\": \"specific\",\n",
    "                \"building_ids\": [building_id]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        analyzer2 = EnergyPlusAnalyzer(os.path.join(job_output_dir, \"parsed_data_test2\"))\n",
    "        \n",
    "        file_pairs = prepare_selective_file_pairs(\n",
    "            job_output_dir=job_output_dir,\n",
    "            parse_mode=\"selective\",\n",
    "            parse_types={\"idf\": True, \"sql\": True},\n",
    "            building_selection=config_single[\"building_selection\"],\n",
    "            idf_map_csv=os.path.join(job_output_dir, \"extracted_idf_buildings.csv\")\n",
    "        )\n",
    "        \n",
    "        print(f\"Found {len(file_pairs)} file pairs for building {building_id}\")\n",
    "        \n",
    "        # Uncomment to run\n",
    "        # analyzer2.analyze_project_selective(file_pairs)\n",
    "\n",
    "# %% Test 3: Parse only geometry\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 3: Parse Only Geometry\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config_geometry = {\n",
    "    \"idf_content\": {\n",
    "        \"mode\": \"categories_only\",\n",
    "        \"categories\": [\"geometry\"]\n",
    "    },\n",
    "    \"sql_content\": {\n",
    "        \"mode\": \"selective\",\n",
    "        \"variables\": {\n",
    "            \"mode\": \"categories\",\n",
    "            \"categories\": [\"geometry\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "analyzer3 = EnergyPlusAnalyzer(os.path.join(job_output_dir, \"parsed_data_test3\"))\n",
    "\n",
    "file_pairs = prepare_selective_file_pairs(\n",
    "    job_output_dir=job_output_dir,\n",
    "    parse_mode=\"all\",\n",
    "    parse_types={\"idf\": True, \"sql\": True},\n",
    "    building_selection={},\n",
    "    idf_map_csv=os.path.join(job_output_dir, \"extracted_idf_buildings.csv\")\n",
    ")\n",
    "\n",
    "print(f\"Will parse geometry data from {len(file_pairs)} file pairs\")\n",
    "\n",
    "# Uncomment to run\n",
    "# analyzer3.analyze_project_selective(\n",
    "#     file_pairs,\n",
    "#     idf_content_config=config_geometry[\"idf_content\"],\n",
    "#     sql_content_config=config_geometry[\"sql_content\"]\n",
    "# )\n",
    "\n",
    "# %% Test 4: Parse specific files directly\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 4: Parse Specific Files\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select first 2 IDF files and first SQL file\n",
    "specific_idf_files = []\n",
    "specific_sql_files = []\n",
    "\n",
    "if idf_files:\n",
    "    for f in idf_files[:2]:\n",
    "        specific_idf_files.append(os.path.join(idf_dir, f))\n",
    "\n",
    "# Find SQL files\n",
    "sql_files_found = []\n",
    "for root, dirs, files in os.walk(sql_dir):\n",
    "    for f in files:\n",
    "        if f.endswith('.sql'):\n",
    "            sql_files_found.append(os.path.join(root, f))\n",
    "            if len(sql_files_found) >= 1:\n",
    "                break\n",
    "\n",
    "specific_sql_files = sql_files_found[:1]\n",
    "\n",
    "print(f\"Specific IDF files: {[os.path.basename(f) for f in specific_idf_files]}\")\n",
    "print(f\"Specific SQL files: {[os.path.basename(f) for f in specific_sql_files]}\")\n",
    "\n",
    "config_specific = {\n",
    "    \"parse_mode\": \"specific_files\",\n",
    "    \"building_selection\": {\n",
    "        \"specific_files\": {\n",
    "            \"idf\": specific_idf_files,\n",
    "            \"sql\": specific_sql_files\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "analyzer4 = EnergyPlusAnalyzer(os.path.join(job_output_dir, \"parsed_data_test4\"))\n",
    "\n",
    "file_pairs = prepare_selective_file_pairs(\n",
    "    job_output_dir=job_output_dir,\n",
    "    parse_mode=\"specific_files\",\n",
    "    parse_types={\"idf\": True, \"sql\": True},\n",
    "    building_selection=config_specific[\"building_selection\"]\n",
    ")\n",
    "\n",
    "print(f\"Found {len(file_pairs)} file pairs from specific files\")\n",
    "\n",
    "# Uncomment to run\n",
    "# analyzer4.analyze_project_selective(file_pairs)\n",
    "\n",
    "# %% Test 5: Parse only energy variables\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 5: Parse Only Energy Variables\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config_energy = {\n",
    "    \"parse_types\": {\n",
    "        \"idf\": False,  # Skip IDF parsing\n",
    "        \"sql\": True\n",
    "    },\n",
    "    \"sql_content\": {\n",
    "        \"mode\": \"selective\",\n",
    "        \"variables\": {\n",
    "            \"mode\": \"pattern\",\n",
    "            \"variable_patterns\": [\"*Energy*\", \"*Power*\"]\n",
    "        },\n",
    "        \"frequency_filter\": [\"Hourly\", \"Daily\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "analyzer5 = EnergyPlusAnalyzer(os.path.join(job_output_dir, \"parsed_data_test5\"))\n",
    "\n",
    "file_pairs = prepare_selective_file_pairs(\n",
    "    job_output_dir=job_output_dir,\n",
    "    parse_mode=\"all\",\n",
    "    parse_types=config_energy[\"parse_types\"],\n",
    "    building_selection={},\n",
    "    idf_map_csv=os.path.join(job_output_dir, \"extracted_idf_buildings.csv\")\n",
    ")\n",
    "\n",
    "print(f\"Will parse energy variables from {len(file_pairs)} SQL files\")\n",
    "\n",
    "# Uncomment to run\n",
    "# analyzer5.analyze_project_selective(\n",
    "#     file_pairs,\n",
    "#     sql_content_config=config_energy[\"sql_content\"]\n",
    "# )\n",
    "\n",
    "# %% Test 6: Full example with all options\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 6: Full Configuration Example\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "full_config = {\n",
    "    \"parsing\": {\n",
    "        \"perform_parsing\": True,\n",
    "        \"parse_mode\": \"selective\",\n",
    "        \"parse_types\": {\n",
    "            \"idf\": True,\n",
    "            \"sql\": True\n",
    "        },\n",
    "        \"building_selection\": {\n",
    "            \"mode\": \"range\",\n",
    "            \"building_range\": {\"start\": 0, \"end\": 3}\n",
    "        },\n",
    "        \"idf_content\": {\n",
    "            \"mode\": \"selective\",\n",
    "            \"categories\": [\"geometry\", \"hvac\", \"lighting\"],\n",
    "            \"exclude_objects\": [\"SCHEDULE:COMPACT\"]\n",
    "        },\n",
    "        \"sql_content\": {\n",
    "            \"mode\": \"selective\",\n",
    "            \"variables\": {\n",
    "                \"mode\": \"categories\",\n",
    "                \"categories\": [\"energy\", \"comfort\"]\n",
    "            },\n",
    "            \"time_filter\": {\n",
    "                \"months\": [1, 7]  # January and July only\n",
    "            },\n",
    "            \"frequency_filter\": [\"Daily\"],\n",
    "            \"components\": {\n",
    "                \"timeseries\": True,\n",
    "                \"schedules\": False,\n",
    "                \"summary_metrics\": True\n",
    "            }\n",
    "        },\n",
    "        \"output_options\": {\n",
    "            \"save_format\": \"parquet\",\n",
    "            \"create_summary\": True\n",
    "        },\n",
    "        \"validation\": {\n",
    "            \"validate_before_parsing\": True,\n",
    "            \"continue_on_error\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# This shows how it would be used in the full system\n",
    "print(\"Full configuration loaded:\")\n",
    "print(f\"- Parse mode: {full_config['parsing']['parse_mode']}\")\n",
    "print(f\"- Building range: {full_config['parsing']['building_selection']['building_range']}\")\n",
    "print(f\"- IDF categories: {full_config['parsing']['idf_content']['categories']}\")\n",
    "print(f\"- SQL categories: {full_config['parsing']['sql_content']['variables']['categories']}\")\n",
    "\n",
    "# %% Check results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING PARSED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check what was parsed in each test\n",
    "test_dirs = [\n",
    "    \"parsed_data_test1\",\n",
    "    \"parsed_data_test2\", \n",
    "    \"parsed_data_test3\",\n",
    "    \"parsed_data_test4\",\n",
    "    \"parsed_data_test5\"\n",
    "]\n",
    "\n",
    "for test_dir in test_dirs:\n",
    "    test_path = os.path.join(job_output_dir, test_dir)\n",
    "    if os.path.exists(test_path):\n",
    "        print(f\"\\n{test_dir}:\")\n",
    "        parsed_info = get_parsed_data_info(test_path)\n",
    "        print(f\"  Categories parsed: {len(parsed_info['categories'])}\")\n",
    "        print(f\"  Total buildings: {parsed_info['total_buildings']}\")\n",
    "        print(f\"  Total files: {parsed_info['total_files']}\")\n",
    "        \n",
    "        # Show categories\n",
    "        if parsed_info['categories']:\n",
    "            print(\"  Categories:\")\n",
    "            for cat, info in list(parsed_info['categories'].items())[:5]:\n",
    "                print(f\"    - {cat}: {info['rows']} rows\")\n",
    "\n",
    "# %% Utility function to run any config\n",
    "def run_parsing_with_config(config_dict, output_name):\n",
    "    \"\"\"\n",
    "    Utility function to run parsing with any configuration\n",
    "    \"\"\"\n",
    "    analyzer = EnergyPlusAnalyzer(os.path.join(job_output_dir, output_name))\n",
    "    \n",
    "    # Extract parsing config\n",
    "    parsing_cfg = config_dict.get(\"parsing\", config_dict)\n",
    "    \n",
    "    # Prepare file pairs\n",
    "    file_pairs = prepare_selective_file_pairs(\n",
    "        job_output_dir=job_output_dir,\n",
    "        parse_mode=parsing_cfg.get(\"parse_mode\", \"all\"),\n",
    "        parse_types=parsing_cfg.get(\"parse_types\", {\"idf\": True, \"sql\": True}),\n",
    "        building_selection=parsing_cfg.get(\"building_selection\", {}),\n",
    "        idf_map_csv=os.path.join(job_output_dir, \"extracted_idf_buildings.csv\")\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(file_pairs)} file pairs\")\n",
    "    \n",
    "    # Run analysis\n",
    "    analyzer.analyze_project_selective(\n",
    "        file_pairs,\n",
    "        idf_content_config=parsing_cfg.get(\"idf_content\"),\n",
    "        sql_content_config=parsing_cfg.get(\"sql_content\"),\n",
    "        output_options=parsing_cfg.get(\"output_options\"),\n",
    "        validation_options=parsing_cfg.get(\"validation\")\n",
    "    )\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "# Example usage:\n",
    "analyzer = run_parsing_with_config(full_config, \"parsed_data_full_test\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
