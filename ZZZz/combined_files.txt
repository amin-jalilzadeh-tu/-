File: D:\Documents\E_Plus_2030_py\modification\elec_functions.py
============================================================
"""
elec_functions.py

Provides functions for applying lighting + parasitic equipment parameters
to an EnergyPlus IDF, analogous to hvac_functions or vent_functions.

Contents:
  1) create_elec_scenarios(...)
     - Takes df_lighting with columns [ogc_fid, object_name, param_name, assigned_value, min_val, max_val],
       generates scenario picks, and writes them to CSV.

  2) apply_building_level_elec(idf, param_dict)
     - A building-level approach: lumps all lighting/EQ loads into one or two IDF objects (LIGHTS, ELECTRICEQUIPMENT),
       referencing an existing zone list and referencing "LightsSchedule" or "ParasiticSchedule".

  3) apply_object_level_elec(idf, df_lighting)
     - A row-by-row approach: reads from a scenario DataFrame and updates each LIGHTS/ELECTRICEQUIPMENT object directly.
"""

import os
import random
import pandas as pd

# ---------------------------------------------------------------------------
# 1) CREATE ELEC SCENARIOS
# ---------------------------------------------------------------------------
def create_elec_scenarios(
    df_lighting,
    building_id,
    num_scenarios=5,
    picking_method="random_uniform",
    random_seed=42,
    scenario_csv_out=None
):
    """
    Generates a scenario-level DataFrame from "assigned_lighting.csv" rows:
      Each row has: ogc_fid, object_name, param_name, assigned_value, min_val, max_val

    If picking_method=="random_uniform" and min_val < max_val, picks a random float in [min_val, max_val].
    Otherwise keeps assigned_value as is.

    Final columns in df_scen:
      scenario_index, ogc_fid, object_name, param_name, param_value,
      param_min, param_max, picking_method

    If scenario_csv_out is provided, we write it to that CSV.

    Returns:
      pd.DataFrame: the scenario DataFrame
    """
    if random_seed is not None:
        random.seed(random_seed)

    # filter for the building
    df_bldg = df_lighting[df_lighting["ogc_fid"] == building_id].copy()
    if df_bldg.empty:
        print(f"[create_elec_scenarios] No lighting data found for building {building_id}")
        return pd.DataFrame()

    scenario_rows = []

    # For each scenario
    for s in range(num_scenarios):
        for row in df_bldg.itertuples():
            obj_name = row.object_name
            p_name   = row.param_name

            base_val = row.assigned_value
            p_min    = row.min_val
            p_max    = row.max_val

            new_val  = pick_value(base_val, p_min, p_max, picking_method)

            scenario_rows.append({
                "scenario_index":  s,
                "ogc_fid":         building_id,
                "object_name":     obj_name,
                "param_name":      p_name,
                "param_value":     new_val,
                "param_min":       p_min,
                "param_max":       p_max,
                "picking_method":  picking_method
            })

    df_scen = pd.DataFrame(scenario_rows)

    if scenario_csv_out:
        os.makedirs(os.path.dirname(scenario_csv_out), exist_ok=True)
        df_scen.to_csv(scenario_csv_out, index=False)
        print(f"[create_elec_scenarios] Wrote scenario file => {scenario_csv_out}")

    return df_scen


def pick_value(base_val, p_min, p_max, picking_method):
    """
    If picking_method=="random_uniform" and p_min/p_max are numeric and p_min< p_max,
    pick a random float in [p_min, p_max].
    Otherwise keep base_val as is.
    """
    try:
        base_float = float(base_val)
    except:
        base_float = None

    if picking_method == "random_uniform":
        try:
            fmin = float(p_min)
            fmax = float(p_max)
            if fmax > fmin:
                return random.uniform(fmin, fmax)
        except:
            pass
    # fallback
    return base_val

# ---------------------------------------------------------------------------
# 2) APPLY BUILDING-LEVEL ELECTRICAL PARAMETERS
# ---------------------------------------------------------------------------
def apply_building_level_elec(idf, param_dict, zonelist_name="ALL_ZONES"):
    """
    Interprets a dictionary of lighting/electrical parameters, e.g.:

      param_dict = {
        "lights_wm2": 19.2788535969,
        "parasitic_wm2": 0.285,
        "lights_fraction_radiant": 0.7,
        "lights_fraction_visible": 0.2,
        "lights_fraction_replaceable": 1.0,
        "equip_fraction_radiant": 0.0,
        "equip_fraction_lost": 1.0,
        "lights_schedule_name": "LightsSchedule",      # <--- optional override
        "equip_schedule_name": "ParasiticSchedule"     # <--- optional override
      }

    Then we create or update:
      - One LIGHTS object for the entire building (via `zonelist_name`).
      - One ELECTRICEQUIPMENT object for parasitic loads.

    We reference existing schedules (e.g. "LightsSchedule" or "ParasiticSchedule")
    from the base IDF (instead of "AlwaysOn").
    """

    # Extract numeric picks
    lights_wm2          = float(param_dict.get("lights_wm2", 10.0))
    parasitic_wm2       = float(param_dict.get("parasitic_wm2", 0.285))
    lights_frac_radiant = float(param_dict.get("lights_fraction_radiant", 0.7))
    lights_frac_visible = float(param_dict.get("lights_fraction_visible", 0.2))
    lights_frac_replace = float(param_dict.get("lights_fraction_replaceable", 1.0))
    lights_frac_return  = float(param_dict.get("lights_fraction_return_air", 0.0))
    equip_frac_radiant  = float(param_dict.get("equip_fraction_radiant", 0.0))
    equip_frac_lost     = float(param_dict.get("equip_fraction_lost", 1.0))

    # Which schedules to use (must exist in your base IDF).
    # If param_dict doesn't have them, we default to "LightsSchedule" / "ParasiticSchedule".
    lights_sched_name = param_dict.get("lights_schedule_name", "LightsSchedule")
    equip_sched_name  = param_dict.get("equip_schedule_name",  "ParasiticSchedule")

    print("[ELEC] => Building-level electrical picks:")
    print(f"  lights_wm2={lights_wm2}, parasitic_wm2={parasitic_wm2}")
    print(f"  lights_frac_radiant={lights_frac_radiant}, visible={lights_frac_visible}, replaceable={lights_frac_replace}, return_air={lights_frac_return}")
    print(f"  equip_frac_radiant={equip_frac_radiant}, equip_frac_lost={equip_frac_lost}")
    print(f"  schedules => lights={lights_sched_name}, equip={equip_sched_name}")

    # Create/update LIGHTS object
    lights_obj_name = f"Lights_{zonelist_name}"
    lights_obj = _create_or_update_lights_object(
        idf=idf,
        obj_name=lights_obj_name,
        zone_or_zonelist=zonelist_name,
        lights_wm2=lights_wm2,
        frac_radiant=lights_frac_radiant,
        frac_visible=lights_frac_visible,
        frac_replace=lights_frac_replace,
        frac_return=lights_frac_return,
        lights_schedule_name=lights_sched_name
    )

    # Create/update ELECTRICEQUIPMENT object
    equip_obj_name = f"Equip_{zonelist_name}"
    equip_obj = _create_or_update_equip_object(
        idf=idf,
        obj_name=equip_obj_name,
        zone_or_zonelist=zonelist_name,
        equip_wm2=parasitic_wm2,
        frac_radiant=equip_frac_radiant,
        frac_lost=equip_frac_lost,
        equip_schedule_name=equip_sched_name
    )

    return lights_obj, equip_obj


def _create_or_update_lights_object(
    idf,
    obj_name,
    zone_or_zonelist="ALL_ZONES",
    lights_wm2=10.0,
    frac_radiant=0.7,
    frac_visible=0.2,
    frac_replace=1.0,
    frac_return=0.0,
    lights_schedule_name="LightsSchedule"
):
    """
    Creates/updates a LIGHTS object with 'Watts/Area' method,
    referencing an existing schedule (lights_schedule_name).
    """
    existing = [
        lt for lt in idf.idfobjects["LIGHTS"]
        if lt.Name.upper() == obj_name.upper()
    ]
    if existing:
        lights_obj = existing[0]
    else:
        lights_obj = idf.newidfobject("LIGHTS", Name=obj_name)

    # zone or zone list
    if hasattr(lights_obj, "Zone_or_ZoneList_or_Space_or_SpaceList_Name"):
        lights_obj.Zone_or_ZoneList_or_Space_or_SpaceList_Name = zone_or_zonelist
    else:
        lights_obj.Zone_or_ZoneList_Name = zone_or_zonelist

    # design method
    lights_obj.Design_Level_Calculation_Method = "Watts/Area"
    lights_obj.Watts_per_Zone_Floor_Area = lights_wm2

    # use the existing lighting schedule from your base IDF
    lights_obj.Schedule_Name = lights_schedule_name

    # fractions
    if hasattr(lights_obj, "Fraction_Radiant"):
        lights_obj.Fraction_Radiant = frac_radiant
    if hasattr(lights_obj, "Fraction_Visible"):
        lights_obj.Fraction_Visible = frac_visible
    if hasattr(lights_obj, "Fraction_Replaceable"):
        lights_obj.Fraction_Replaceable = frac_replace
    if hasattr(lights_obj, "Return_Air_Fraction"):
        lights_obj.Return_Air_Fraction = frac_return

    return lights_obj


def _create_or_update_equip_object(
    idf,
    obj_name,
    zone_or_zonelist="ALL_ZONES",
    equip_wm2=0.285,
    frac_radiant=0.0,
    frac_lost=1.0,
    equip_schedule_name="ParasiticSchedule"
):
    """
    Creates/updates an ELECTRICEQUIPMENT object with 'Watts/Area' method,
    referencing an existing schedule (equip_schedule_name).
    """
    existing = [
        eq for eq in idf.idfobjects["ELECTRICEQUIPMENT"]
        if eq.Name.upper() == obj_name.upper()
    ]
    if existing:
        equip_obj = existing[0]
    else:
        equip_obj = idf.newidfobject("ELECTRICEQUIPMENT", Name=obj_name)

    if hasattr(equip_obj, "Zone_or_ZoneList_or_Space_or_SpaceList_Name"):
        equip_obj.Zone_or_ZoneList_or_Space_or_SpaceList_Name = zone_or_zonelist
    else:
        equip_obj.Zone_or_ZoneList_Name = zone_or_zonelist

    equip_obj.Design_Level_Calculation_Method = "Watts/Area"
    equip_obj.Watts_per_Zone_Floor_Area = equip_wm2

    # use the existing equipment schedule from your base IDF
    equip_obj.Schedule_Name = equip_schedule_name

    # fraction fields
    if hasattr(equip_obj, "Fraction_Radiant"):
        equip_obj.Fraction_Radiant = frac_radiant
    if hasattr(equip_obj, "Fraction_Lost"):
        equip_obj.Fraction_Lost = frac_lost

    return equip_obj

# ---------------------------------------------------------------------------
# 3) APPLY OBJECT-LEVEL ELECTRIC PARAMETERS
# ---------------------------------------------------------------------------
def apply_object_level_elec(idf, df_lighting):
    """
    Reads a scenario DataFrame with columns:
      [ogc_fid, object_name, param_name, param_value, param_min, param_max, ...]
    For each object_name, we parse param_name=>param_value pairs
    and update or create the corresponding IDF object.

    e.g. assigned_lighting.csv might have:
      ogc_fid, object_name, param_name, assigned_value, ...
      4136730, LIGHTS, lights_wm2, 19.2788535969
      4136730, ELECTRICEQUIPMENT, parasitic_wm2, 0.285
      4136730, LIGHTS.Fraction_Radiant, lights_fraction_radiant, 0.7
      ...

    Steps:
      1) group by object_name
      2) build a param_dict
      3) update the IDF object accordingly
    """
    object_groups = df_lighting.groupby("object_name")

    for obj_name, group_df in object_groups:
        print(f"[ELEC] Handling object_name='{obj_name}' with {len(group_df)} rows.")
        param_dict = {}
        for row in group_df.itertuples():
            p_name = row.param_name
            val    = row.param_value
            # attempt float
            try:
                param_dict[p_name] = float(val)
            except:
                param_dict[p_name] = val

        # Decide how to update the IDF object
        if obj_name.upper() == "LIGHTS":
            _update_generic_lights_obj(idf, "LIGHTS", param_dict)
        elif obj_name.upper() == "ELECTRICEQUIPMENT":
            _update_generic_equip_obj(idf, "ELECTRICEQUIPMENT", param_dict)
        elif "SCHEDULE" in obj_name.upper():
            pass  # e.g. "LIGHTS_SCHEDULE": your code for schedule logic
        else:
            print(f"[ELEC WARNING] Unknown object_name='{obj_name}', skipping or handle differently.")


def _update_generic_lights_obj(idf, obj_name, param_dict):
    """
    Example for updating a LIGHTS object named `obj_name`.
    param_dict might have "lights_wm2", "lights_fraction_radiant", etc.
    """
    existing = [lt for lt in idf.idfobjects["LIGHTS"] if lt.Name.upper() == obj_name.upper()]
    if existing:
        lights_obj = existing[0]
    else:
        lights_obj = idf.newidfobject("LIGHTS", Name=obj_name)

    if "lights_wm2" in param_dict:
        lights_obj.Design_Level_Calculation_Method = "Watts/Area"
        lights_obj.Watts_per_Zone_Floor_Area = float(param_dict["lights_wm2"])

    if "lights_fraction_radiant" in param_dict and hasattr(lights_obj, "Fraction_Radiant"):
        lights_obj.Fraction_Radiant = float(param_dict["lights_fraction_radiant"])

    if "lights_fraction_visible" in param_dict and hasattr(lights_obj, "Fraction_Visible"):
        lights_obj.Fraction_Visible = float(param_dict["lights_fraction_visible"])

    if "lights_fraction_replaceable" in param_dict and hasattr(lights_obj, "Fraction_Replaceable"):
        lights_obj.Fraction_Replaceable = float(param_dict["lights_fraction_replaceable"])

    if "lights_fraction_return_air" in param_dict and hasattr(lights_obj, "Return_Air_Fraction"):
        lights_obj.Return_Air_Fraction = float(param_dict["lights_fraction_return_air"])


def _update_generic_equip_obj(idf, obj_name, param_dict):
    """
    Example for updating an ELECTRICEQUIPMENT object. param_dict might have:
      "parasitic_wm2", "equip_fraction_radiant", "equip_fraction_lost", etc.
    """
    existing = [eq for eq in idf.idfobjects["ELECTRICEQUIPMENT"] if eq.Name.upper() == obj_name.upper()]
    if existing:
        equip_obj = existing[0]
    else:
        equip_obj = idf.newidfobject("ELECTRICEQUIPMENT", Name=obj_name)

    if "parasitic_wm2" in param_dict:
        equip_obj.Design_Level_Calculation_Method = "Watts/Area"
        equip_obj.Watts_per_Zone_Floor_Area = float(param_dict["parasitic_wm2"])

    if "equip_fraction_radiant" in param_dict and hasattr(equip_obj, "Fraction_Radiant"):
        equip_obj.Fraction_Radiant = float(param_dict["equip_fraction_radiant"])

    if "equip_fraction_lost" in param_dict and hasattr(equip_obj, "Fraction_Lost"):
        equip_obj.Fraction_Lost = float(param_dict["equip_fraction_lost"])

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\modification\equipment_functions.py
============================================================
"""equipment_functions.py

Provides helper functions for scenario generation and IDF updates for
building-level electric equipment loads. The overall style mirrors
``elec_functions.py`` but focuses on generic ELECTRICEQUIPMENT objects
that are separate from lighting/parasitic loads.
"""

import os
import pandas as pd
from idf_objects.eequip.schedules import create_equipment_schedule


# ---------------------------------------------------------------------------
# 1) CREATE EQUIPMENT SCENARIOS
# ---------------------------------------------------------------------------
def create_equipment_scenarios(
    df_equipment,
    building_id,
    num_scenarios=5,
    picking_method="random_uniform",
    random_seed=42,
    scenario_csv_out=None,
):
    """Build a scenario DataFrame from ``assigned_equipment.csv`` rows.

    Parameters
    ----------
    df_equipment : pd.DataFrame
        Rows for a single building with columns ``ogc_fid``, ``param_name`` and
        ``assigned_value``.
    building_id : int
        ID of the building we are processing.
    num_scenarios : int, default 5
        How many scenario rows to generate.
    picking_method : str, ignored for now
        Included for API compatibility.
    random_seed : int, optional
        Seed if future extensions use randomness.
    scenario_csv_out : str, optional
        Path to write ``scenario_params_equipment.csv``.
    """
    if random_seed is not None:
        import random
        random.seed(random_seed)

    df_bldg = df_equipment[df_equipment["ogc_fid"] == building_id].copy()
    if df_bldg.empty:
        print(f"[create_equipment_scenarios] No equipment data for building {building_id}")
        return pd.DataFrame()

    rows = []
    for s in range(num_scenarios):
        for row in df_bldg.itertuples():
            rows.append({
                "scenario_index": s,
                "ogc_fid": building_id,
                "param_name": row.param_name,
                "param_value": row.assigned_value,
                "param_min": None,
                "param_max": None,
                "picking_method": picking_method,
            })
    df_scen = pd.DataFrame(rows)

    if scenario_csv_out:
        os.makedirs(os.path.dirname(scenario_csv_out), exist_ok=True)
        df_scen.to_csv(scenario_csv_out, index=False)
        print(f"[create_equipment_scenarios] Wrote => {scenario_csv_out}")

    return df_scen


# ---------------------------------------------------------------------------
# 2) APPLY BUILDING-LEVEL EQUIPMENT PARAMETERS
# ---------------------------------------------------------------------------
def apply_building_level_equipment(idf, param_dict, zonelist_name="ALL_ZONES"):
    """Create or update a single ELECTRICEQUIPMENT object.

    ``param_dict`` typically contains at least ``equip_wm2``. Optional keys
    ``building_category`` and ``sub_type`` allow schedule generation using
    :func:`create_equipment_schedule`.
    """
    equip_wm2 = float(param_dict.get("equip_wm2", 3.0))
    bcat = param_dict.get("building_category", "Non-Residential")
    subtype = param_dict.get("sub_type", "Other Use Function")

    sched_name = create_equipment_schedule(
        idf,
        building_category=bcat,
        sub_type=subtype,
        schedule_name="EquipSchedule",
    )

    obj_name = f"Equip_{zonelist_name}"
    existing = [
        eq for eq in idf.idfobjects["ELECTRICEQUIPMENT"]
        if eq.Name.upper() == obj_name.upper()
    ]
    equip_obj = existing[0] if existing else idf.newidfobject("ELECTRICEQUIPMENT", Name=obj_name)

    if hasattr(equip_obj, "Zone_or_ZoneList_or_Space_or_SpaceList_Name"):
        equip_obj.Zone_or_ZoneList_or_Space_or_SpaceList_Name = zonelist_name
    else:
        equip_obj.Zone_or_ZoneList_Name = zonelist_name

    equip_obj.Schedule_Name = sched_name
    equip_obj.Design_Level_Calculation_Method = "Watts/Area"
    equip_obj.Watts_per_Zone_Floor_Area = equip_wm2

    return equip_obj


# ---------------------------------------------------------------------------
# 3) APPLY OBJECT-LEVEL EQUIPMENT PARAMETERS
# ---------------------------------------------------------------------------
def apply_object_level_equipment(idf, df_equipment):
    """Update ELECTRICEQUIPMENT objects row by row from a scenario DataFrame."""
    for row in df_equipment.itertuples():
        obj_name = row.object_name if hasattr(row, "object_name") else "ELECTRICEQUIPMENT"
        p_name = row.param_name
        val = row.param_value

        existing = [eq for eq in idf.idfobjects["ELECTRICEQUIPMENT"] if eq.Name.upper() == obj_name.upper()]
        equip_obj = existing[0] if existing else idf.newidfobject("ELECTRICEQUIPMENT", Name=obj_name)

        if p_name == "equip_wm2":
            equip_obj.Design_Level_Calculation_Method = "Watts/Area"
            equip_obj.Watts_per_Zone_Floor_Area = float(val)
        elif p_name == "Schedule_Name":
            equip_obj.Schedule_Name = val
        else:
            # Generic setter if attribute exists
            if hasattr(equip_obj, p_name):
                try:
                    setattr(equip_obj, p_name, float(val))
                except Exception:
                    setattr(equip_obj, p_name, val)

    return

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\modification\main_modifi.py
============================================================
"""
main_modifi.py

Handles the generation of scenario-based IDFs for sensitivity, surrogate, 
calibration, or any parametric runs.

Workflow Outline:
  1) Loads "assigned"/"structured" CSV data for HVAC, DHW, Vent, Elec, Fenestration.
  2) Generates multiple scenario picks (random or other) -> scenario_params_*.csv
  3) Loads scenario CSVs, loops over scenario_index, applies them to IDFs
  4) Optionally runs simulations, post-processes, and does validation
"""

import os
import pandas as pd

# ---------------------------------------------------------------------------
# Local modules
# ---------------------------------------------------------------------------
from modification.common_utils import (
    load_assigned_csv,
    load_scenario_csv,
    load_idf,
    save_idf,
    generate_multiple_param_sets,
    save_param_scenarios_to_csv
)

# HVAC
from modification.hvac_functions import (
    create_hvac_scenarios,
    apply_building_level_hvac,
    apply_zone_level_hvac
)

# DHW
from modification.dhw_functions import apply_dhw_params_to_idf

# Elec
from modification.elec_functions import (
    create_elec_scenarios,
    apply_building_level_elec,
    apply_object_level_elec
)

# Equipment
from modification.equipment_functions import (
    create_equipment_scenarios,
    apply_building_level_equipment,
    apply_object_level_equipment,
)

# Fenestration
from modification.fenez_functions2 import (
    create_fenez_scenarios,
    apply_object_level_fenez
)

# Vent
from modification.vent_functions import (
    create_vent_scenarios,
    apply_building_level_vent,
    apply_zone_level_vent
)


def run_modification_workflow(config):
    """
    Main orchestration function that:
      - Loads assigned/structured CSV data for each system (HVAC, DHW, Vent, Elec, Fenez)
      - Creates multiple scenario picks
      - Applies them to a base IDF, generating scenario IDFs
      - Optionally runs simulations, post-process, and validation.
    """
    # -----------------------------------------------------------------------
    # 1) Extract from config
    # -----------------------------------------------------------------------
    base_idf_path   = config["base_idf_path"]
    idd_path        = config["idd_path"]
    assigned_csvs   = config["assigned_csv"]
    scenario_csvs   = config["scenario_csv"]
    building_id     = config["building_id"]
    num_scenarios   = config["num_scenarios"]
    picking_method  = config["picking_method"]
    scale_factor    = config.get("picking_scale_factor", 1.0)
    output_idf_dir  = config["output_idf_dir"]

    os.makedirs(output_idf_dir, exist_ok=True)

    # -----------------------------------------------------------------------
    # 2) HVAC CSV (either building+zones or single 'hvac')
    # -----------------------------------------------------------------------
    df_hvac_bld_sub = pd.DataFrame()
    df_hvac_zn_sub  = pd.DataFrame()
    has_hvac_data   = False

    if "hvac_building" in assigned_csvs and "hvac_zones" in assigned_csvs:
        path_bld = assigned_csvs["hvac_building"]
        path_zn  = assigned_csvs["hvac_zones"]

        df_hvac_bld_all = load_assigned_csv(path_bld)
        df_hvac_zn_all  = load_assigned_csv(path_zn)
        df_hvac_bld_sub = df_hvac_bld_all[df_hvac_bld_all["ogc_fid"] == building_id].copy()
        df_hvac_zn_sub  = df_hvac_zn_all[df_hvac_zn_all["ogc_fid"] == building_id].copy()
        has_hvac_data = True
    elif "hvac" in assigned_csvs:
        # single CSV
        path_hvac_single = assigned_csvs["hvac"]
        df_hvac_all = load_assigned_csv(path_hvac_single)
        df_hvac_bld_sub = df_hvac_all[df_hvac_all["ogc_fid"] == building_id].copy()
        has_hvac_data = True

    # -----------------------------------------------------------------------
    # 3) DHW
    # -----------------------------------------------------------------------
    df_dhw_all = load_assigned_csv(assigned_csvs["dhw"])
    df_dhw_sub = df_dhw_all[df_dhw_all["ogc_fid"] == building_id].copy()

    # -----------------------------------------------------------------------
    # 4) Vent (either building+zones or single 'vent')
    # -----------------------------------------------------------------------
    df_vent_bld_sub = pd.DataFrame()
    df_vent_zn_sub  = pd.DataFrame()
    has_vent_data   = False

    if "vent_building" in assigned_csvs and "vent_zones" in assigned_csvs:
        vent_bld_path = assigned_csvs["vent_building"]
        vent_zn_path  = assigned_csvs["vent_zones"]
        df_vent_bld_all = load_assigned_csv(vent_bld_path)
        df_vent_zn_all  = load_assigned_csv(vent_zn_path)
        df_vent_bld_sub = df_vent_bld_all[df_vent_bld_all["ogc_fid"] == building_id].copy()
        df_vent_zn_sub  = df_vent_zn_all[df_vent_zn_all["ogc_fid"] == building_id].copy()
        has_vent_data = True
    elif "vent" in assigned_csvs:
        vent_single_path = assigned_csvs["vent"]
        df_vent_all = load_assigned_csv(vent_single_path)
        df_vent_bld_sub = df_vent_all[df_vent_all["ogc_fid"] == building_id].copy()
        has_vent_data = True

    # -----------------------------------------------------------------------
    # 5) Elec
    # -----------------------------------------------------------------------
    df_elec_all = load_assigned_csv(assigned_csvs["elec"])
    df_elec_sub = df_elec_all[df_elec_all["ogc_fid"] == building_id].copy()

    # -----------------------------------------------------------------------
    # 6) Equipment
    # -----------------------------------------------------------------------
    df_equip_all = load_assigned_csv(assigned_csvs["equip"])
    df_equip_sub = df_equip_all[df_equip_all["ogc_fid"] == building_id].copy()

    # -----------------------------------------------------------------------
    # 7) Fenestration
    # -----------------------------------------------------------------------
    df_fenez_all = load_assigned_csv(assigned_csvs["fenez"])
    df_fenez_sub = df_fenez_all[df_fenez_all["ogc_fid"] == building_id].copy()

    # -----------------------------------------------------------------------
    # 7) Generate scenario picks for each system
    # -----------------------------------------------------------------------

    # 7A) HVAC
    if has_hvac_data and (not df_hvac_bld_sub.empty or not df_hvac_zn_sub.empty):
        from modification.hvac_functions import create_hvac_scenarios
        df_scen_hvac = create_hvac_scenarios(
            df_building=df_hvac_bld_sub,
            df_zones=df_hvac_zn_sub,
            building_id=building_id,
            num_scenarios=num_scenarios,
            picking_method=picking_method,
            random_seed=42,
            scenario_csv_out=scenario_csvs["hvac"]
        )
    else:
        df_scen_hvac = pd.DataFrame()
        if "hvac" in assigned_csvs and not df_hvac_bld_sub.empty:
            hvac_scenarios = generate_multiple_param_sets(
                df_main_sub=df_hvac_bld_sub,
                num_sets=num_scenarios,
                picking_method=picking_method,
                scale_factor=scale_factor
            )
            save_param_scenarios_to_csv(hvac_scenarios, building_id, scenario_csvs["hvac"])

    # 7B) DHW
    # If you prefer a param_min/param_max approach, import create_dhw_scenarios. 
    # Otherwise, fallback to generate_multiple_param_sets:
    from modification.dhw_functions import create_dhw_scenarios
    df_scen_dhw = create_dhw_scenarios(
        df_dhw_input=df_dhw_sub,
        building_id=building_id,
        num_scenarios=num_scenarios,
        picking_method=picking_method,
        random_seed=42,
        scenario_csv_out=scenario_csvs["dhw"]
    )

    # If older approach:
    # dhw_scenarios = generate_multiple_param_sets(df_main_sub=df_dhw_sub, ...)
    # save_param_scenarios_to_csv(dhw_scenarios, building_id, scenario_csvs["dhw"])

    # 7C) Vent
    if has_vent_data and (not df_vent_bld_sub.empty or not df_vent_zn_sub.empty):
        df_scen_vent = create_vent_scenarios(
            df_building=df_vent_bld_sub,
            df_zones=df_vent_zn_sub,
            building_id=building_id,
            num_scenarios=num_scenarios,
            picking_method=picking_method,
            random_seed=42,
            scenario_csv_out=scenario_csvs["vent"]
        )
    else:
        df_scen_vent = pd.DataFrame()

    # 7D) Elec => "create_elec_scenarios" for param_min/param_max approach
    df_scen_elec = create_elec_scenarios(
        df_lighting=df_elec_sub,
        building_id=building_id,
        num_scenarios=num_scenarios,
        picking_method=picking_method,
        random_seed=42,
        scenario_csv_out=scenario_csvs["elec"]
    )

    # 7E) Equipment
    df_scen_equip = create_equipment_scenarios(
        df_equipment=df_equip_sub,
        building_id=building_id,
        num_scenarios=num_scenarios,
        picking_method=picking_method,
        random_seed=42,
        scenario_csv_out=scenario_csvs["equip"]
    )

    # 7F) Fenestration
    df_scen_fenez = create_fenez_scenarios(
        df_struct_fenez=df_fenez_sub,
        building_id=building_id,
        num_scenarios=num_scenarios,
        picking_method=picking_method,
        random_seed=42,
        scenario_csv_out=scenario_csvs["fenez"]
    )

    # -----------------------------------------------------------------------
    # 8) Load scenario CSVs back, group by scenario_index
    # -----------------------------------------------------------------------
    df_hvac_scen  = load_scenario_csv(scenario_csvs["hvac"])  if os.path.isfile(scenario_csvs["hvac"])  else pd.DataFrame()
    df_dhw_scen   = load_scenario_csv(scenario_csvs["dhw"])   if os.path.isfile(scenario_csvs["dhw"])   else pd.DataFrame()
    df_vent_scen  = load_scenario_csv(scenario_csvs["vent"])  if os.path.isfile(scenario_csvs["vent"])  else pd.DataFrame()
    df_elec_scen  = load_scenario_csv(scenario_csvs["elec"])  if os.path.isfile(scenario_csvs["elec"])  else pd.DataFrame()
    df_equip_scen = load_scenario_csv(scenario_csvs["equip"]) if os.path.isfile(scenario_csvs["equip"]) else pd.DataFrame()
    df_fenez_scen = load_scenario_csv(scenario_csvs["fenez"]) if os.path.isfile(scenario_csvs["fenez"]) else pd.DataFrame()

    hvac_groups  = df_hvac_scen.groupby("scenario_index")  if not df_hvac_scen.empty  else None
    dhw_groups   = df_dhw_scen.groupby("scenario_index")   if not df_dhw_scen.empty   else None
    vent_groups  = df_vent_scen.groupby("scenario_index")  if not df_vent_scen.empty  else None
    elec_groups  = df_elec_scen.groupby("scenario_index")  if not df_elec_scen.empty  else None
    equip_groups = df_equip_scen.groupby("scenario_index") if not df_equip_scen.empty else None
    fenez_groups = df_fenez_scen.groupby("scenario_index") if not df_fenez_scen.empty else None

    # -----------------------------------------------------------------------
    # 9) For each scenario, load base IDF, apply parameters, save new IDF
    # -----------------------------------------------------------------------
    for i in range(num_scenarios):
        print(f"\n--- Creating scenario #{i} for building {building_id} ---")

        # 9A) Pull sub-DataFrames
        hvac_df = hvac_groups.get_group(i) if hvac_groups and i in hvac_groups.groups else pd.DataFrame()
        dhw_df  = dhw_groups.get_group(i)  if dhw_groups  and i in dhw_groups.groups  else pd.DataFrame()
        vent_df = vent_groups.get_group(i) if vent_groups and i in vent_groups.groups else pd.DataFrame()
        elec_df = elec_groups.get_group(i) if elec_groups and i in elec_groups.groups else pd.DataFrame()
        equip_df = equip_groups.get_group(i) if equip_groups and i in equip_groups.groups else pd.DataFrame()
        fenez_df= fenez_groups.get_group(i)if fenez_groups and i in fenez_groups.groups else pd.DataFrame()

        # 9B) For HVAC: building-level vs. zone-level
        hvac_bld_df  = hvac_df[hvac_df["zone_name"].isna()]   if not hvac_df.empty else pd.DataFrame()
        hvac_zone_df = hvac_df[hvac_df["zone_name"].notna()]  if not hvac_df.empty else pd.DataFrame()
        hvac_params  = _make_param_dict(hvac_bld_df)

        # 9C) Convert to param dict for DHW
        dhw_params = _make_param_dict(dhw_df)

        # 9D) Vent building vs. zone
        vent_bld_df  = vent_df[vent_df["zone_name"].isnull()] if not vent_df.empty else pd.DataFrame()
        vent_zone_df = vent_df[vent_df["zone_name"].notnull()]if not vent_df.empty else pd.DataFrame()
        vent_params  = _make_param_dict(vent_bld_df)

        # 9E) Elec => building-level approach or object-level
        elec_params = _make_param_dict(elec_df)

        # 9F) Equipment
        equip_params = _make_param_dict(equip_df)

        # 9G) Load base IDF
        idf = load_idf(base_idf_path, idd_path)

        # 9H) Apply building-level + zone-level HVAC
        apply_building_level_hvac(idf, hvac_params)
        apply_zone_level_hvac(idf, hvac_zone_df)

        # 9I) Apply DHW
        apply_dhw_params_to_idf(idf, dhw_params, suffix=f"Scenario_{i}")

        # 9J) Apply Vent
        if not vent_bld_df.empty or not vent_zone_df.empty:
            apply_building_level_vent(idf, vent_params)
            apply_zone_level_vent(idf, vent_zone_df)

        # 9K) Apply Elec => building-level approach
        #    Or if you prefer object-level, do apply_object_level_elec(idf, elec_df)
        if not elec_df.empty:
            apply_building_level_elec(idf, elec_params, zonelist_name="ALL_ZONES")

        # 9L) Apply Equipment
        if not equip_df.empty:
            apply_building_level_equipment(idf, equip_params, zonelist_name="ALL_ZONES")

        # 9M) Apply Fenestration (object-level)
        apply_object_level_fenez(idf, fenez_df)

        # 9N) Save scenario IDF
        scenario_idf_name = f"building_{building_id}_scenario_{i}.idf"
        scenario_idf_path = os.path.join(output_idf_dir, scenario_idf_name)
        save_idf(idf, scenario_idf_path)
        print(f"[INFO] Saved scenario IDF: {scenario_idf_path}")

    print("[INFO] All scenario IDFs generated successfully.")

    # -----------------------------------------------------------------------
    # 10) (Optional) Run Simulations
    # -----------------------------------------------------------------------
    if config.get("run_simulations", False):
        print("\n[INFO] Running simulations for scenario IDFs...")
        sim_cfg = config.get("simulation_config", {})
        # your simulate_all(...) or E+ runner here
        print("[INFO] Simulations complete (placeholder).")

    # -----------------------------------------------------------------------
    # 11) (Optional) Post-processing
    # -----------------------------------------------------------------------
    if config.get("perform_post_process", False):
        print("[INFO] Performing post-processing merges (placeholder).")
        ppcfg = config.get("post_process_config", {})
        # merge_all_results(...)
        print("[INFO] Post-processing step complete (placeholder).")

    # -----------------------------------------------------------------------
    # 12) (Optional) Validation
    # -----------------------------------------------------------------------
    if config.get("perform_validation", False):
        print("[INFO] Performing validation on scenario results (placeholder).")
        val_cfg = config["validation_config"]
        # run_validation_process(val_cfg)
        print("[INFO] Validation step complete (placeholder).")


def _make_param_dict(df_scenario):
    """
    Builds a dict {param_name: value} from a subset DataFrame, handling both
    'assigned_value' or 'param_value' columns in the scenario CSV.

    We check which column is present. If neither is found, we raise an error.
    """
    if df_scenario.empty:
        return {}

    possible_cols = list(df_scenario.columns)
    if "assigned_value" in possible_cols:
        val_col = "assigned_value"
    elif "param_value" in possible_cols:
        val_col = "param_value"
    else:
        raise AttributeError(
            "No 'assigned_value' or 'param_value' column found in scenario dataframe! "
            f"Columns are: {possible_cols}"
        )

    param_dict = {}
    for row in df_scenario.itertuples():
        p_name = row.param_name
        val    = getattr(row, val_col)
        # Attempt float
        try:
            param_dict[p_name] = float(val)
        except (ValueError, TypeError):
            param_dict[p_name] = val
    return param_dict

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_creation.py
============================================================
"""
idf_creation.py

Handles the creation of EnergyPlus IDF files for a list of buildings,
plus optional simulation runs and post-processing.

Key functionalities:
  1) create_idf_for_building(...) builds a single IDF using geomeppy,
     applying geometry, fenestration, HVAC, etc.
  2) create_idfs_for_all_buildings(...) loops over multiple buildings,
     then optionally runs simulations and merges results in one or more ways.

Updated to allow writing logs/results inside a specific job folder via logs_base_dir.
"""

import os
import logging
import pandas as pd

# geomeppy for IDF manipulation
from geomeppy import IDF

# --- Import your custom submodules ---
from idf_objects.geomz.building import create_building_with_roof_type
from idf_objects.fenez.fenestration import add_fenestration
from idf_objects.fenez.materials import (
    update_construction_materials,
    assign_constructions_to_surfaces
)
from idf_objects.Elec.lighting import add_lights_and_parasitics
from idf_objects.eequip.equipment import add_electric_equipment
from idf_objects.DHW.water_heater import add_dhw_to_idf
from idf_objects.HVAC.custom_hvac import add_HVAC_Ideal_to_all_zones
from idf_objects.ventilation.add_ventilation import add_ventilation_to_idf
from idf_objects.setzone.add_outdoor_air_and_zone_sizing_to_all_zones import add_outdoor_air_and_zone_sizing_to_all_zones
from idf_objects.tempground.add_ground_temperatures import add_ground_temperatures
from idf_objects.other.zonelist import create_zonelist

# Output & simulation modules
from idf_objects.outputdef.assign_output_settings import assign_output_settings
from idf_objects.outputdef.add_output_definitions import add_output_definitions
from postproc.merge_results import merge_all_results
from epw.run_epw_sims import simulate_all

###############################################################################
# Global Default IDF Config
# (Override these via environment variables or main_config if needed.)
###############################################################################
idf_config = {
    "iddfile": "EnergyPlus/Energy+.idd",         # Default path to the IDD file
    "idf_file_path": "EnergyPlus/Minimal.idf",   # Default path to a minimal base IDF
    "output_dir": "output/output_IDFs"           # Default folder to save generated IDFs
}


def create_idf_for_building(
    building_row,
    building_index,
    scenario="scenario1",
    calibration_stage="pre_calibration",
    strategy="B",
    random_seed=42,
    # Geometry
    user_config_geom=None,
    assigned_geom_log=None,
    # Lighting
    user_config_lighting=None,
    assigned_lighting_log=None,
    # Electric equipment
    user_config_equipment=None,
    assigned_equip_log=None,
    # DHW
    user_config_dhw=None,
    assigned_dhw_log=None,
    # Fenestration
    res_data=None,
    nonres_data=None,
    assigned_fenez_log=None,
    # HVAC
    user_config_hvac=None,
    assigned_hvac_log=None,
    # Vent
    user_config_vent=None,
    assigned_vent_log=None,
    # Zone sizing
    assigned_setzone_log=None,
    # Ground temps
    assigned_groundtemp_log=None,
    # Output definitions
    output_definitions=None
):
    """
    Build an IDF for a single building, applying geometry, fenestration, lighting,
    HVAC, ventilation, zone sizing, ground temps, and user overrides.

    Returns
    -------
    out_path : str
        File path to the saved IDF.
    """
    # 1) Setup IDF from the minimal template
    IDF.setiddname(idf_config["iddfile"])
    idf = IDF(idf_config["idf_file_path"])

    # 2) Basic building object settings
    building_obj = idf.newidfobject("BUILDING")
    building_obj.Name = f"Sample_Building_{building_index}"

    orientation = building_row.get("building_orientation", 0.0)



    # for orientation correction this changed 
    #if not pd.isna(orientation):
    #    building_obj.North_Axis = orientation






    if pd.isna(orientation):
        orientation = 0.0

    # Apply orientation when creating geometry.  The BUILDING object's
    # North_Axis is kept at 0 so that the rotated geometry correctly
    # represents the building's orientation in the world coordinate system.
    building_obj.North_Axis = 0.0









    # 3) Create geometry
    if assigned_geom_log is not None and building_row.get("ogc_fid") not in assigned_geom_log:
        assigned_geom_log[building_row.get("ogc_fid")] = {}

    edge_types = []
    for side_col in ["north_side", "east_side", "south_side", "west_side"]:
        edge_types.append(building_row.get(side_col, "Facade"))

    create_building_with_roof_type(
        idf=idf,
        area=building_row.get("area", 100.0),
        perimeter=building_row.get("perimeter", 40.0),
        orientation=orientation,
        building_row=building_row,
        edge_types=edge_types,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        user_config=user_config_geom,
        assigned_geom_log=assigned_geom_log
    )

    # 4) Update materials & constructions
    construction_map = update_construction_materials(
        idf=idf,
        building_row=building_row,
        building_index=building_index,
        scenario=scenario,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        user_config_fenez=None,  # not used directly
        assigned_fenez_log=assigned_fenez_log
    )
    assign_constructions_to_surfaces(idf, construction_map)

    # Create zone list for convenience
    create_zonelist(idf, zonelist_name="ALL_ZONES")

    # 5) Fenestration
    add_fenestration(
        idf=idf,
        building_row=building_row,
        scenario=scenario,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        res_data=res_data,
        nonres_data=nonres_data,
        assigned_fenez_log=assigned_fenez_log
    )

    # 6) Lighting
    add_lights_and_parasitics(
        idf=idf,
        building_row=building_row,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        user_config=user_config_lighting,
        assigned_values_log=assigned_lighting_log
    )

    # 7) Electric equipment
    add_electric_equipment(
        idf=idf,
        building_row=building_row,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        user_config=user_config_equipment,
        assigned_values_log=assigned_equip_log,
        zonelist_name="ALL_ZONES",
    )
    # 8) DHW
    add_dhw_to_idf(
        idf=idf,
        building_row=building_row,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        name_suffix=f"MyDHW_{building_index}",
        user_config_dhw=user_config_dhw,
        assigned_dhw_log=assigned_dhw_log,
        use_nta=True
    )

    # 9) HVAC
    add_HVAC_Ideal_to_all_zones(
        idf=idf,
        building_row=building_row,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        user_config_hvac=user_config_hvac,
        assigned_hvac_log=assigned_hvac_log
    )

    # 10) Ventilation
    add_ventilation_to_idf(
        idf=idf,
        building_row=building_row,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        user_config_vent=user_config_vent,
        assigned_vent_log=assigned_vent_log,
        infiltration_model="weather",
    )

    # 11) Zone sizing
    add_outdoor_air_and_zone_sizing_to_all_zones(
        idf=idf,
        building_row=building_row,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        assigned_setzone_log=assigned_setzone_log
    )

    # 12) Ground temperatures
    add_ground_temperatures(
        idf=idf,
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        assigned_groundtemp_log=assigned_groundtemp_log
    )

    # 13) Output definitions
    if output_definitions is None:
        output_definitions = {
            "desired_variables": ["Facility Total Electric Demand Power", "Zone Air Temperature"],
            "desired_meters": ["Electricity:Facility"],
            "override_variable_frequency": "Hourly",
            "override_meter_frequency": "Hourly",
            "include_tables": True,
            "include_summary": True
        }
    out_settings = assign_output_settings(
        desired_variables=output_definitions.get("desired_variables", []),
        desired_meters=output_definitions.get("desired_meters", []),
        override_variable_frequency=output_definitions.get("override_variable_frequency", "Hourly"),
        override_meter_frequency=output_definitions.get("override_meter_frequency", "Hourly"),
        include_tables=output_definitions.get("include_tables", True),
        include_summary=output_definitions.get("include_summary", True)
    )
    add_output_definitions(idf, out_settings)

    # 13) Save final IDF
    os.makedirs(idf_config["output_dir"], exist_ok=True)
    idf_filename = f"building_{building_index}.idf"
    out_path = os.path.join(idf_config["output_dir"], idf_filename)
    idf.save(out_path)
    print(f"[create_idf_for_building] IDF saved at: {out_path}")

    return out_path


def create_idfs_for_all_buildings(
    df_buildings,
    scenario="scenario1",
    calibration_stage="pre_calibration",
    strategy="B",
    random_seed=42,
    # partial user configs
    user_config_geom=None,
    user_config_lighting=None,
    user_config_equipment=None,
    user_config_dhw=None,
    res_data=None,
    nonres_data=None,
    user_config_hvac=None,
    user_config_vent=None,
    user_config_epw=None,  # pass epw config or list if relevant
    # output definitions
    output_definitions=None,
    # simulation & postprocess
    run_simulations=True,
    simulate_config=None,
    post_process=True,
    post_process_config=None,
    # NEW: Where to store logs and results
    logs_base_dir=None
):
    """
    Loops over df_buildings, calls create_idf_for_building for each building,
    optionally runs E+ simulations in parallel, and merges results if post_process=True.

    If logs_base_dir is provided, all assigned_*.csv and merged results go under that folder
    (e.g. logs_base_dir/assigned, logs_base_dir/Sim_Results, etc.).
    """
    logger = logging.getLogger(__name__)

    # A) Prepare dictionaries to store final picks for each module
    assigned_geom_log       = {}
    assigned_lighting_log   = {}
    assigned_equip_log      = {}
    assigned_dhw_log        = {}
    assigned_fenez_log      = {}
    assigned_hvac_log       = {}
    assigned_vent_log       = {}
    assigned_epw_log        = {}
    assigned_groundtemp_log = {}
    assigned_setzone_log    = {}

    # B) Create an IDF for each building
    for idx, row in df_buildings.iterrows():
        bldg_id = row.get("ogc_fid", idx)
        logger.info(f"--- Creating IDF for building index {idx}, ogc_fid={bldg_id} ---")

        idf_path = create_idf_for_building(
            building_row=row,
            building_index=idx,
            scenario=scenario,
            calibration_stage=calibration_stage,
            strategy=strategy,
            random_seed=random_seed,
            # geometry
            user_config_geom=user_config_geom,
            assigned_geom_log=assigned_geom_log,
            # lighting
            user_config_lighting=user_config_lighting,
            assigned_lighting_log=assigned_lighting_log,
            # electric equipment
            user_config_equipment=user_config_equipment,
            assigned_equip_log=assigned_equip_log,
            # DHW
            user_config_dhw=user_config_dhw,
            assigned_dhw_log=assigned_dhw_log,
            # Fenestration
            res_data=res_data,
            nonres_data=nonres_data,
            assigned_fenez_log=assigned_fenez_log,
            # HVAC
            user_config_hvac=user_config_hvac,
            assigned_hvac_log=assigned_hvac_log,
            # Vent
            user_config_vent=user_config_vent,
            assigned_vent_log=assigned_vent_log,
            # zone sizing
            assigned_setzone_log=assigned_setzone_log,
            # ground temps
            assigned_groundtemp_log=assigned_groundtemp_log,
            # output definitions
            output_definitions=output_definitions
        )
        # Store the final IDF filename in df_buildings
        df_buildings.loc[idx, "idf_name"] = os.path.basename(idf_path)

    # C) If we’re told to run simulations
    if run_simulations:
        logger.info("[create_idfs_for_all_buildings] => Running simulations ...")
        if simulate_config is None:
            simulate_config = {}

        # Decide on a base_output_dir for sim results
        if logs_base_dir:
            sim_output_dir = os.path.join(logs_base_dir, "Sim_Results")
        else:
            sim_output_dir = simulate_config.get("base_output_dir", "output/Sim_Results")

        idf_directory = idf_config["output_dir"]
        iddfile       = idf_config["iddfile"]

        simulate_all(
            df_buildings=df_buildings,
            idf_directory=idf_directory,
            iddfile=iddfile,
            base_output_dir=sim_output_dir,
            user_config_epw=user_config_epw,
            assigned_epw_log=assigned_epw_log,
            num_workers=simulate_config.get("num_workers", 4)
            # ep_force_overwrite=simulate_config.get("ep_force_overwrite", False)
        )

    # D) Post-processing
    if post_process:
        logger.info("[create_idfs_for_all_buildings] => Post-processing results & writing logs ...")

        if post_process_config is None:
            post_process_config = {
                "base_output_dir": "output/Sim_Results",
                "outputs": [
                    {
                        "convert_to_daily": False,
                        "convert_to_monthly": False,
                        "aggregator": "none",
                        "output_csv": "output/results/merged_as_is.csv"
                    }
                ]
            }

        # If logs_base_dir is set, we override base_output_dir
        if logs_base_dir:
            post_process_config["base_output_dir"] = os.path.join(logs_base_dir, "Sim_Results")

        base_output_dir = post_process_config.get("base_output_dir", "output/Sim_Results")
        multiple_outputs = post_process_config.get("outputs", [])

        # Possibly handle multiple post-process outputs
        for proc_item in multiple_outputs:
            convert_daily = proc_item.get("convert_to_daily", False)
            convert_monthly = proc_item.get("convert_to_monthly", False)
            aggregator = proc_item.get("aggregator", "mean")  # daily aggregator
            out_csv = proc_item.get("output_csv", "output/results/merged_default.csv")

            # If logs_base_dir is set and the out_csv is still something like "output/results/..."
            # We can relocate it under logs_base_dir, e.g. logs_base_dir/results
            # Let's do a check:
            if logs_base_dir and "output/" in out_csv:
                # redirect to logs_base_dir
                # e.g. logs_base_dir/results/merged_default.csv
                # you can pick your subfolder naming
                rel_filename = out_csv.split("output/")[-1]  # e.g. results/merged_default.csv
                out_csv = os.path.join(logs_base_dir, rel_filename)

            # Make sure directory exists
            os.makedirs(os.path.dirname(out_csv), exist_ok=True)

            # Now merge the results
            merge_all_results(
                base_output_dir=base_output_dir,
                output_csv=out_csv,
                convert_to_daily=convert_daily,
                daily_aggregator=aggregator,
                convert_to_monthly=convert_monthly
            )

        # Write CSV logs for assigned parameters
        _write_geometry_csv(assigned_geom_log, logs_base_dir)
        _write_lighting_csv(assigned_lighting_log, logs_base_dir)
        _write_equipment_csv(assigned_equip_log, logs_base_dir)
        _write_fenestration_csv(assigned_fenez_log, logs_base_dir)
        _write_dhw_csv(assigned_dhw_log, logs_base_dir)
        _write_hvac_csv(assigned_hvac_log, logs_base_dir)
        _write_vent_csv(assigned_vent_log, logs_base_dir)
        # (If needed, also EPW or groundtemp logs, do similarly)

        logger.info("[create_idfs_for_all_buildings] => Done post-processing.")

    return df_buildings  # includes "idf_name" column


###############################################################################
# Internal Helper Functions to Write Assigned Logs
# -- Now accept logs_base_dir so we can place them in job_output_dir
###############################################################################
def _make_assigned_path(filename, logs_base_dir):
    """Helper to build the path for assigned_*.csv, given logs_base_dir."""
    if logs_base_dir:
        assigned_dir = os.path.join(logs_base_dir, "assigned")
    else:
        assigned_dir = "output/assigned"

    os.makedirs(assigned_dir, exist_ok=True)
    return os.path.join(assigned_dir, filename)


def _write_geometry_csv(assigned_geom_log, logs_base_dir):
    rows = []
    for bldg_id, param_dict in assigned_geom_log.items():
        for param_name, param_val in param_dict.items():
            rows.append({
                "ogc_fid": bldg_id,
                "param_name": param_name,
                "assigned_value": param_val
            })
    if not rows:
        return
    df = pd.DataFrame(rows)
    out_path = _make_assigned_path("assigned_geometry.csv", logs_base_dir)
    df.to_csv(out_path, index=False)


def _write_lighting_csv(assigned_lighting_log, logs_base_dir):
    rows = []
    for bldg_id, param_dict in assigned_lighting_log.items():
        for param_name, subdict in param_dict.items():
            assigned_val = subdict.get("assigned_value")
            min_v = subdict.get("min_val")
            max_v = subdict.get("max_val")
            obj_name = subdict.get("object_name", "")
            rows.append({
                "ogc_fid": bldg_id,
                "object_name": obj_name,
                "param_name": param_name,
                "assigned_value": assigned_val,
                "min_val": min_v,
                "max_val": max_v
            })
    if not rows:
        return
    df = pd.DataFrame(rows)
    out_path = _make_assigned_path("assigned_lighting.csv", logs_base_dir)
    df.to_csv(out_path, index=False)


def _write_fenestration_csv(assigned_fenez_log, logs_base_dir):
    rows = []
    for bldg_id, param_dict in assigned_fenez_log.items():
        for key, val in param_dict.items():
            rows.append({
                "ogc_fid": bldg_id,
                "param_name": key,
                "assigned_value": val
            })
    if not rows:
        return
    df = pd.DataFrame(rows)
    out_path = _make_assigned_path("assigned_fenez_params.csv", logs_base_dir)
    df.to_csv(out_path, index=False)


def _write_dhw_csv(assigned_dhw_log, logs_base_dir):
    rows = []
    for bldg_id, param_dict in assigned_dhw_log.items():
        for param_name, param_val in param_dict.items():
            rows.append({
                "ogc_fid": bldg_id,
                "param_name": param_name,
                "assigned_value": param_val
            })
    if not rows:
        return
    df = pd.DataFrame(rows)
    out_path = _make_assigned_path("assigned_dhw_params.csv", logs_base_dir)
    df.to_csv(out_path, index=False)


def _write_hvac_csv(assigned_hvac_log, logs_base_dir):
    rows = []
    for bldg_id, param_dict in assigned_hvac_log.items():
        for param_name, param_val in param_dict.items():
            rows.append({
                "ogc_fid": bldg_id,
                "param_name": param_name,
                "assigned_value": param_val
            })
    if not rows:
        return
    df = pd.DataFrame(rows)
    out_path = _make_assigned_path("assigned_hvac_params.csv", logs_base_dir)
    df.to_csv(out_path, index=False)


def _write_vent_csv(assigned_vent_log, logs_base_dir):
    rows = []
    for bldg_id, param_dict in assigned_vent_log.items():
        for param_name, param_val in param_dict.items():
            rows.append({
                "ogc_fid": bldg_id,
                "param_name": param_name,
                "assigned_value": param_val
            })
    if not rows:
        return
    df = pd.DataFrame(rows)
    out_path = _make_assigned_path("assigned_ventilation.csv", logs_base_dir)
    df.to_csv(out_path, index=False)


def _write_equipment_csv(assigned_equip_log, logs_base_dir):
    rows = []
    for bldg_id, param_dict in assigned_equip_log.items():
        for param_name, param_val in param_dict.items():
            rows.append({
                "ogc_fid": bldg_id,
                "param_name": param_name,
                "assigned_value": param_val,
            })
    if not rows:
        return
    df = pd.DataFrame(rows)
    out_path = _make_assigned_path("assigned_equipment.csv", logs_base_dir)
    df.to_csv(out_path, index=False)

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\main_modifi.py
============================================================
"""
main_modifi.py

Handles the generation of scenario-based IDFs for sensitivity, surrogate,
calibration, or any parametric runs, then optionally runs E+ simulation,
post-processing, and validation in a job-specific folder if provided.

Usage:
  - Typically invoked from your orchestrator (or command line) with a config dict:
    {
      "base_idf_path": "output_IDFs/building_0.idf",
      "idd_path": "EnergyPlus/Energy+.idd",
      "assigned_csv": {
        "hvac_building": "output/assigned/assigned_hvac_building.csv",
        "hvac_zones": "output/assigned/assigned_hvac_zones.csv",
        "dhw": "output/assigned/assigned_dhw_params.csv",
        "vent_build": "output/assigned/assigned_vent_building.csv",
        "vent_zones": "output/assigned/assigned_vent_zones.csv",
        "elec": "output/assigned/assigned_lighting.csv",
        "fenez": "output/assigned/structured_fenez_params.csv"
      },
      "scenario_csv": {
        "hvac": "output/scenarios/scenario_params_hvac.csv",
        "dhw": "output/scenarios/scenario_params_dhw.csv",
        "vent": "output/scenarios/scenario_params_vent.csv",
        "elec": "output/scenarios/scenario_params_elec.csv",
        "fenez": "output/scenarios/scenario_params_fenez.csv"
      },
      "output_idf_dir": "output/scenario_idfs",
      "building_id": 4136730,
      "num_scenarios": 5,
      "picking_method": "random_uniform",
      "picking_scale_factor": 0.5,

      "run_simulations": true,
      "simulation_config": {
        "num_workers": 4,
        "output_dir": "output/Sim_Results/Scenarios"
      },
      "perform_post_process": true,
      "post_process_config": {
        "output_csv_as_is": "output/results_scenarioes/merged_as_is_scenarios.csv",
        "output_csv_daily_mean": "output/results_scenarioes/merged_daily_mean_scenarios.csv"
      },
      "perform_validation": true,
      "validation_config": {
        "real_data_csv": "data/mock_merged_daily_mean.csv",
        "sim_data_csv": "output/results_scenarioes/merged_daily_mean_scenarios.csv",
        "bldg_ranges": { "0": [0,1,2] },
        "variables_to_compare": [...],
        "threshold_cv_rmse": 30.0,
        "skip_plots": true,
        "output_csv": "scenario_validation_report.csv"
      },

      "job_output_dir": "/usr/src/app/output/xxxx-uuid"   # (Optional)
    }
"""

import os
import logging
import pandas as pd

# ---------------------------------------------------------------------------
# A) Common Utilities
# ---------------------------------------------------------------------------
from modification.common_utils import (
    load_assigned_csv,
    load_scenario_csv,
    load_idf,
    save_idf,
    generate_multiple_param_sets,
    save_param_scenarios_to_csv
)

# ---------------------------------------------------------------------------
# B) Modules for scenario creation & application
# ---------------------------------------------------------------------------
from modification.hvac_functions import (
    create_hvac_scenarios,
    apply_building_level_hvac,
    apply_zone_level_hvac
)
from modification.dhw_functions import (
    create_dhw_scenarios,
    apply_dhw_params_to_idf
)
from modification.vent_functions import (
    create_vent_scenarios,
    apply_building_level_vent,
    apply_zone_level_vent
)
from modification.elec_functions import (
    create_elec_scenarios,
    apply_building_level_elec,
    apply_object_level_elec
)
from modification.fenez_functions2 import (
    create_fenez_scenarios,
    apply_object_level_fenez
)

# ---------------------------------------------------------------------------
# C) Simulation + Post-processing + Validation
# ---------------------------------------------------------------------------
from epw.run_epw_sims import simulate_all
from postproc.merge_results import merge_all_results
from validation.main_validation import run_validation_process


def run_all_idfs_in_folder(
    folder_path: str,
    iddfile: str,
    base_output_dir: str,
    default_lat: float = 52.15,
    default_lon: float = 4.40,
    default_year: int = 2020,
    num_workers: int = 4
):
    """
    Utility function to find .idf files in folder_path and run them with simulate_all(...).
    Adjust lat/lon/year or load them from a side CSV if needed.
    """
    logger = logging.getLogger(__name__)
    logger.info(f"[run_all_idfs_in_folder] Searching .idf files in {folder_path}")

    if not os.path.isdir(folder_path):
        logger.warning(f"[run_all_idfs_in_folder] Folder not found => {folder_path}")
        return

    idf_files = [f for f in os.listdir(folder_path) if f.lower().endswith(".idf")]
    if not idf_files:
        logger.warning(f"[run_all_idfs_in_folder] No .idf files in {folder_path} to run.")
        return

    data_rows = []
    for idx, idf_name in enumerate(idf_files):
        data_rows.append({
            "idf_name": idf_name,
            "lat": default_lat,
            "lon": default_lon,
            "desired_climate_year": default_year,
            "ogc_fid": idx  # or parse from filename
        })

    df_scenarios = pd.DataFrame(data_rows)
    logger.info(f"[run_all_idfs_in_folder] Running {len(df_scenarios)} scenario IDFs with simulate_all...")

    simulate_all(
        df_buildings=df_scenarios,
        idf_directory=folder_path,
        iddfile=iddfile,
        base_output_dir=base_output_dir,
        user_config_epw=None,
        assigned_epw_log=None,
        num_workers=num_workers
    )
    logger.info("[run_all_idfs_in_folder] Simulations triggered.")


def run_modification_workflow(config):
    """
    Main function for scenario-based IDF creation + optional E+ simulation,
    post-processing, and validation.

    Steps:
      1) Resolve folder paths (scenario IDFs, results) based on config + optional job_output_dir.
      2) Load assigned CSV data (HVAC, DHW, Vent, Elec, Fenez).
      3) Filter for the chosen building.
      4) Generate scenario param picks (random or otherwise).
      5) For each scenario, load a fresh base IDF, apply picks, save scenario IDF.
      6) (Optional) run E+ sims for these scenario IDFs, then post-process, then validate.

    :param config: dict
    :return: None
    """
    logger = logging.getLogger(__name__)
    logger.info("[MODIFICATION] Starting scenario-based workflow...")

    # -----------------------------------------------------------------------
    # 1) Extract config parts & resolve paths
    # -----------------------------------------------------------------------
    base_idf_path   = config["base_idf_path"]
    idd_path        = config["idd_path"]
    assigned_csvs   = config["assigned_csv"]
    scenario_csvs   = config["scenario_csv"]
    building_id     = config["building_id"]
    num_scenarios   = config["num_scenarios"]
    picking_method  = config["picking_method"]
    scale_factor    = config.get("picking_scale_factor", 1.0)

    # The user might specify something like "output/scenario_idfs" or just "scenario_idfs".
    scenario_idf_dir = config.get("output_idf_dir", "output/scenario_idfs")

    # Also we have simulation, post-processing, and validation flags:
    run_sims        = config.get("run_simulations", False)
    sim_cfg         = config.get("simulation_config", {})
    do_postproc     = config.get("perform_post_process", False)
    postproc_cfg    = config.get("post_process_config", {})
    do_validation   = config.get("perform_validation", False)
    validation_cfg  = config.get("validation_config", {})

    # If "job_output_dir" is provided, make scenario_idf_dir relative to it (if it's not absolute).
    job_output_dir = config.get("job_output_dir")  # optional
    if job_output_dir and not os.path.isabs(scenario_idf_dir):
        scenario_idf_dir = os.path.join(job_output_dir, scenario_idf_dir)
    os.makedirs(scenario_idf_dir, exist_ok=True)

    logger.info(f"[MODIFICATION] Scenario IDFs will be placed in: {scenario_idf_dir}")

    # -----------------------------------------------------------------------
    # 2) Load assigned CSV data
    # -----------------------------------------------------------------------
    # HVAC
    df_hvac_bld = None
    df_hvac_zn  = None
    if "hvac_building" in assigned_csvs and "hvac_zones" in assigned_csvs:
        df_hvac_bld = load_assigned_csv(assigned_csvs["hvac_building"])
        df_hvac_zn  = load_assigned_csv(assigned_csvs["hvac_zones"])
    elif "hvac" in assigned_csvs:
        df_hvac_bld = load_assigned_csv(assigned_csvs["hvac"])

    # DHW
    df_dhw = load_assigned_csv(assigned_csvs["dhw"]) if "dhw" in assigned_csvs else None

    # Vent
    df_vent_bld = None
    df_vent_zn  = None
    if "vent_build" in assigned_csvs and "vent_zones" in assigned_csvs:
        df_vent_bld = load_assigned_csv(assigned_csvs["vent_build"])
        df_vent_zn  = load_assigned_csv(assigned_csvs["vent_zones"])
    elif "vent" in assigned_csvs:
        df_vent_bld = load_assigned_csv(assigned_csvs["vent"])

    # Elec
    df_elec  = load_assigned_csv(assigned_csvs["elec"])  if "elec"  in assigned_csvs else None

    # Fenestration
    df_fenez = load_assigned_csv(assigned_csvs["fenez"]) if "fenez" in assigned_csvs else None

    # -----------------------------------------------------------------------
    # 3) Filter data for this building
    # -----------------------------------------------------------------------
    def filter_for_building(df):
        if df is not None and not df.empty:
            return df[df["ogc_fid"] == building_id].copy()
        return pd.DataFrame()

    df_hvac_bld_sub = filter_for_building(df_hvac_bld)
    df_hvac_zn_sub  = filter_for_building(df_hvac_zn)
    df_dhw_sub      = filter_for_building(df_dhw)
    df_vent_bld_sub = filter_for_building(df_vent_bld)
    df_vent_zn_sub  = filter_for_building(df_vent_zn)
    df_elec_sub     = filter_for_building(df_elec)
    df_fenez_sub    = filter_for_building(df_fenez)

    # -----------------------------------------------------------------------
    # 4) Generate scenario picks (random or otherwise)
    # -----------------------------------------------------------------------
    # HVAC
    if not df_hvac_bld_sub.empty:
        if not df_hvac_zn_sub.empty:
            # multi-step scenario creation for building & zone
            create_hvac_scenarios(
                df_building=df_hvac_bld_sub,
                df_zones=df_hvac_zn_sub,
                building_id=building_id,
                num_scenarios=num_scenarios,
                picking_method=picking_method,
                random_seed=42,
                scenario_csv_out=scenario_csvs["hvac"]
            )
        else:
            hvac_scen = generate_multiple_param_sets(
                df_main_sub=df_hvac_bld_sub,
                num_sets=num_scenarios,
                picking_method=picking_method,
                scale_factor=scale_factor
            )
            save_param_scenarios_to_csv(hvac_scen, building_id, scenario_csvs["hvac"])

    # DHW
    if not df_dhw_sub.empty:
        create_dhw_scenarios(
            df_dhw_input=df_dhw_sub,
            building_id=building_id,
            num_scenarios=num_scenarios,
            picking_method=picking_method,
            random_seed=42,
            scenario_csv_out=scenario_csvs["dhw"]
        )

    # Vent
    if not df_vent_bld_sub.empty or not df_vent_zn_sub.empty:
        create_vent_scenarios(
            df_building=df_vent_bld_sub,
            df_zones=df_vent_zn_sub,
            building_id=building_id,
            num_scenarios=num_scenarios,
            picking_method=picking_method,
            random_seed=42,
            scenario_csv_out=scenario_csvs["vent"]
        )

    # Elec
    if not df_elec_sub.empty:
        create_elec_scenarios(
            df_lighting=df_elec_sub,
            building_id=building_id,
            num_scenarios=num_scenarios,
            picking_method=picking_method,
            random_seed=42,
            scenario_csv_out=scenario_csvs["elec"]
        )

    # Fenestration
    if not df_fenez_sub.empty:
        create_fenez_scenarios(
            df_struct_fenez=df_fenez_sub,
            building_id=building_id,
            num_scenarios=num_scenarios,
            picking_method=picking_method,
            random_seed=42,
            scenario_csv_out=scenario_csvs["fenez"]
        )

    # -----------------------------------------------------------------------
    # 5) Load scenario CSV => group by scenario_index
    # -----------------------------------------------------------------------
    def safe_load_scenario(csv_path):
        if os.path.isfile(csv_path):
            return load_scenario_csv(csv_path)
        return pd.DataFrame()

    df_hvac_scen  = safe_load_scenario(scenario_csvs["hvac"])
    df_dhw_scen   = safe_load_scenario(scenario_csvs["dhw"])
    df_vent_scen  = safe_load_scenario(scenario_csvs["vent"])
    df_elec_scen  = safe_load_scenario(scenario_csvs["elec"])
    df_fenez_scen = safe_load_scenario(scenario_csvs["fenez"])

    hvac_groups  = df_hvac_scen.groupby("scenario_index")  if not df_hvac_scen.empty  else None
    dhw_groups   = df_dhw_scen.groupby("scenario_index")   if not df_dhw_scen.empty   else None
    vent_groups  = df_vent_scen.groupby("scenario_index")  if not df_vent_scen.empty  else None
    elec_groups  = df_elec_scen.groupby("scenario_index")  if not df_elec_scen.empty  else None
    fenez_groups = df_fenez_scen.groupby("scenario_index") if not df_fenez_scen.empty else None

    # -----------------------------------------------------------------------
    # 6) For each scenario, load base IDF, apply parameters, save new IDF
    # -----------------------------------------------------------------------
    for i in range(num_scenarios):
        logger.info(f"[MODIFICATION] => Creating scenario #{i} for building {building_id}")

        hvac_df   = hvac_groups.get_group(i) if hvac_groups and i in hvac_groups.groups else pd.DataFrame()
        dhw_df    = dhw_groups.get_group(i)  if dhw_groups  and i in dhw_groups.groups  else pd.DataFrame()
        vent_df   = vent_groups.get_group(i) if vent_groups and i in vent_groups.groups else pd.DataFrame()
        elec_df   = elec_groups.get_group(i) if elec_groups and i in elec_groups.groups else pd.DataFrame()
        fenez_df  = fenez_groups.get_group(i)if fenez_groups and i in fenez_groups.groups else pd.DataFrame()

        hvac_bld_df   = hvac_df[hvac_df["zone_name"].isna()]
        hvac_zone_df  = hvac_df[hvac_df["zone_name"].notna()]
        hvac_params   = _make_param_dict(hvac_bld_df)

        dhw_params    = _make_param_dict(dhw_df)

        vent_bld_df   = vent_df[vent_df["zone_name"].isnull()]
        vent_zone_df  = vent_df[vent_df["zone_name"].notnull()]
        vent_params   = _make_param_dict(vent_bld_df)

        elec_params   = _make_param_dict(elec_df)

        # Load base IDF
        idf = load_idf(base_idf_path, idd_path)

        # Apply HVAC
        apply_building_level_hvac(idf, hvac_params)
        apply_zone_level_hvac(idf, hvac_zone_df)

        # Apply DHW
        apply_dhw_params_to_idf(idf, dhw_params, suffix=f"Scenario_{i}")

        # Apply Vent
        if not vent_bld_df.empty or not vent_zone_df.empty:
            apply_building_level_vent(idf, vent_params)
            apply_zone_level_vent(idf, vent_zone_df)

        # Apply Elec => building-level or object-level
        if not elec_df.empty:
            apply_building_level_elec(idf, elec_params, zonelist_name="ALL_ZONES")
            # or use apply_object_level_elec(idf, elec_df) if you prefer

        # Apply Fenestration => object-level
        apply_object_level_fenez(idf, fenez_df)

        # Save scenario IDF
        scenario_idf_name = f"building_{building_id}_scenario_{i}.idf"
        scenario_idf_path = os.path.join(scenario_idf_dir, scenario_idf_name)
        save_idf(idf, scenario_idf_path)
        logger.info(f"[MODIFICATION] Saved scenario IDF => {scenario_idf_path}")

    logger.info("[MODIFICATION] All scenario IDFs generated successfully.")

    # -----------------------------------------------------------------------
    # 7) (Optional) Simulations
    # -----------------------------------------------------------------------
    if run_sims:
        logger.info("[MODIFICATION] Running E+ simulations for all scenario IDFs.")
        base_sim_dir = sim_cfg.get("output_dir", "output/Sim_Results/Scenarios")

        # if job_output_dir is given, we can make the sim results go inside it, too:
        if job_output_dir and not os.path.isabs(base_sim_dir):
            base_sim_dir = os.path.join(job_output_dir, base_sim_dir)
        os.makedirs(base_sim_dir, exist_ok=True)

        num_workers  = sim_cfg.get("num_workers", 4)

        run_all_idfs_in_folder(
            folder_path=scenario_idf_dir,
            iddfile=idd_path,
            base_output_dir=base_sim_dir,
            default_lat=52.15,
            default_lon=4.40,
            default_year=2020,
            num_workers=num_workers
        )

    # -----------------------------------------------------------------------
    # 8) (Optional) Post-processing
    # -----------------------------------------------------------------------
    if do_postproc:
        logger.info("[MODIFICATION] Performing post-processing merges.")

        base_sim_dir = sim_cfg.get("output_dir", "output/Sim_Results/Scenarios")
        if job_output_dir and not os.path.isabs(base_sim_dir):
            base_sim_dir = os.path.join(job_output_dir, base_sim_dir)

        output_csv_as_is = postproc_cfg.get("output_csv_as_is", "")
        output_csv_daily_mean = postproc_cfg.get("output_csv_daily_mean", "")

        # Build full paths inside job_output_dir if they are relative
        if output_csv_as_is:
            if job_output_dir and not os.path.isabs(output_csv_as_is):
                output_csv_as_is = os.path.join(job_output_dir, output_csv_as_is)
            os.makedirs(os.path.dirname(output_csv_as_is), exist_ok=True)

            merge_all_results(
                base_output_dir=base_sim_dir,
                output_csv=output_csv_as_is,
                convert_to_daily=False,
                convert_to_monthly=False
            )

        if output_csv_daily_mean:
            if job_output_dir and not os.path.isabs(output_csv_daily_mean):
                output_csv_daily_mean = os.path.join(job_output_dir, output_csv_daily_mean)
            os.makedirs(os.path.dirname(output_csv_daily_mean), exist_ok=True)

            merge_all_results(
                base_output_dir=base_sim_dir,
                output_csv=output_csv_daily_mean,
                convert_to_daily=True,
                daily_aggregator="mean",
                convert_to_monthly=False
            )

        logger.info("[MODIFICATION] Post-processing step complete.")

    # -----------------------------------------------------------------------
    # 9) (Optional) Validation
    # -----------------------------------------------------------------------
    if do_validation:
        logger.info("[MODIFICATION] Performing scenario validation with config => %s", validation_cfg)

        # If the validation config references CSV paths that might be relative,
        # you could also adjust them to be inside job_output_dir here if desired.
        # e.g.:
        # real_csv = validation_cfg.get("real_data_csv", "")
        # if job_output_dir and not os.path.isabs(real_csv):
        #     real_csv = os.path.join(job_output_dir, real_csv)
        # validation_cfg["real_data_csv"] = real_csv

        run_validation_process(validation_cfg)
        logger.info("[MODIFICATION] Validation step complete.")


def _make_param_dict(df_scenario):
    """
    Builds a dict {param_name: value} from the scenario DataFrame columns,
    checking 'assigned_value' or 'param_value'.
    """
    if df_scenario.empty:
        return {}

    cols = df_scenario.columns.tolist()
    if "assigned_value" in cols:
        val_col = "assigned_value"
    elif "param_value" in cols:
        val_col = "param_value"
    else:
        raise AttributeError(
            "No 'assigned_value' or 'param_value' column found in scenario dataframe! "
            f"Columns are: {cols}"
        )

    result = {}
    for row in df_scenario.itertuples():
        p_name = row.param_name
        raw_val = getattr(row, val_col)
        try:
            result[p_name] = float(raw_val)
        except (ValueError, TypeError):
            result[p_name] = raw_val
    return result

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\orchestrator.py
============================================================
"""
orchestrator.py

Orchestrates the entire EnergyPlus workflow using a job-specific subfolder
for config files and a job-specific folder in /output for results.

Steps:
  1. Retrieve 'job_id' from job_config (set by job_manager or app).
  2. Form an output directory: <OUTPUT_DIR>/<job_id>.
  3. Load main_config.json from user_configs/<job_id>.
  4. Merge with posted_data["main_config"] if present.
  5. Apply Excel overrides, JSON overrides, create IDFs, run sims, etc.
  6. If scenario modification is enabled, override paths so scenario IDFs/results
     stay in the same job folder, then run scenario-based modifications.
  7. Perform structuring (e.g., flatten assigned CSVs) if requested.
  8. Perform global validation, sensitivity, surrogate, calibration if requested;
     patch any relative CSV paths to be inside the job folder (unless "data/").
  9. Zip & email final results if mail_user.json is present.
  10. Respect any cancel_event from job_manager.
"""

import os
import json
import logging
import threading
import pandas as pd

# Splitting / deep-merge
from splitter import deep_merge_dicts

# DB loading if needed
from database_handler import load_buildings_from_db

# Excel overrides
from excel_overrides import (
    override_dhw_lookup_from_excel_file,
    override_epw_lookup_from_excel_file,
    override_lighting_lookup_from_excel_file,
    override_hvac_lookup_from_excel_file,
    override_vent_lookup_from_excel_file
)

# Fenestration config
from idf_objects.fenez.fenez_config_manager import build_fenez_config

# IDF creation
import idf_creation
from idf_creation import create_idfs_for_all_buildings

# Scenario modification
from main_modifi import run_modification_workflow

# Validation
from validation.main_validation import run_validation_process

# Sensitivity / Surrogate / Calibration
from cal.unified_sensitivity import run_sensitivity_analysis
from cal.unified_surrogate import (
    load_scenario_params as sur_load_scenario_params,
    pivot_scenario_params,
    load_sim_results,
    aggregate_results,
    merge_params_with_results,
    build_and_save_surrogate
)
from cal.unified_calibration import run_unified_calibration

# Zip & email
from zip_and_mail import zip_user_output, send_results_email

from cleanup_old_jobs import cleanup_old_results


class WorkflowCanceled(Exception):
    """Custom exception used to stop the workflow if a cancel_event is set."""
    pass


def orchestrate_workflow(job_config: dict, cancel_event: threading.Event = None):
    """
    Orchestrates the entire E+ workflow using a job-specific subfolder for config JSON,
    plus a job-specific output folder for results.

    Args:
        job_config (dict): includes:
            {
              "job_id": "<unique_id_for_this_job>",
              "job_subfolder": "user_configs/<job_id>",
              "posted_data": {...} (optional),
              ...
            }
        cancel_event (threading.Event): If set, we gracefully exit early.

    Raises:
        WorkflowCanceled if cancel_event is set mid-way.

    Returns:
        None (logs extensively, optionally zips/emails final results).
    """
    logger = logging.getLogger(__name__)
    logger.info("=== Starting orchestrate_workflow ===")

    # -------------------------------------------------------------------------
    # 0) Identify job_id, define check_canceled
    # -------------------------------------------------------------------------
    job_id = job_config.get("job_id", "unknown_job_id")
    logger.info(f"[INFO] Orchestrator for job_id={job_id}")

    def check_canceled():
        """Raise WorkflowCanceled if cancel_event is set."""
        if cancel_event and cancel_event.is_set():
            logger.warning("=== CANCEL event detected. Stopping workflow. ===")
            raise WorkflowCanceled("Workflow was canceled by user request.")

    # -------------------------------------------------------------------------
    # 1) Identify the user_configs folder (where main_config.json resides)
    # -------------------------------------------------------------------------
    user_configs_folder = job_config.get("job_subfolder")
    if not user_configs_folder or not os.path.isdir(user_configs_folder):
        logger.error(f"[ERROR] job_subfolder not found or invalid => {user_configs_folder}")
        return

    # -------------------------------------------------------------------------
    # 2) Build an output directory for this job under OUTPUT_DIR
    #    e.g. /usr/src/app/output/<job_id>
    # -------------------------------------------------------------------------
    env_out_dir = os.environ.get("OUTPUT_DIR", "/usr/src/app/output")
    job_output_dir = os.path.join(env_out_dir, job_id)
    os.makedirs(job_output_dir, exist_ok=True)
    logger.info(f"[INFO] Using job-specific output folder: {job_output_dir}")

    # -------------------------------------------------------------------------
    # 3) Load main_config.json from user_configs/<job_id>
    # -------------------------------------------------------------------------
    main_config_path = os.path.join(user_configs_folder, "main_config.json")
    if not os.path.isfile(main_config_path):
        logger.error(f"[ERROR] Cannot find main_config.json at {main_config_path}")
        return

    with open(main_config_path, "r") as f:
        existing_config_raw = json.load(f)
    main_config = existing_config_raw.get("main_config", {})
    logger.info(f"[INFO] Loaded existing main_config from {main_config_path}.")

    # Merge posted_data["main_config"] if present
    posted_data = job_config.get("posted_data", {})
    if "main_config" in posted_data:
        logger.info("[INFO] Deep merging posted_data['main_config'] into main_config.")
        deep_merge_dicts(main_config, posted_data["main_config"])
        # optionally re-save
        with open(main_config_path, "w") as f:
            json.dump({"main_config": main_config}, f, indent=2)

    # -------------------------------------------------------------------------
    # 4) Extract sub-sections from main_config
    # -------------------------------------------------------------------------
    check_canceled()
    paths_dict       = main_config.get("paths", {})
    excel_flags      = main_config.get("excel_overrides", {})
    user_flags       = main_config.get("user_config_overrides", {})
    def_dicts        = main_config.get("default_dicts", {})
    structuring_cfg  = main_config.get("structuring", {})
    modification_cfg = main_config.get("modification", {})
    validation_cfg   = main_config.get("validation", {})
    sens_cfg         = main_config.get("sensitivity", {})
    sur_cfg          = main_config.get("surrogate", {})
    cal_cfg          = main_config.get("calibration", {})

    # IDF creation block
    idf_cfg = main_config.get("idf_creation", {})
    perform_idf_creation = idf_cfg.get("perform_idf_creation", False)
    scenario             = idf_cfg.get("scenario", "scenario1")
    calibration_stage    = idf_cfg.get("calibration_stage", "pre_calibration")
    strategy             = idf_cfg.get("strategy", "B")
    random_seed          = idf_cfg.get("random_seed", 42)
    run_simulations      = idf_cfg.get("run_simulations", True)
    simulate_config      = idf_cfg.get("simulate_config", {})
    post_process         = idf_cfg.get("post_process", True)
    post_process_config  = idf_cfg.get("post_process_config", {})
    output_definitions   = idf_cfg.get("output_definitions", {})
    use_database         = main_config.get("use_database", False)
    db_filter            = main_config.get("db_filter", {})
    filter_by            = main_config.get("filter_by")  # if using DB

    # -------------------------------------------------------------------------
    # 5) Possibly override idf_creation.idf_config from env, then force IDFs
    #    to go in <job_output_dir>/output_IDFs
    # -------------------------------------------------------------------------
    check_canceled()

    env_idd_path = os.environ.get("IDD_PATH")
    if env_idd_path:
        idf_creation.idf_config["iddfile"] = env_idd_path
    env_base_idf = os.environ.get("BASE_IDF_PATH")
    if env_base_idf:
        idf_creation.idf_config["idf_file_path"] = env_base_idf

    job_idf_dir = os.path.join(job_output_dir, "output_IDFs")
    os.makedirs(job_idf_dir, exist_ok=True)
    idf_creation.idf_config["output_dir"] = job_idf_dir

    # If user explicitly set these in main_config, override again
    if "iddfile" in idf_cfg:
        idf_creation.idf_config["iddfile"] = idf_cfg["iddfile"]
    if "idf_file_path" in idf_cfg:
        idf_creation.idf_config["idf_file_path"] = idf_cfg["idf_file_path"]

    if "output_idf_dir" in idf_cfg:
        subfolder = idf_cfg["output_idf_dir"]  # e.g. "output_IDFs"
        full_dir = os.path.join(job_output_dir, subfolder)
        idf_creation.idf_config["output_dir"] = full_dir
    else:
        idf_creation.idf_config["output_dir"] = os.path.join(job_output_dir, "output_IDFs")

    # -------------------------------------------------------------------------
    # 6) Setup default dictionaries
    # -------------------------------------------------------------------------
    base_res_data    = def_dicts.get("res_data", {})
    base_nonres_data = def_dicts.get("nonres_data", {})
    dhw_lookup       = def_dicts.get("dhw", {})
    epw_lookup       = def_dicts.get("epw", [])
    lighting_lookup  = def_dicts.get("lighting", {})
    hvac_lookup      = def_dicts.get("hvac", {})
    vent_lookup      = def_dicts.get("vent", {})

    # -------------------------------------------------------------------------
    # 7) Apply Excel overrides if flags are set
    # -------------------------------------------------------------------------
    check_canceled()

    updated_res_data, updated_nonres_data = build_fenez_config(
        base_res_data=base_res_data,
        base_nonres_data=base_nonres_data,
        excel_path=paths_dict.get("fenez_excel", ""),
        do_excel_override=excel_flags.get("override_fenez_excel", False),
        user_fenez_overrides=[]
    )

    if excel_flags.get("override_dhw_excel", False):
        dhw_lookup = override_dhw_lookup_from_excel_file(
            dhw_excel_path=paths_dict.get("dhw_excel", ""),
            default_dhw_lookup=dhw_lookup,
            override_dhw_flag=True
        )

    if excel_flags.get("override_epw_excel", False):
        epw_lookup = override_epw_lookup_from_excel_file(
            epw_excel_path=paths_dict.get("epw_excel", ""),
            epw_lookup=epw_lookup,
            override_epw_flag=True
        )

    if excel_flags.get("override_lighting_excel", False):
        lighting_lookup = override_lighting_lookup_from_excel_file(
            lighting_excel_path=paths_dict.get("lighting_excel", ""),
            lighting_lookup=lighting_lookup,
            override_lighting_flag=True
        )

    if excel_flags.get("override_hvac_excel", False):
        hvac_lookup = override_hvac_lookup_from_excel_file(
            hvac_excel_path=paths_dict.get("hvac_excel", ""),
            hvac_lookup=hvac_lookup,
            override_hvac_flag=True
        )

    if excel_flags.get("override_vent_excel", False):
        vent_lookup = override_vent_lookup_from_excel_file(
            vent_excel_path=paths_dict.get("vent_excel", ""),
            vent_lookup=vent_lookup,
            override_vent_flag=True
        )

    # -------------------------------------------------------------------------
    # 8) JSON overrides from user_configs/<job_id> if user_flags are set
    # -------------------------------------------------------------------------
    check_canceled()

    def safe_load_subjson(fname, key):
        """
        Loads user_configs/<job_id>/fname if it exists, returns data.get(key).
        """
        full_path = os.path.join(user_configs_folder, fname)
        if os.path.isfile(full_path):
            try:
                with open(full_path, "r") as ff:
                    data = json.load(ff)
                return data.get(key)
            except Exception as e:
                logger.error(f"[ERROR] loading {fname} => {e}")
        return None

    # Fenestration
    user_fenez_data = []
    if user_flags.get("override_fenez_json", False):
        loaded = safe_load_subjson("fenestration.json", "fenestration")
        if loaded:
            user_fenez_data = loaded

    updated_res_data, updated_nonres_data = build_fenez_config(
        base_res_data=updated_res_data,
        base_nonres_data=updated_nonres_data,
        excel_path="",
        do_excel_override=False,
        user_fenez_overrides=user_fenez_data
    )

    # DHW
    user_config_dhw = None
    if user_flags.get("override_dhw_json", False):
        user_config_dhw = safe_load_subjson("dhw.json", "dhw")

    # EPW
    user_config_epw = []
    if user_flags.get("override_epw_json", False):
        e = safe_load_subjson("epw.json", "epw")
        if e:
            user_config_epw = e

    # Lighting
    user_config_lighting = None
    if user_flags.get("override_lighting_json", False):
        user_config_lighting = safe_load_subjson("lighting.json", "lighting")

    # HVAC
    user_config_hvac = None
    if user_flags.get("override_hvac_json", False):
        user_config_hvac = safe_load_subjson("hvac.json", "hvac")

    # Vent
    user_config_vent = []
    if user_flags.get("override_vent_json", False):
        v = safe_load_subjson("vent.json", "vent")
        if v:
            user_config_vent = v

    # Geometry
    geom_data = {}
    if user_flags.get("override_geometry_json", False):
        g = safe_load_subjson("geometry.json", "geometry")
        if g:
            geom_data["geometry"] = g

    # Shading
    shading_data = {}
    if user_flags.get("override_shading_json", False):
        s = safe_load_subjson("shading.json", "shading")
        if s:
            shading_data["shading"] = s

    # -------------------------------------------------------------------------
    # 9) IDF creation
    # -------------------------------------------------------------------------
    check_canceled()
    df_buildings = pd.DataFrame()

    if perform_idf_creation:
        logger.info("[INFO] IDF creation is ENABLED.")

        # a) Load building data
        if use_database:
            logger.info("[INFO] Loading building data from DB.")
            if not filter_by:
                raise ValueError("[ERROR] 'filter_by' must be specified when 'use_database' is True.")
            df_buildings = load_buildings_from_db(db_filter, filter_by)

            # Optionally save the raw DB buildings
            extracted_csv_path = os.path.join(job_output_dir, "extracted_buildings.csv")
            df_buildings.to_csv(extracted_csv_path, index=False)
            logger.info(f"[INFO] Saved extracted buildings to {extracted_csv_path}")

        else:
            bldg_data_path = paths_dict.get("building_data", "")
            if os.path.isfile(bldg_data_path):
                df_buildings = pd.read_csv(bldg_data_path)
            else:
                logger.warning(f"[WARN] building_data CSV not found => {bldg_data_path}")

        # b) Create IDFs & (optionally) run sims in job folder
        df_buildings = create_idfs_for_all_buildings(
            df_buildings=df_buildings,
            scenario=scenario,
            calibration_stage=calibration_stage,
            strategy=strategy,
            random_seed=random_seed,
            user_config_geom=geom_data.get("geometry", []),
            user_config_lighting=user_config_lighting,
            user_config_dhw=user_config_dhw,
            res_data=updated_res_data,
            nonres_data=updated_nonres_data,
            user_config_hvac=user_config_hvac,
            user_config_vent=user_config_vent,
            user_config_epw=user_config_epw,
            output_definitions=output_definitions,
            run_simulations=run_simulations,
            simulate_config=simulate_config,
            post_process=post_process,
            post_process_config=post_process_config,
            logs_base_dir=job_output_dir
        )

        # === Store the mapping (ogc_fid -> idf_name) so we can look it up later ===
        idf_map_csv = os.path.join(job_output_dir, "extracted_idf_buildings.csv")
        df_buildings.to_csv(idf_map_csv, index=False)
        logger.info(f"[INFO] Wrote building -> IDF map to {idf_map_csv}")

    else:
        logger.info("[INFO] Skipping IDF creation.")

    # -------------------------------------------------------------------------
    # 10) Perform structuring if requested
    # -------------------------------------------------------------------------
    check_canceled()
    if structuring_cfg.get("perform_structuring", False):
        logger.info("[INFO] Performing structuring ...")

        # Example: Fenestration
        from idf_objects.structuring.fenestration_structuring import transform_fenez_log_to_structured_with_ranges
        fenez_conf = structuring_cfg.get("fenestration", {})
        fenez_in   = fenez_conf.get("csv_in",  "assigned/assigned_fenez_params.csv")
        fenez_out  = fenez_conf.get("csv_out", "assigned/structured_fenez_params.csv")

        if not os.path.isabs(fenez_in):
            fenez_in = os.path.join(job_output_dir, fenez_in)
        if not os.path.isabs(fenez_out):
            fenez_out = os.path.join(job_output_dir, fenez_out)

        if os.path.isfile(fenez_in):
            transform_fenez_log_to_structured_with_ranges(csv_input=fenez_in, csv_output=fenez_out)
        else:
            logger.warning(f"[STRUCTURING] Fenestration input CSV not found => {fenez_in}")

        # Example: DHW
        from idf_objects.structuring.dhw_structuring import transform_dhw_log_to_structured
        dhw_conf = structuring_cfg.get("dhw", {})
        dhw_in   = dhw_conf.get("csv_in",  "assigned/assigned_dhw_params.csv")
        dhw_out  = dhw_conf.get("csv_out", "assigned/structured_dhw_params.csv")

        if not os.path.isabs(dhw_in):
            dhw_in = os.path.join(job_output_dir, dhw_in)
        if not os.path.isabs(dhw_out):
            dhw_out = os.path.join(job_output_dir, dhw_out)

        if os.path.isfile(dhw_in):
            transform_dhw_log_to_structured(dhw_in, dhw_out)
        else:
            logger.warning(f"[STRUCTURING] DHW input CSV not found => {dhw_in}")

        # Example: HVAC flatten
        from idf_objects.structuring.flatten_hvac import flatten_hvac_data, parse_assigned_value as parse_hvac
        hvac_conf = structuring_cfg.get("hvac", {})
        hvac_in   = hvac_conf.get("csv_in",  "assigned/assigned_hvac_params.csv")
        hvac_bld  = hvac_conf.get("build_out", "assigned/assigned_hvac_building.csv")
        hvac_zone = hvac_conf.get("zone_out",  "assigned/assigned_hvac_zones.csv")

        if not os.path.isabs(hvac_in):
            hvac_in = os.path.join(job_output_dir, hvac_in)
        if not os.path.isabs(hvac_bld):
            hvac_bld = os.path.join(job_output_dir, hvac_bld)
        if not os.path.isabs(hvac_zone):
            hvac_zone = os.path.join(job_output_dir, hvac_zone)

        if os.path.isfile(hvac_in):
            df_hvac = pd.read_csv(hvac_in)
            df_hvac["assigned_value"] = df_hvac["assigned_value"].apply(parse_hvac)
            flatten_hvac_data(
                df_input=df_hvac,
                out_build_csv=hvac_bld,
                out_zone_csv=hvac_zone
            )
        else:
            logger.warning(f"[STRUCTURING] HVAC input CSV not found => {hvac_in}")

        # Example: Vent flatten
        from idf_objects.structuring.flatten_assigned_vent import flatten_ventilation_data, parse_assigned_value as parse_vent
        vent_conf = structuring_cfg.get("vent", {})
        vent_in   = vent_conf.get("csv_in", "assigned/assigned_ventilation.csv")
        vent_bld  = vent_conf.get("build_out", "assigned/assigned_vent_building.csv")
        vent_zone = vent_conf.get("zone_out", "assigned/assigned_vent_zones.csv")

        if not os.path.isabs(vent_in):
            vent_in = os.path.join(job_output_dir, vent_in)
        if not os.path.isabs(vent_bld):
            vent_bld = os.path.join(job_output_dir, vent_bld)
        if not os.path.isabs(vent_zone):
            vent_zone = os.path.join(job_output_dir, vent_zone)

        if os.path.isfile(vent_in):
            df_vent = pd.read_csv(vent_in)
            df_vent["assigned_value"] = df_vent["assigned_value"].apply(parse_vent)
            flatten_ventilation_data(
                df_input=df_vent,
                out_build_csv=vent_bld,
                out_zone_csv=vent_zone
            )
        else:
            logger.warning(f"[STRUCTURING] Vent input CSV not found => {vent_in}")

    else:
        logger.info("[INFO] Skipping structuring.")

    # -------------------------------------------------------------------------
    # 11) Scenario Modification
    # -------------------------------------------------------------------------
    check_canceled()
    if modification_cfg.get("perform_modification", False):
        logger.info("[INFO] Scenario modification is ENABLED.")

        mod_cfg = modification_cfg["modify_config"]

        # 1) Ensure scenario IDFs go to <job_output_dir>/scenario_idfs
        scenario_idf_dir = os.path.join(job_output_dir, "scenario_idfs")
        os.makedirs(scenario_idf_dir, exist_ok=True)
        mod_cfg["output_idf_dir"] = scenario_idf_dir

        # 2) Ensure scenario sims => <job_output_dir>/Sim_Results/Scenarios
        if "simulation_config" in mod_cfg:
            sim_out = os.path.join(job_output_dir, "Sim_Results", "Scenarios")
            os.makedirs(sim_out, exist_ok=True)
            mod_cfg["simulation_config"]["output_dir"] = sim_out

        # 3) Post-process => <job_output_dir>/results_scenarioes
        if "post_process_config" in mod_cfg:
            ppcfg = mod_cfg["post_process_config"]
            as_is_csv = os.path.join(job_output_dir, "results_scenarioes", "merged_as_is_scenarios.csv")
            daily_csv = os.path.join(job_output_dir, "results_scenarioes", "merged_daily_mean_scenarios.csv")
            os.makedirs(os.path.dirname(as_is_csv), exist_ok=True)
            os.makedirs(os.path.dirname(daily_csv), exist_ok=True)
            ppcfg["output_csv_as_is"] = as_is_csv
            ppcfg["output_csv_daily_mean"] = daily_csv

        # 4) Fix assigned_csv paths
        assigned_csv_dict = mod_cfg.get("assigned_csv", {})
        for key, rel_path in assigned_csv_dict.items():
            assigned_csv_dict[key] = os.path.join(job_output_dir, rel_path)

        # 5) Fix scenario_csv paths
        scenario_csv_dict = mod_cfg.get("scenario_csv", {})
        for key, rel_path in scenario_csv_dict.items():
            scenario_csv_dict[key] = os.path.join(job_output_dir, rel_path)

        # ----------------------------------------------------------------------
        # NEW LOGIC: pick the base_idf_path from building_id automatically
        # ----------------------------------------------------------------------
        # The user sets "building_id" in the config, e.g. 20233330
        building_id = mod_cfg["building_id"]

        # We need the CSV that was saved right after create_idfs_for_all_buildings(...)
        idf_map_csv = os.path.join(job_output_dir, "extracted_idf_buildings.csv")
        if not os.path.isfile(idf_map_csv):
            raise FileNotFoundError(
                f"Cannot find building->IDF map CSV at {idf_map_csv}. "
                f"Did you skip 'perform_idf_creation'?"
            )

        # Read the mapping: each row has "ogc_fid" and "idf_name"
        df_idf_map = pd.read_csv(idf_map_csv)
        row_match = df_idf_map.loc[df_idf_map["ogc_fid"] == building_id]

        if row_match.empty:
            raise ValueError(
                f"No building found for building_id={building_id} in {idf_map_csv}"
            )

        # e.g. "building_0.idf", "building_16.idf", "building_16_ba62d0.idf", etc.
        idf_filename = row_match.iloc[0]["idf_name"]

        # Build the full path to that IDF in output_IDFs
        base_idf_path = os.path.join(job_output_dir, "output_IDFs", idf_filename)
        mod_cfg["base_idf_path"] = base_idf_path
        logger.info(f"[INFO] Auto-selected base IDF => {base_idf_path}")
        # ----------------------------------------------------------------------

        # Finally, run the scenario workflow
        run_modification_workflow(mod_cfg)
    else:
        logger.info("[INFO] Skipping scenario modification.")


    # -------------------------------------------------------------------------
    # 12) Helper to handle patching CSVs that are "relative" but not "data/".
    # -------------------------------------------------------------------------
    def patch_if_relative(csv_path: str):
        """
        1) If absolute, return as-is.
        2) If starts with 'data/', interpret as /usr/src/app/data/... (no job folder).
        3) Else, join with job_output_dir.
        """
        if not csv_path:
            return csv_path
        if os.path.isabs(csv_path):
            return csv_path
        if csv_path.startswith("data/"):
            return os.path.join("/usr/src/app", csv_path)
        return os.path.join(job_output_dir, csv_path)

    # -------------------------------------------------------------------------
    # 13) Global Validation
    # -------------------------------------------------------------------------
        # (A) Validation - BASE
    # -------------------------------------------------------------------------
    check_canceled()
    base_validation_cfg = main_config.get("validation_base", {})
    if base_validation_cfg.get("perform_validation", False):
        logger.info("[INFO] BASE Validation is ENABLED.")
        val_conf = base_validation_cfg["config"]

        # Patch relative paths
        sim_csv = val_conf.get("sim_data_csv")
        if sim_csv:
            val_conf["sim_data_csv"] = patch_if_relative(sim_csv)

        real_csv = val_conf.get("real_data_csv")
        if real_csv:
            val_conf["real_data_csv"] = patch_if_relative(real_csv)

        out_csv = val_conf.get("output_csv")
        if out_csv:
            val_conf["output_csv"] = patch_if_relative(out_csv)

        # Now run the validation
        run_validation_process(val_conf)
    else:
        logger.info("[INFO] Skipping BASE validation or not requested.")

    # (B) Validation - SCENARIOS
    # -------------------------------------------------------------------------
    check_canceled()
    scenario_validation_cfg = main_config.get("validation_scenarios", {})
    if scenario_validation_cfg.get("perform_validation", False):
        logger.info("[INFO] SCENARIO Validation is ENABLED.")
        val_conf = scenario_validation_cfg["config"]

        # Patch relative paths
        sim_csv = val_conf.get("sim_data_csv")
        if sim_csv:
            val_conf["sim_data_csv"] = patch_if_relative(sim_csv)

        real_csv = val_conf.get("real_data_csv")
        if real_csv:
            val_conf["real_data_csv"] = patch_if_relative(real_csv)

        out_csv = val_conf.get("output_csv")
        if out_csv:
            val_conf["output_csv"] = patch_if_relative(out_csv)

        # Now run the validation
        run_validation_process(val_conf)
    else:
        logger.info("[INFO] Skipping SCENARIO validation or not requested.")


    # -------------------------------------------------------------------------
    # 14) Sensitivity Analysis
    # -------------------------------------------------------------------------
    check_canceled()
    if sens_cfg.get("perform_sensitivity", False):
        logger.info("[INFO] Sensitivity Analysis is ENABLED.")

        scenario_folder = sens_cfg.get("scenario_folder", "")
        sens_cfg["scenario_folder"] = patch_if_relative(scenario_folder)

        results_csv = sens_cfg.get("results_csv", "")
        sens_cfg["results_csv"] = patch_if_relative(results_csv)

        out_csv = sens_cfg.get("output_csv", "sensitivity_output.csv")
        sens_cfg["output_csv"] = patch_if_relative(out_csv)

        run_sensitivity_analysis(
            scenario_folder=sens_cfg["scenario_folder"],
            method=sens_cfg["method"],
            results_csv=sens_cfg.get("results_csv", ""),
            target_variable=sens_cfg.get("target_variable", []),
            output_csv=sens_cfg.get("output_csv", "sensitivity_output.csv"),
            n_morris_trajectories=sens_cfg.get("n_morris_trajectories", 10),
            num_levels=sens_cfg.get("num_levels", 4),
            n_sobol_samples=sens_cfg.get("n_sobol_samples", 128)
        )
    else:
        logger.info("[INFO] Skipping sensitivity analysis.")

    # -------------------------------------------------------------------------
    # 15) Surrogate Modeling
    # -------------------------------------------------------------------------
    check_canceled()
    if sur_cfg.get("perform_surrogate", False):
        logger.info("[INFO] Surrogate Modeling is ENABLED.")

        scenario_folder = sur_cfg.get("scenario_folder", "")
        sur_cfg["scenario_folder"] = patch_if_relative(scenario_folder)

        results_csv = sur_cfg.get("results_csv", "")
        sur_cfg["results_csv"] = patch_if_relative(results_csv)

        model_out = sur_cfg.get("model_out", "")
        sur_cfg["model_out"] = patch_if_relative(model_out)

        cols_out = sur_cfg.get("cols_out", "")
        sur_cfg["cols_out"] = patch_if_relative(cols_out)

        target_var = sur_cfg["target_variable"]
        test_size  = sur_cfg["test_size"]

        df_scen = sur_load_scenario_params(sur_cfg["scenario_folder"])
        pivot_df = pivot_scenario_params(df_scen)

        df_sim = load_sim_results(sur_cfg["results_csv"])
        df_agg = aggregate_results(df_sim)
        merged_df = merge_params_with_results(pivot_df, df_agg, target_var)

        rf_model, trained_cols = build_and_save_surrogate(
            df_data=merged_df,
            target_col=target_var,
            model_out_path=sur_cfg["model_out"],
            columns_out_path=sur_cfg["cols_out"],
            test_size=test_size,
            random_state=42
        )
        if rf_model:
            logger.info("[INFO] Surrogate model built & saved.")
        else:
            logger.warning("[WARN] Surrogate modeling failed or insufficient data.")
    else:
        logger.info("[INFO] Skipping surrogate modeling.")

    # -------------------------------------------------------------------------
    # 16) Calibration
    # -------------------------------------------------------------------------
    check_canceled()
    if cal_cfg.get("perform_calibration", False):
        logger.info("[INFO] Calibration is ENABLED.")

        scen_folder = cal_cfg.get("scenario_folder", "")
        cal_cfg["scenario_folder"] = patch_if_relative(scen_folder)

        real_csv = cal_cfg.get("real_data_csv", "")
        cal_cfg["real_data_csv"] = patch_if_relative(real_csv)

        sur_model_path = cal_cfg.get("surrogate_model_path", "")
        cal_cfg["surrogate_model_path"] = patch_if_relative(sur_model_path)

        sur_cols_path = cal_cfg.get("surrogate_columns_path", "")
        cal_cfg["surrogate_columns_path"] = patch_if_relative(sur_cols_path)

        hist_csv = cal_cfg.get("output_history_csv", "")
        cal_cfg["output_history_csv"] = patch_if_relative(hist_csv)

        best_params_folder = cal_cfg.get("best_params_folder", "")
        cal_cfg["best_params_folder"] = patch_if_relative(best_params_folder)

        run_unified_calibration(cal_cfg)
    else:
        logger.info("[INFO] Skipping calibration.")

    # -------------------------------------------------------------------------
    # 17) Zip & Email final results, if mail_user.json present
    # -------------------------------------------------------------------------
    try:
        mail_user_path = os.path.join(user_configs_folder, "mail_user.json")
        if os.path.isfile(mail_user_path):
            with open(mail_user_path, "r") as f:
                mail_info = json.load(f)

            mail_user_list = mail_info.get("mail_user", [])
            if len(mail_user_list) > 0:
                first_user = mail_user_list[0]
                recipient_email = first_user.get("email", "")
                if recipient_email:
                    zip_path = zip_user_output(job_output_dir)
                    send_results_email(zip_path, recipient_email)
                    logger.info(f"[INFO] Emailed zip {zip_path} to {recipient_email}")
                else:
                    logger.warning("[WARN] mail_user.json => missing 'email'")
            else:
                logger.warning("[WARN] mail_user.json => 'mail_user' list is empty.")
        else:
            logger.info("[INFO] No mail_user.json found, skipping email.")
    except Exception as e:
        logger.error(f"[ERROR] Zipping/Emailing results failed => {e}")

    # -------------------------------------------------------------------------
    # LAST STEP: (Optional) Call the cleanup function
    # -------------------------------------------------------------------------
    try:
        cleanup_old_results()  # This will remove any job folder older than MAX_AGE_HOURS
    except Exception as e:
        logger.error(f"[CLEANUP ERROR] => {e}")

    logger.info("=== End of orchestrate_workflow ===")

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\eequip\assign_equip_values.py
============================================================
# File: D:\Documents\E_Plus_2030_py\idf_objects\eequip\assign_equip_values.py

import random
from .equip_lookup import equip_lookup
from .overrides_helper import find_applicable_overrides # if you use override logic

def assign_equipment_parameters(
    building_id: int,
    building_category: str,
    sub_type: str,
    age_range=None, # Passed to find_applicable_overrides
    calibration_stage: str = "pre_calibration",
    strategy: str = "A",
    random_seed: int = None,
    user_config: list = None, # override table (list of dicts)
    assigned_log: dict = None # optional dictionary to store final picks
):
    """
    Returns a dict with ``equip_wm2``, ``tD`` and ``tN`` picks for electric
    equipment. (Docstring from original file)
    """
    print(f"\n--- [DEBUG assign_equipment_parameters for bldg_id {building_id}] ---")
    print(f"[DEBUG assign_equip_params] INPUTS: building_category='{building_category}', sub_type='{sub_type}', calibration_stage='{calibration_stage}', strategy='{strategy}'")
    print(f"[DEBUG assign_equip_params]          age_range='{age_range}', user_config is {'Provided' if user_config else 'None'}")

    if random_seed is not None:
        random.seed(random_seed)
        print(f"[DEBUG assign_equip_params] Random seed set to: {random_seed}")

    # Normalize category strings so that lookups are consistent
    _original_building_category = building_category
    if building_category: # Check if building_category is not None or empty
        bt_low = building_category.lower()
        if bt_low == "residential":
            building_category = "Residential"
        elif bt_low == "non_residential": # Corrected from "non_residential" to match potential input casing
            building_category = "Non-Residential"
    print(f"[DEBUG assign_equip_params] Category after normalization: '{building_category}' (was '{_original_building_category}')")

    _original_sub_type = sub_type
    sub_type = sub_type.strip() if sub_type else ""
    print(f"[DEBUG assign_equip_params] Sub_type after strip: '{sub_type}' (was '{_original_sub_type}') (len: {len(sub_type)})")

    # Initialize ranges with minimal fallbacks, to be updated if lookups succeed
    equip_rng_default = (3.0, 3.0)
    tD_rng_default    = (500, 500)
    tN_rng_default    = (200, 200)

    equip_rng = equip_rng_default
    tD_rng    = tD_rng_default
    tN_rng    = tN_rng_default
    
    lookup_successful = False

    # 1) Grab the stage dictionary or fallback
    _original_calibration_stage = calibration_stage
    if calibration_stage not in equip_lookup:
        print(f"[DEBUG assign_equip_params] WARNING: calibration_stage '{calibration_stage}' not in equip_lookup keys: {list(equip_lookup.keys()) if isinstance(equip_lookup, dict) else 'Not a dict'}. Defaulting to 'pre_calibration'.")
        calibration_stage = "pre_calibration"
    
    if calibration_stage not in equip_lookup:
        print(f"[DEBUG assign_equip_params] CRITICAL FALLBACK (Stage): calibration_stage '{calibration_stage}' (even after potential default) is NOT in equip_lookup. Using hardcoded minimal fallback for ALL parameters.")
        # Ranges already initialized to minimal fallbacks
    else:
        stage_dict = equip_lookup[calibration_stage]
        print(f"[DEBUG assign_equip_params] Using calibration_stage: '{calibration_stage}'. Stage_dict keys: {list(stage_dict.keys()) if isinstance(stage_dict, dict) else 'Not a dict'}")

        # 2) Navigate to the sub-type dictionary or fallback
        if not isinstance(stage_dict, dict) or building_category not in stage_dict:
            print(f"[DEBUG assign_equip_params] FALLBACK (A - category): building_category '{building_category}' not in stage_dict for stage '{calibration_stage}' (or stage_dict is not a dict: {type(stage_dict)}). Using minimal fallback.")
            # Ranges already initialized to minimal fallbacks
        else:
            cat_dict = stage_dict[building_category]
            print(f"[DEBUG assign_equip_params] Found cat_dict for '{building_category}'. Sub-type keys in cat_dict: {list(cat_dict.keys()) if isinstance(cat_dict, dict) else 'Not a dict'}")
            
            if not isinstance(cat_dict, dict) or sub_type not in cat_dict:
                print(f"[DEBUG assign_equip_params] FALLBACK (B - sub_type): sub_type '{sub_type}' not in cat_dict for category '{building_category}' (or cat_dict is not a dict: {type(cat_dict)}). Using minimal fallback.")
                if isinstance(cat_dict, dict): print(f"   Available sub_types in cat_dict: {list(cat_dict.keys())}")
                # Ranges already initialized to minimal fallbacks
            else:
                param_dict = cat_dict[sub_type]
                if not isinstance(param_dict, dict):
                    print(f"[DEBUG assign_equip_params] FALLBACK (C - param_dict type): param_dict for '{sub_type}' is not a dictionary (type: {type(param_dict)}). Using minimal fallback.")
                    # Ranges already initialized to minimal fallbacks
                else:
                    print(f"[DEBUG assign_equip_params] SUCCESS: Found param_dict for sub_type '{sub_type}'. Keys: {list(param_dict.keys())}")
                    lookup_successful = True
                    # Get parameters with their own fallbacks if specific keys are missing
                    equip_rng = param_dict.get("EQUIP_WM2_range", equip_rng_default)
                    tD_rng    = param_dict.get("tD_range", tD_rng_default)
                    tN_rng    = param_dict.get("tN_range", tN_rng_default)
                    
                    if "EQUIP_WM2_range" not in param_dict: print(f"   [DEBUG assign_equip_params] Note: EQUIP_WM2_range missing in param_dict for '{sub_type}', used default {equip_rng_default}.")
                    if "tD_range" not in param_dict: print(f"   [DEBUG assign_equip_params] Note: tD_range missing in param_dict for '{sub_type}', used default {tD_rng_default}.")
                    if "tN_range" not in param_dict: print(f"   [DEBUG assign_equip_params] Note: tN_range missing in param_dict for '{sub_type}', used default {tN_rng_default}.")

    print(f"[DEBUG assign_equip_params] Ranges status after lookup (lookup_successful={lookup_successful}):")
    print(f"  equip_rng: {equip_rng}")
    print(f"  tD_rng: {tD_rng}")
    print(f"  tN_rng: {tN_rng}")

    # 3) Find override rows
    matches = [] # Ensure matches is defined
    if user_config is not None:
        # Assuming find_applicable_overrides exists and works correctly.
        # Add try-except if it's a source of potential errors.
        try:
            matches = find_applicable_overrides(building_id, sub_type, age_range, user_config)
            print(f"[DEBUG assign_equip_params] Found {len(matches)} applicable overrides for bldg_id={building_id}, sub_type='{sub_type}', age_range='{age_range}'.")
            if matches: print(f"   Overrides data: {matches}")
        except Exception as e:
            print(f"[DEBUG assign_equip_params] ERROR in find_applicable_overrides: {e}")
            matches = [] # Reset to empty list on error
    else:
        print(f"[DEBUG assign_equip_params] No user_config provided for overrides.")
        matches = []

    # 4) Apply overrides
    if matches:
        print(f"[DEBUG assign_equip_params] Applying {len(matches)} overrides...")
    for row_idx, row in enumerate(matches):
        # Defensive get for keys in override rows
        pname = row.get("param_name")
        mn = row.get("min_val")
        mx = row.get("max_val")

        if pname is None or mn is None or mx is None:
            print(f"  [DEBUG assign_equip_params] Override {row_idx+1} skipped: malformed row (missing param_name, min_val, or max_val): {row}")
            continue
            
        pname = pname.strip() # Ensure no leading/trailing spaces

        print(f"  [DEBUG assign_equip_params] Override {row_idx+1}: param='{pname}', min_val={mn}, max_val={mx}")
        if pname == "equip_wm2":
            equip_rng = (float(mn), float(mx))
            print(f"    Updated equip_rng to: {equip_rng}")
        elif pname == "tD":
            tD_rng = (float(mn), float(mx))
            print(f"    Updated tD_rng to: {tD_rng}")
        elif pname == "tN":
            tN_rng = (float(mn), float(mx))
            print(f"    Updated tN_rng to: {tN_rng}")
        else:
            print(f"    [DEBUG assign_equip_params] Unrecognized param_name '{pname}' in override row.")
    
    if matches: print(f"[DEBUG assign_equip_params] Ranges after potential overrides: equip_rng={equip_rng}, tD_rng={tD_rng}, tN_rng={tN_rng}")

    # 5) Strategy to pick final values
    def pick_val(param_name, r, current_strategy): # Added param_name and strategy for better logging
        val = None
        # Ensure r is a tuple of two numbers
        if not (isinstance(r, (tuple, list)) and len(r) == 2 and all(isinstance(n, (int, float)) for n in r)):
            print(f"  [DEBUG assign_equip_params] pick_val for '{param_name}': Invalid range format {r}. Using default 0.0.")
            return 0.0 # Or handle error appropriately
            
        if current_strategy == "A": # midpoint
            val = (r[0] + r[1]) / 2.0
        elif current_strategy == "B": # random
            val = random.uniform(r[0], r[1])
        else: # fallback => pick min
            val = r[0]
        print(f"  [DEBUG assign_equip_params] pick_val for '{param_name}': range={r}, strategy='{current_strategy}', picked={val}")
        return val

    assigned_equip = max(0.0, float(pick_val("equip_wm2", equip_rng, strategy)))
    assigned_tD    = max(0.0, float(pick_val("tD", tD_rng, strategy)))
    assigned_tN    = max(0.0, float(pick_val("tN", tN_rng, strategy)))

    assigned = {
        "equip_wm2": {"assigned_value": assigned_equip, "min_val": equip_rng[0], "max_val": equip_rng[1], "object_name": "ELECTRICEQUIPMENT"},
        "tD": {"assigned_value": assigned_tD, "min_val": tD_rng[0], "max_val": tD_rng[1], "object_name": "ELECTRICEQUIPMENT_SCHEDULE"},
        "tN": {"assigned_value": assigned_tN, "min_val": tN_rng[0], "max_val": tN_rng[1], "object_name": "ELECTRICEQUIPMENT_SCHEDULE"}
    }
    print(f"[DEBUG assign_equip_params] Final assigned values: {assigned}")

    # 6) Optional logging of both the picks and underlying ranges
    if assigned_log is not None:
        log_data = {
            "assigned": assigned,
            "ranges": {
                "equip_wm2": equip_rng,
                "tD": tD_rng,
                "tN": tN_rng,
            },
            "lookup_successful": lookup_successful, # Added for insight
            "overrides_applied_count": len(matches) # Added for insight
        }
        assigned_log[building_id] = log_data
        print(f"[DEBUG assign_equip_params] Logged data for building_id {building_id}: {log_data}")

    print(f"--- [END DEBUG assign_equipment_parameters for bldg_id {building_id}] ---")
    return assigned
------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\eequip\equip_lookup.py
============================================================
# eequip/equip_lookup.py
"""
Equipment Lookup Table (Pre/Post Calibration)
---------------------------------------------
This file defines default electric equipment parameters for both 
residential and non-residential buildings.

NOTE (รอบนี้): The "EQUIP_WM2_range" values below for non-residential pre_calibration
have been FURTHER ADJUSTED to represent MORE ENERGY-EFFICIENT or typical office/plug load
scenarios. Heavy process loads (e.g., large refrigeration in retail, industrial machinery)
are typically modeled separately. These are ILLUSTRATIVE examples and MUST BE VALIDATED
against specific project requirements and local standards (e.g., NTA 8800).
The tD_range and tN_range are NOT directly used by the EnergyPlus ELECTRICEQUIPMENT
object's energy calculation in the provided scripts; schedules from schedule_def.py are used.
"""

equip_lookup = {
    "pre_calibration": {
        # ===============================
        # 1) RESIDENTIAL (example sub-types) - Values seem generally plausible
        # ===============================
        "Residential": {
            "Corner House":                 { "EQUIP_WM2_range": (2.5, 4.0), "tD_range": (400, 600), "tN_range": (100, 200) },
            "Apartment":                    { "EQUIP_WM2_range": (1.5, 3.0), "tD_range": (300, 500), "tN_range": (100, 200) },
            "Terrace or Semi-detached House":{ "EQUIP_WM2_range": (2.5, 4.0), "tD_range": (400, 600), "tN_range": (100, 200) },
            "Detached House":               { "EQUIP_WM2_range": (3.0, 5.0), "tD_range": (500, 700), "tN_range": (200, 300) },
            "Two-and-a-half-story House":   { "EQUIP_WM2_range": (3.0, 5.0), "tD_range": (500, 700), "tN_range": (200, 300) }
        },
        # ===============================
        # 2) NON-RESIDENTIAL (Values adjusted for more typical/efficient plug loads)
        # ===============================
        "Non-Residential": {
            "Office Function": { # Standard office: PCs, monitors, printers, etc.
                "EQUIP_WM2_range": (4.0, 7.0),   # Adjusted from 8-10 previously
                "tD_range": (2000, 2400),
                "tN_range": (100, 250)
            },
            "Retail Function": { # POS, back-office computers. Does NOT include large display refrigeration.
                "EQUIP_WM2_range": (3.0, 7.0),   # Adjusted from 10-12 (for general equipment)
                "tD_range": (2500, 3000),
                "tN_range": (200, 400)
            },
            "Education Function": { # Classrooms: few PCs/projector, Staff rooms: more PCs
                "EQUIP_WM2_range": (2.5, 5.0),   # Adjusted from 7-9
                "tD_range": (1400, 1800),
                "tN_range": (100, 200)
            },
            "Healthcare Function": { # General areas: nurse stations, office equip. Excludes specialized medical.
                "EQUIP_WM2_range": (4.0, 8.0),   # Adjusted from 10-12
                "tD_range": (3000, 4000),
                "tN_range": (500, 700)
            },
            "Meeting Function": { # AV equipment, laptops if BYOD
                "EQUIP_WM2_range": (2.0, 5.0),   # Adjusted from 8-10
                "tD_range": (1800, 2200),
                "tN_range": (100, 200)
            },
            "Sport Function": { # Reception PCs, small office, potentially some small fitness equip electronics
                "EQUIP_WM2_range": (1.5, 4.0),   # Adjusted from 9-11
                "tD_range": (2000, 2500),
                "tN_range": (300, 500)
            },
            "Cell Function": { # Minimal in-cell, e.g. small TV or radio.
                "EQUIP_WM2_range": (1.0, 2.5),   # Adjusted from 8-10
                "tD_range": (3500, 4000),
                "tN_range": (800, 1000)
            },
            "Industrial Function": { # Office/admin areas within industrial, not process machinery.
                "EQUIP_WM2_range": (3.0, 6.0),   # Adjusted from 12-15
                "tD_range": (2800, 3500),
                "tN_range": (300, 600)
            },
            "Accommodation Function": { # Guest rooms: TV, charging, clock. Lobby: PCs.
                "EQUIP_WM2_range": (2.0, 4.0),   # Adjusted from 6-8
                "tD_range": (2000, 2800),
                "tN_range": (400, 700)
            },
            "Other Use Function": { # Generic non-residential equipment
                "EQUIP_WM2_range": (3.0, 6.0),   # Adjusted from 5-8
                "tD_range": (1500, 2000),
                "tN_range": (100, 300)
            }
        }
    },
    "post_calibration": {
        # Post-calibration values are highly project-specific.
        # Structure from your original file is maintained.
        "Residential": {
            "Corner House": {"EQUIP_WM2_range": (4.0,4.0), "tD_range": (500,500), "tN_range": (150,150)},
            "Apartment": {"EQUIP_WM2_range": (3.0,3.0), "tD_range": (400,400), "tN_range": (150,150)},
            "Terrace or Semi-detached House": {"EQUIP_WM2_range": (4.0,4.0), "tD_range": (500,500), "tN_range": (150,150)},
            "Detached House": {"EQUIP_WM2_range": (5.0,5.0), "tD_range": (600,600), "tN_range": (250,250)},
            "Two-and-a-half-story House": {"EQUIP_WM2_range": (5.0,5.0), "tD_range": (600,600), "tN_range": (250,250)}
        },
        "Non-Residential": { # Copying one example, others would follow similar calibrated pattern
            "Office Function": {"EQUIP_WM2_range": (5.0,5.0), "tD_range": (2300,2300), "tN_range": (150,150)},
            # ... other non-residential types with their calibrated values ...
            "Meeting Function": {"EQUIP_WM2_range": (4.0,4.0), "tD_range": (2000,2000), "tN_range": (150,150)},
            "Healthcare Function": {"EQUIP_WM2_range": (7.0,7.0), "tD_range": (3800,3800), "tN_range": (600,600)},
            "Sport Function": {"EQUIP_WM2_range": (3.0,3.0), "tD_range": (2200,2200), "tN_range": (400,400)},
            "Cell Function": {"EQUIP_WM2_range": (2.0,2.0), "tD_range": (3800,3800), "tN_range": (900,900)},
            "Retail Function": {"EQUIP_WM2_range": (6.0,6.0), "tD_range": (2800,2800), "tN_range": (300,300)},
            "Industrial Function": {"EQUIP_WM2_range": (5.0,5.0), "tD_range": (3000,3000), "tN_range": (400,400)},
            "Accommodation Function": {"EQUIP_WM2_range": (3.0,3.0), "tD_range": (2500,2500), "tN_range": (500,500)},
            "Education Function": {"EQUIP_WM2_range": (4.0,4.0), "tD_range": (1600,1600), "tN_range": (150,150)},
            "Other Use Function": {"EQUIP_WM2_range": (4.0,4.0), "tD_range": (1800,1800), "tN_range": (200,200)}
        }
    }
}
------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\eequip\equipment.py
============================================================
# File: D:\Documents\E_Plus_2030_py\idf_objects\eequip\equipment.py
"""equipment.py

Adds ELECTRICEQUIPMENT objects to an IDF using default lookup tables
and optional user overrides.
"""

from idf_objects.Elec.lighting import get_building_category_and_subtype # This will use the debugged version from Elec/lighting.py
from .assign_equip_values import assign_equipment_parameters
from .schedules import create_equipment_schedule


def add_electric_equipment(
    idf,
    building_row,
    calibration_stage="pre_calibration",
    strategy="A",
    random_seed=None,
    user_config=None,
    assigned_values_log=None,
    zonelist_name="ALL_ZONES",
):
    """Create an ELECTRICEQUIPMENT object for the entire building.

    Parameters
    ----------
    idf : Eppy IDF
        The IDF object to modify.
    building_row : pd.Series or dict
        Row with at least ``ogc_fid`` and ``building_function`` fields.
    calibration_stage : str, default "pre_calibration"
        Lookup key for ``equip_lookup``.
    strategy : str, default "A"
        Selection strategy for value picking.
    random_seed : int, optional
        Seed for the random generator if strategy uses randomness.
    user_config : list of dicts, optional
        Override rows for equipment parameters.
    assigned_values_log : dict, optional
        If provided, the picked parameters are stored under
        ``assigned_values_log[building_id]``.
    zonelist_name : str, default "ALL_ZONES"
        ZoneList name to reference in the created object.
    """

    # 1) Get building_category / sub_type
    building_category, sub_type = get_building_category_and_subtype(building_row) # Uses the debugged version
    
    bldg_id = int(building_row.get("ogc_fid", 0))
    print(f"\n--- [DEBUG add_electric_equipment for bldg_id {bldg_id}] ---")
    print(f"[DEBUG add_electric_equipment] Calling get_building_category_and_subtype, received: category='{building_category}', sub_type='{sub_type}'")

    picks = assign_equipment_parameters( # Call to assign_equipment_parameters
        building_id=bldg_id,
        building_category=building_category,
        sub_type=sub_type,
        age_range=None, # Assuming age_range is not the issue for now
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        user_config=user_config,
        assigned_log=assigned_values_log,
    )

    equip_wm2 = picks["equip_wm2"]["assigned_value"]

    sched_name = create_equipment_schedule(
        idf,
        building_category=building_category,
        sub_type=sub_type,
        schedule_name="EquipSchedule",
    )

    eq_obj = idf.newidfobject("ELECTRICEQUIPMENT")
    eq_obj.Name = f"Equip_{zonelist_name}"
    eq_obj.Zone_or_ZoneList_or_Space_or_SpaceList_Name = zonelist_name
    eq_obj.Schedule_Name = sched_name
    eq_obj.Design_Level_Calculation_Method = "Watts/Area"
    eq_obj.Watts_per_Zone_Floor_Area = equip_wm2
    
    print(f"[DEBUG add_electric_equipment] Successfully created ELECTRICEQUIPMENT object for bldg_id {bldg_id} with equip_wm2 = {equip_wm2}.")
    print(f"--- [END DEBUG add_electric_equipment for bldg_id {bldg_id}] ---")
    return eq_obj
------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\eequip\schedule_def.py
============================================================
# eequip/schedule_def.py

"""
EQUIP_SCHEDULE_DEFINITIONS
===========================
This dictionary defines typical usage patterns for electric equipment
throughout the day, differentiating weekday vs. weekend, and by building
category (Residential vs. Non-Residential) and sub-type.

NOTE (รอบนี้): The non-residential schedules below have been FURTHER REFINED
to represent more energy-conscious or typical operational patterns for general
plug loads and office-type equipment. These are ILLUSTRATIVE examples and
MUST BE VALIDATED and customized based on specific project requirements,
occupancy data, equipment types, and local standards (e.g., NTA 8800).
"""

EQUIP_SCHEDULE_DEFINITIONS = {
    "Residential": {
        # Residential equipment schedules - adjusted slightly for plausibility
        "Corner House": {
            "weekday": [(0, 6, 0.08), (6, 9, 0.35), (9, 17, 0.18), (17, 21, 0.50), (21, 24, 0.15)],
            "weekend": [(0, 7, 0.10), (7, 22, 0.45), (22, 24, 0.15)],
        },
        "Apartment": {
            "weekday": [(0, 6, 0.06), (6, 8, 0.25), (8, 18, 0.12), (18, 23, 0.45), (23, 24, 0.08)],
            "weekend": [(0, 8, 0.08), (8, 22, 0.40), (22, 24, 0.10)],
        },
        "Terrace or Semi-detached House": {
            "weekday": [(0, 6, 0.08), (6, 9, 0.35), (9, 17, 0.18), (17, 22, 0.50), (22, 24, 0.15)],
            "weekend": [(0, 7, 0.10), (7, 22, 0.45), (22, 24, 0.15)],
        },
        "Detached House": {
            "weekday": [(0, 6, 0.10), (6, 9, 0.40), (9, 17, 0.20), (17, 22, 0.55), (22, 24, 0.20)],
            "weekend": [(0, 7, 0.12), (7, 23, 0.50), (23, 24, 0.20)],
        },
        "Two-and-a-half-story House": {
            "weekday": [(0, 6, 0.08), (6, 9, 0.35), (9, 17, 0.18), (17, 22, 0.50), (22, 24, 0.15)],
            "weekend": [(0, 7, 0.10), (7, 22, 0.45), (22, 24, 0.15)],
        },
    },
    "Non-Residential": {
        "Office Function": { # Equipment (PCs, monitors) often on during work hours
            "weekday": [
                (0, 7, 0.05),   # Night standby (network gear, some PCs in sleep)
                (7, 8, 0.30),   # Arrival, boot up
                (8, 12, 0.75),  # Core work hours (PCs active)
                (12, 13, 0.50), # Lunch (some PCs sleep/idle, some active)
                (13, 17, 0.75), # Core work hours
                (17, 18, 0.40), # Winding down, some shutdown
                (18, 24, 0.05),  # Night standby
            ],
            "weekend": [ # Minimal, mainly server/network gear or essential services
                (0, 24, 0.05),
            ],
        },
        "Retail Function": { # POS, back-office. Excludes major refrigeration/process loads.
            "weekday": [
                (0, 8, 0.03),   # Closed, essential standby
                (8, 10, 0.40),  # Staff prep, systems on
                (10, 18, 0.70), # Open - active POS, back office
                (18, 19, 0.35), # Closing tasks
                (19, 24, 0.03),  # Closed
            ],
            "weekend": [
                (0, 9, 0.03),
                (9, 17, 0.65),  # Weekend opening hours
                (17, 18, 0.25),
                (18, 24, 0.03),
            ],
        },
        "Education Function": { # Computers in labs/classrooms, staff PCs
            "weekday": [
                (0, 7, 0.02),
                (7, 8, 0.30),   # Staff arrive, systems on
                (8, 12, 0.65),  # Classes, computer use
                (12, 13, 0.20), # Lunch, lower use
                (13, 16, 0.65), # Classes
                (16, 18, 0.10), # Staff finishing up
                (18, 24, 0.02),
            ],
            "weekend": [(0, 24, 0.02)], # Mostly off
        },
        "Healthcare Function": { # Office equip, nurse stations, patient monitoring (not heavy medical imaging)
            "weekday": [ # Assumes some 24/7 base for critical, higher for admin/clinic hours
                (0, 7, 0.40),   # Night essentials
                (7, 19, 0.60),  # Daytime higher activity
                (19, 22, 0.50), # Evening
                (22, 24, 0.40),
            ],
            "weekend": [
                (0, 7, 0.35),
                (7, 19, 0.55),
                (19, 22, 0.45),
                (22, 24, 0.35),
            ],
        },
        "Meeting Function": { # AV, laptops
            "weekday": [
                (0, 8, 0.02),
                (8, 9, 0.20),
                (9, 12, 0.50), # Intermittent use of AV/laptops
                (12, 13, 0.15),
                (13, 17, 0.50),
                (17, 18, 0.10),
                (18, 24, 0.02),
            ],
            "weekend": [(0, 24, 0.02)],
        },
        "Sport Function": { # Office/reception, some electronic fitness if applicable
            "weekday": [
                (0, 7, 0.01),
                (7, 16, 0.30), 
                (16, 22, 0.60), 
                (22, 24, 0.02),
            ],
            "weekend": [
                (0, 8, 0.01),
                (8, 20, 0.50), 
                (20, 24, 0.02),
            ],
        },
        "Cell Function": { # Minimal in-cell equipment
            "weekday": [(0, 24, 0.20)], # Reduced
            "weekend": [(0, 24, 0.20)],
        },
        "Industrial Function": { # Assumes office/control part of industrial, not main machinery
            "weekday": [
                (0, 6, 0.05),
                (6, 18, 0.60), # Operational hours for support equipment
                (18, 22, 0.08),
                (22, 24, 0.05),
            ],
            "weekend": [(0, 24, 0.05)],
        },
        "Accommodation Function": { # Guest room + common area office/lobby equip
            "weekday": [
                (0, 6, 0.20),
                (6, 10, 0.35),
                (10, 17, 0.20),
                (17, 23, 0.50),
                (23, 24, 0.20),
            ],
            "weekend": [
                (0, 6, 0.22),
                (6, 11, 0.40),
                (11, 17, 0.30),
                (17, 23, 0.55),
                (23, 24, 0.22),
            ],
        },
        "Other Use Function": {
            "weekday": [
                (0, 7, 0.03),
                (7, 19, 0.40), 
                (19, 24, 0.03),
            ],
            "weekend": [
                (0, 24, 0.05),
            ],
        },
    },
}

# Optional: Functions to read/apply Excel overrides (kept from original)
def read_schedule_overrides_from_excel(excel_path):
    """Read Excel overrides for schedule definitions."""
    import pandas as pd # Ensure pandas is available

    df = pd.read_excel(excel_path)
    required = [
        "building_category", "sub_type", "day_type",
        "start_hour", "end_hour", "fraction_value",
    ]
    for c in required:
        if c not in df.columns:
            raise ValueError(f"Missing column '{c}' in {excel_path}")

    overrides = {}
    for _, row in df.iterrows():
        cat = str(row["building_category"]).strip()
        stype = str(row["sub_type"]).strip()
        dtype = str(row["day_type"]).strip().lower()
        block = (float(row["start_hour"]), float(row["end_hour"]), float(row["fraction_value"]))

        overrides.setdefault(cat, {}).setdefault(stype, {}).setdefault(dtype, []).append(block)
    return overrides


def apply_schedule_overrides_to_schedules(base_schedules, overrides):
    """Merge schedule overrides into ``base_schedules`` in-place."""
    for cat, stypes in overrides.items():
        base_schedules.setdefault(cat, {})
        for stype, days in stypes.items():
            base_schedules[cat].setdefault(stype, {})
            for day_type, blocks in days.items():
                base_schedules[cat][stype][day_type] = blocks
    return base_schedules
------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\eequip\schedules.py
============================================================
# eequip/schedules.py

from .schedule_def import EQUIP_SCHEDULE_DEFINITIONS

"""
This module creates detailed schedules for electric equipment usage
(weekday vs. weekend), differentiating by building category (Residential vs. Non-Residential)
and sub-type (e.g. Corner House, Office, Retail, etc.).

We provide two main functions:

1) create_equipment_schedule(idf, building_category, sub_type, schedule_name)
   - Creates a multi-day schedule with 'WeekDays', 'Saturday', 'Sunday'.

2) create_equipment_parasitic_schedule(idf, sched_name)
   - Creates a schedule that is always ON (1.0).
"""


def create_equipment_schedule(idf, building_category, sub_type, schedule_name="EquipSchedule"):
    """
    Creates a SCHEDULE:COMPACT object in the IDF representing a typical 
    equipment usage pattern for weekdays vs. weekends, based on 
    EQUIP_SCHEDULE_DEFINITIONS.

    Parameters:
        - idf: Eppy IDF object (or a similar interface)
        - building_category: e.g. "Residential" or "Non-Residential"
        - sub_type: e.g. "Corner House", "Office Function"
        - schedule_name: name of the schedule in IDF

    Returns:
        - The name of the new schedule object (same as schedule_name).
    """

    # Attempt to retrieve a sub-type dict. If not found, fallback to a simple 0.5 fraction all day.
    try:
        sub_dict = EQUIP_SCHEDULE_DEFINITIONS[building_category][sub_type]
    except KeyError:
        sub_dict = {
            "weekday": [(0, 24, 0.5)],
            "weekend": [(0, 24, 0.5)],
        }

    # Create a new schedule object in the IDF
    schedule = idf.newidfobject("SCHEDULE:COMPACT")
    schedule.Name = schedule_name
    schedule.Schedule_Type_Limits_Name = "Fraction"

    # We'll define a pattern that covers the full year:
    field_idx = 1

    # First line: "Through: 12/31"
    setattr(schedule, f"Field_{field_idx}", "Through: 12/31")
    field_idx += 1

    # 1) WeekDays
    setattr(schedule, f"Field_{field_idx}", "For: WeekDays")
    field_idx += 1
    for (start_hour, end_hour, fraction) in sub_dict["weekday"]:
        setattr(
            schedule,
            f"Field_{field_idx}",
            f"Until: {end_hour:02d}:00,{fraction:.2f}"
        )
        field_idx += 1

    # 2) Saturday
    setattr(schedule, f"Field_{field_idx}", "For: Saturday")
    field_idx += 1
    for (start_hour, end_hour, fraction) in sub_dict["weekend"]:
        setattr(
            schedule,
            f"Field_{field_idx}",
            f"Until: {end_hour:02d}:00,{fraction:.2f}"
        )
        field_idx += 1

    # 3) Sunday
    setattr(schedule, f"Field_{field_idx}", "For: Sunday")
    field_idx += 1
    for (start_hour, end_hour, fraction) in sub_dict["weekend"]:
        setattr(
            schedule,
            f"Field_{field_idx}",
            f"Until: {end_hour:02d}:00,{fraction:.2f}"
        )
        field_idx += 1

    return schedule.Name


def create_equipment_parasitic_schedule(idf, sched_name="EquipParasiticSchedule"):
    """
    Creates a schedule that is always ON at 1.0 for parasitic equipment loads.
    You can also rename it or adjust if you want partial load or special schedules.

    Parameters:
        - idf: Eppy IDF object
        - sched_name: the schedule name in the IDF

    Returns:
        - The name of the new schedule object
    """

    schedule = idf.newidfobject("SCHEDULE:COMPACT")
    schedule.Name = sched_name
    schedule.Schedule_Type_Limits_Name = "Fraction"

    # A simple all-day, all-year schedule at 1.0
    schedule.Field_1 = "Through: 12/31"
    schedule.Field_2 = "For: AllDays"
    schedule.Field_3 = "Until: 24:00,1.0"

    return schedule.Name

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\Elec\assign_lighting_values.py
============================================================
# File: D:\Documents\E_Plus_2030_py\idf_objects\Elec\assign_lighting_values.py

import random
from .lighting_lookup import lighting_lookup
from .constants import ( # Ensure all DEFAULT constants are imported
    DEFAULT_LIGHTING_WM2, DEFAULT_PARASITIC_WM2, DEFAULT_TD, DEFAULT_TN,
    DEFAULT_LIGHTS_FRACTION_RADIANT, DEFAULT_LIGHTS_FRACTION_VISIBLE,
    DEFAULT_LIGHTS_FRACTION_REPLACEABLE, DEFAULT_LIGHTS_FRACTION_RETURN_AIR,
    DEFAULT_EQUIP_FRACTION_RADIANT, DEFAULT_EQUIP_FRACTION_LOST
)
from .overrides_helper import find_applicable_overrides # Assuming this helper function exists and is correct


def assign_lighting_parameters(
    building_id: int,
    building_category: str,
    sub_type: str,
    age_range=None,
    calibration_stage: str = "pre_calibration",
    strategy: str = "A",
    random_seed: int = None,
    user_config: list = None, # list of override dicts from lighting.json
    assigned_log: dict = None # optional dictionary to store final picks
):
    """
    Determines final lighting parameters for a given building,
    merging any user overrides from ``lighting.json`` with defaults
    stored under ``lighting_lookup[calibration_stage][building_category][sub_type]``.
    """
    print(f"\n--- [DEBUG assign_lighting_parameters for bldg_id {building_id}] ---")
    print(f"[DEBUG assign_light_params] INPUTS: building_category='{building_category}', sub_type='{sub_type}', calibration_stage='{calibration_stage}', strategy='{strategy}'")

    # (A) Set random seed if specified
    if random_seed is not None:
        random.seed(random_seed)
        print(f"[DEBUG assign_light_params] Random seed set to: {random_seed}")

    # (B) Get the "stage_dict" for the given calibration_stage
    _original_calibration_stage = calibration_stage
    if calibration_stage not in lighting_lookup:
        print(f"[DEBUG assign_light_params] WARNING: calibration_stage '{calibration_stage}' not in lighting_lookup keys: {list(lighting_lookup.keys())}. Defaulting to 'pre_calibration'.")
        calibration_stage = "pre_calibration"
    
    # Define the comprehensive fallback structure (as in your original code for this file)
    # This is used if category or sub_type lookups fail at a high level.
    FULL_FALLBACK_DICT = {
        "lights_wm2": {"assigned_value": DEFAULT_LIGHTING_WM2, "min_val": DEFAULT_LIGHTING_WM2, "max_val": DEFAULT_LIGHTING_WM2, "object_name": "LIGHTS"},
        "parasitic_wm2": {"assigned_value": DEFAULT_PARASITIC_WM2, "min_val": DEFAULT_PARASITIC_WM2, "max_val": DEFAULT_PARASITIC_WM2, "object_name": "ELECTRICEQUIPMENT"},
        "tD": {"assigned_value": DEFAULT_TD, "min_val": DEFAULT_TD, "max_val": DEFAULT_TD, "object_name": "LIGHTS_SCHEDULE"},
        "tN": {"assigned_value": DEFAULT_TN, "min_val": DEFAULT_TN, "max_val": DEFAULT_TN, "object_name": "LIGHTS_SCHEDULE"},
        "lights_fraction_radiant": {"assigned_value": DEFAULT_LIGHTS_FRACTION_RADIANT, "min_val": DEFAULT_LIGHTS_FRACTION_RADIANT, "max_val": DEFAULT_LIGHTS_FRACTION_RADIANT, "object_name": "LIGHTS.Fraction_Radiant"},
        "lights_fraction_visible": {"assigned_value": DEFAULT_LIGHTS_FRACTION_VISIBLE, "min_val": DEFAULT_LIGHTS_FRACTION_VISIBLE, "max_val": DEFAULT_LIGHTS_FRACTION_VISIBLE, "object_name": "LIGHTS.Fraction_Visible"},
        "lights_fraction_replaceable": {"assigned_value": DEFAULT_LIGHTS_FRACTION_REPLACEABLE, "min_val": DEFAULT_LIGHTS_FRACTION_REPLACEABLE, "max_val": DEFAULT_LIGHTS_FRACTION_REPLACEABLE, "object_name": "LIGHTS.Fraction_Replaceable"},
        "lights_fraction_return_air": {"assigned_value": DEFAULT_LIGHTS_FRACTION_RETURN_AIR, "min_val": DEFAULT_LIGHTS_FRACTION_RETURN_AIR, "max_val": DEFAULT_LIGHTS_FRACTION_RETURN_AIR, "object_name": "LIGHTS.Return_Air_Fraction"},
        "equip_fraction_radiant": {"assigned_value": DEFAULT_EQUIP_FRACTION_RADIANT, "min_val": DEFAULT_EQUIP_FRACTION_RADIANT, "max_val": DEFAULT_EQUIP_FRACTION_RADIANT, "object_name": "ELECTRICEQUIPMENT.Fraction_Radiant"},
        "equip_fraction_lost": {"assigned_value": DEFAULT_EQUIP_FRACTION_LOST, "min_val": DEFAULT_EQUIP_FRACTION_LOST, "max_val": DEFAULT_EQUIP_FRACTION_LOST, "object_name": "ELECTRICEQUIPMENT.Fraction_Lost"}
    }

    if calibration_stage not in lighting_lookup: # Should have been caught by the default, but defensive check
        print(f"[DEBUG assign_light_params] CRITICAL FALLBACK (Stage): calibration_stage '{calibration_stage}' (even after potential default) is NOT in lighting_lookup. Using FULL_FALLBACK_DICT.")
        if assigned_log is not None: assigned_log[building_id] = FULL_FALLBACK_DICT
        print(f"--- [END DEBUG assign_lighting_parameters for bldg_id {building_id} - CRITICAL STAGE FALLBACK] ---")
        return FULL_FALLBACK_DICT
        
    stage_dict = lighting_lookup[calibration_stage]
    print(f"[DEBUG assign_light_params] Using calibration_stage: '{calibration_stage}'. Stage_dict keys: {list(stage_dict.keys()) if isinstance(stage_dict, dict) else 'Not a dict'}")

    # Normalise and strip inputs (as per your original file)
    _original_building_category = building_category
    if building_category.lower() == "residential": # Note: your original file had `if building_category.lower() == ...` which could error if building_category is None
        building_category = "Residential"
    elif building_category.lower() == "non_residential": # Same potential error if None
        building_category = "Non-Residential"
    # Safer normalization:
    # if building_category: # Check if building_category is not None or empty
    #     if building_category.lower() == "residential":
    #         building_category = "Residential"
    #     elif building_category.lower() == "non_residential":
    #         building_category = "Non-Residential"
    # For now, using your structure, assuming building_category is a valid string from get_building_category_and_subtype
    print(f"[DEBUG assign_light_params] Category after normalization: '{building_category}' (was '{_original_building_category}')")
    
    _original_sub_type = sub_type
    sub_type = sub_type.strip() if sub_type else "" # This is good
    print(f"[DEBUG assign_light_params] Sub_type after strip: '{sub_type}' (was '{_original_sub_type}') (len: {len(sub_type)})")

    # (C) Navigate to the sub_type dictionary or fallback
    param_dict = None # Initialize to be safe
    if not isinstance(stage_dict, dict) or building_category not in stage_dict:
        print(f"[DEBUG assign_light_params] FALLBACK (C1 - category): building_category '{building_category}' not in stage_dict for stage '{calibration_stage}' (or stage_dict is not a dict: {type(stage_dict)}). Returning FULL_FALLBACK_DICT.")
        if assigned_log is not None: assigned_log[building_id] = FULL_FALLBACK_DICT
        print(f"--- [END DEBUG assign_lighting_parameters for bldg_id {building_id} - FALLBACK C1] ---")
        return FULL_FALLBACK_DICT
    
    cat_dict = stage_dict[building_category]
    print(f"[DEBUG assign_light_params] Found cat_dict for '{building_category}'. Sub-type keys in cat_dict: {list(cat_dict.keys()) if isinstance(cat_dict, dict) else 'Not a dict'}")

    if not isinstance(cat_dict, dict) or sub_type not in cat_dict:
        print(f"[DEBUG assign_light_params] FALLBACK (C2 - sub_type): sub_type '{sub_type}' not in cat_dict for category '{building_category}' (or cat_dict is not a dict: {type(cat_dict)}). Returning FULL_FALLBACK_DICT.")
        if isinstance(cat_dict, dict): print(f"   Expected one of: {list(cat_dict.keys())}")
        if assigned_log is not None: assigned_log[building_id] = FULL_FALLBACK_DICT
        print(f"--- [END DEBUG assign_lighting_parameters for bldg_id {building_id} - FALLBACK C2] ---")
        return FULL_FALLBACK_DICT
        
    param_dict = cat_dict[sub_type]
    if not isinstance(param_dict, dict):
        print(f"[DEBUG assign_light_params] FALLBACK (C3 - param_dict type): param_dict for '{sub_type}' is not a dictionary (type: {type(param_dict)}). Returning FULL_FALLBACK_DICT.")
        if assigned_log is not None: assigned_log[building_id] = FULL_FALLBACK_DICT
        print(f"--- [END DEBUG assign_lighting_parameters for bldg_id {building_id} - FALLBACK C3] ---")
        return FULL_FALLBACK_DICT

    print(f"[DEBUG assign_light_params] SUCCESS: Found param_dict for sub_type '{sub_type}'. Keys: {list(param_dict.keys())}")

    # (D) Extract default ranges from found param_dict or constants if key missing in param_dict
    # These will be the starting point before overrides.
    lights_rng      = param_dict.get("LIGHTS_WM2_range", (DEFAULT_LIGHTING_WM2, DEFAULT_LIGHTING_WM2))
    parasitic_rng   = param_dict.get("PARASITIC_WM2_range", (DEFAULT_PARASITIC_WM2, DEFAULT_PARASITIC_WM2))
    tD_rng          = param_dict.get("tD_range", (DEFAULT_TD, DEFAULT_TD))
    tN_rng          = param_dict.get("tN_range", (DEFAULT_TN, DEFAULT_TN))
    lights_fraction_radiant_rng     = param_dict.get("lights_fraction_radiant_range", (DEFAULT_LIGHTS_FRACTION_RADIANT, DEFAULT_LIGHTS_FRACTION_RADIANT))
    lights_fraction_visible_rng     = param_dict.get("lights_fraction_visible_range", (DEFAULT_LIGHTS_FRACTION_VISIBLE, DEFAULT_LIGHTS_FRACTION_VISIBLE))
    lights_fraction_replace_rng     = param_dict.get("lights_fraction_replaceable_range", (DEFAULT_LIGHTS_FRACTION_REPLACEABLE, DEFAULT_LIGHTS_FRACTION_REPLACEABLE))
    lights_fraction_return_air_rng  = param_dict.get("lights_fraction_return_air_range", (DEFAULT_LIGHTS_FRACTION_RETURN_AIR, DEFAULT_LIGHTS_FRACTION_RETURN_AIR))
    equip_fraction_radiant_rng      = param_dict.get("equip_fraction_radiant_range", (DEFAULT_EQUIP_FRACTION_RADIANT, DEFAULT_EQUIP_FRACTION_RADIANT))
    equip_fraction_lost_rng         = param_dict.get("equip_fraction_lost_range", (DEFAULT_EQUIP_FRACTION_LOST, DEFAULT_EQUIP_FRACTION_LOST))

    print(f"[DEBUG assign_light_params] Initial ranges from param_dict/defaults (before overrides):")
    print(f"  LIGHTS_WM2_range: {lights_rng} {'(from param_dict)' if 'LIGHTS_WM2_range' in param_dict else '(default const)'}")
    print(f"  PARASITIC_WM2_range: {parasitic_rng} {'(from param_dict)' if 'PARASITIC_WM2_range' in param_dict else '(default const)'}")
    print(f"  tD_range: {tD_rng} {'(from param_dict)' if 'tD_range' in param_dict else '(default const)'}")
    print(f"  tN_range: {tN_rng} {'(from param_dict)' if 'tN_range' in param_dict else '(default const)'}")
    print(f"  lights_fraction_radiant_range: {lights_fraction_radiant_rng} {'(from param_dict)' if 'lights_fraction_radiant_range' in param_dict else '(default const)'}")
    print(f"  lights_fraction_visible_range: {lights_fraction_visible_rng} {'(from param_dict)' if 'lights_fraction_visible_range' in param_dict else '(default const)'}")
    print(f"  lights_fraction_replaceable_range: {lights_fraction_replace_rng} {'(from param_dict)' if 'lights_fraction_replaceable_range' in param_dict else '(default const)'}")
    print(f"  lights_fraction_return_air_range: {lights_fraction_return_air_rng} {'(from param_dict)' if 'lights_fraction_return_air_range' in param_dict else '(default const)'}")
    print(f"  equip_fraction_radiant_range: {equip_fraction_radiant_rng} {'(from param_dict)' if 'equip_fraction_radiant_range' in param_dict else '(default const)'}")
    print(f"  equip_fraction_lost_range: {equip_fraction_lost_rng} {'(from param_dict)' if 'equip_fraction_lost_range' in param_dict else '(default const)'}")

    # (E) Find any user overrides that apply
    if user_config is not None:
        matches = find_applicable_overrides(building_id, sub_type, age_range, user_config)
    else:
        matches = []
    
    # This debug print is already in your code and is useful:
    print(f"[DEBUG lighting] bldg_id={building_id}, type='{sub_type}', matched overrides => {matches}") # Original debug line

    # (F) Override default ranges with user-config
    if matches:
        print(f"[DEBUG assign_light_params] Applying {len(matches)} overrides...")
    for row_idx, row in enumerate(matches):
        pname = row.get("param_name", "").strip().lower()
        fv = row.get("fixed_value", None) 
        mn = row.get("min_val", None)
        mx = row.get("max_val", None)
        
        current_rng = None
        if fv is not None: current_rng = (float(fv), float(fv))
        elif mn is not None and mx is not None: current_rng = (float(mn), float(mx))
        
        if current_rng:
            print(f"  [DEBUG assign_light_params] Override {row_idx+1}: param='{pname}', new_range={current_rng}")
            if pname == "lights_wm2": lights_rng = current_rng
            elif pname == "parasitic_wm2": parasitic_rng = current_rng
            elif pname == "td": tD_rng = current_rng
            elif pname == "tn": tN_rng = current_rng
            elif pname == "lights_fraction_radiant": lights_fraction_radiant_rng = current_rng
            elif pname == "lights_fraction_visible": lights_fraction_visible_rng = current_rng
            elif pname == "lights_fraction_replaceable": lights_fraction_replace_rng = current_rng
            elif pname == "lights_fraction_return_air": lights_fraction_return_air_rng = current_rng
            elif pname == "equip_fraction_radiant": equip_fraction_radiant_rng = current_rng
            elif pname == "equip_fraction_lost": equip_fraction_lost_rng = current_rng
            else: print(f"    [DEBUG assign_light_params] Unrecognized param_name '{pname}' in override row.")
        else:
            print(f"  [DEBUG assign_light_params] Override {row_idx+1} for '{pname}' skipped (no fixed_value or min/max_val).")
    
    if matches: print(f"[DEBUG assign_light_params] Ranges after overrides: lights_rng={lights_rng}, parasitic_rng={parasitic_rng}, etc.")

    # (G) Pick final values
    def pick_val(param_name, r): # Added param_name for better logging
        val = None
        if strategy == "A": val = (r[0] + r[1]) / 2.0
        elif strategy == "B": val = random.uniform(r[0], r[1])
        else: val = r[0]
        print(f"  [DEBUG assign_light_params] pick_val for '{param_name}': range={r}, strategy='{strategy}', picked={val}")
        return val

    assigned_lights = pick_val("lights_wm2", lights_rng)
    assigned_paras  = pick_val("parasitic_wm2", parasitic_rng)
    assigned_tD     = pick_val("tD", tD_rng)
    assigned_tN     = pick_val("tN", tN_rng)
    assigned_lights_frac_rad = pick_val("lights_fraction_radiant", lights_fraction_radiant_rng)
    assigned_lights_frac_vis = pick_val("lights_fraction_visible", lights_fraction_visible_rng)
    assigned_lights_frac_rep = pick_val("lights_fraction_replaceable", lights_fraction_replace_rng)
    assigned_lights_frac_ret = pick_val("lights_fraction_return_air", lights_fraction_return_air_rng)
    assigned_equip_frac_rad  = pick_val("equip_fraction_radiant", equip_fraction_radiant_rng)
    assigned_equip_frac_lost = pick_val("equip_fraction_lost", equip_fraction_lost_rng)
    
    # (H) Build final dict
    assigned = {
        "lights_wm2": {"assigned_value": assigned_lights, "min_val": lights_rng[0], "max_val": lights_rng[1], "object_name": "LIGHTS"},
        "parasitic_wm2": {"assigned_value": assigned_paras, "min_val": parasitic_rng[0], "max_val": parasitic_rng[1], "object_name": "ELECTRICEQUIPMENT"},
        "tD": {"assigned_value": assigned_tD, "min_val": tD_rng[0], "max_val": tD_rng[1], "object_name": "LIGHTS_SCHEDULE"},
        "tN": {"assigned_value": assigned_tN, "min_val": tN_rng[0], "max_val": tN_rng[1], "object_name": "LIGHTS_SCHEDULE"},
        "lights_fraction_radiant": {"assigned_value": assigned_lights_frac_rad, "min_val": lights_fraction_radiant_rng[0], "max_val": lights_fraction_radiant_rng[1], "object_name": "LIGHTS.Fraction_Radiant"},
        "lights_fraction_visible": {"assigned_value": assigned_lights_frac_vis, "min_val": lights_fraction_visible_rng[0], "max_val": lights_fraction_visible_rng[1], "object_name": "LIGHTS.Fraction_Visible"},
        "lights_fraction_replaceable": {"assigned_value": assigned_lights_frac_rep, "min_val": lights_fraction_replace_rng[0], "max_val": lights_fraction_replace_rng[1], "object_name": "LIGHTS.Fraction_Replaceable"},
        "lights_fraction_return_air": {"assigned_value": assigned_lights_frac_ret, "min_val": lights_fraction_return_air_rng[0], "max_val": lights_fraction_return_air_rng[1], "object_name": "LIGHTS.Return_Air_Fraction"},
        "equip_fraction_radiant": {"assigned_value": assigned_equip_frac_rad, "min_val": equip_fraction_radiant_rng[0], "max_val": equip_fraction_radiant_rng[1], "object_name": "ELECTRICEQUIPMENT.Fraction_Radiant"},
        "equip_fraction_lost": {"assigned_value": assigned_equip_frac_lost, "min_val": equip_fraction_lost_rng[0], "max_val": equip_fraction_lost_rng[1], "object_name": "ELECTRICEQUIPMENT.Fraction_Lost"}
    }
    print(f"[DEBUG assign_light_params] Final assigned dict structure: {assigned}")

    # (I) Optionally store in assigned_log
    if assigned_log is not None:
        assigned_log[building_id] = assigned
    
    print(f"--- [END DEBUG assign_lighting_parameters for bldg_id {building_id}] ---")
    return assigned
------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\Elec\constants.py
============================================================
# Elec/constants.py

"""
Global constants or default fallback values for the lighting module.
These can be overridden by user configs or Excel-based overrides.
"""

# Default power density values (W/m²)
DEFAULT_LIGHTING_WM2 = 10.0
DEFAULT_PARASITIC_WM2 = 0.285

# Default burning hours if not found in the lookup
DEFAULT_TD = 2000
DEFAULT_TN = 300

# Optional: If you want fraction parameter defaults here
# (instead of defining them in the fallback block of assign_lighting_values.py),
# you can do so, e.g.:
DEFAULT_LIGHTS_FRACTION_RADIANT = 0.7
DEFAULT_LIGHTS_FRACTION_VISIBLE = 0.2
DEFAULT_LIGHTS_FRACTION_REPLACEABLE = 1.0
DEFAULT_LIGHTS_FRACTION_RETURN_AIR = 0.0

DEFAULT_EQUIP_FRACTION_RADIANT = 0.0
DEFAULT_EQUIP_FRACTION_LOST = 1.0

# You can import & use these defaults in assign_lighting_values.py
# or wherever you handle fraction parameters.

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\Elec\lighting_lookup.py
============================================================
# Elec/lighting_lookup.py

"""
Lighting Lookup Table (Pre/Post Calibration)
---------------------------------------------
This version includes fraction parameters for both LIGHTS
and ELECTRICEQUIPMENT objects.

NOTE (รอบนี้): The "LIGHTS_WM2_range" values below for non-residential pre_calibration
have been FURTHER ADJUSTED to represent MORE ENERGY-EFFICIENT lighting scenarios.
These are ILLUSTRATIVE examples aiming for good practice levels and MUST BE
VALIDATED against specific project requirements and local standards (e.g., NTA 8800).
The tD_range and tN_range are NOT directly used by the EnergyPlus LIGHTS object's
energy calculation in the provided scripts; schedules from schedule_def.py are used.
"""

lighting_lookup = {
    "pre_calibration": {
        # ===============================
        # 1) RESIDENTIAL (all sub-types)
        # ===============================
        # LPD values remain 0.0 as per original; implies residential lighting
        # is accounted for elsewhere or via a different methodology in your project.
        "Residential": {
            "Corner House": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0), # No separate parasitic if main LPD is 0
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Apartment": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Terrace or Semi-detached House": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Detached House": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Two-and-a-half-story House": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            }
        },

        # ===============================
        # 2) NON-RESIDENTIAL (Values further adjusted for higher efficiency)
        # ===============================
        "Non-Residential": {
            "Office Function": {
                "LIGHTS_WM2_range": (4.0, 7.0),    # Efficient office LPD
                "PARASITIC_WM2_range": (0.1, 0.15), # Lowered for efficient drivers
                "tD_range": (2000, 2500),
                "tN_range": (100, 200),
                "lights_fraction_radiant_range": (0.6, 0.7),
                "lights_fraction_visible_range": (0.2, 0.25),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Retail Function": { # General ambient lighting; display can be extra or averaged in
                "LIGHTS_WM2_range": (6.0, 12.0),   # Lowered significantly
                "PARASITIC_WM2_range": (0.15, 0.25),
                "tD_range": (3000, 4000),
                "tN_range": (200, 400),
                "lights_fraction_radiant_range": (0.6, 0.7),
                "lights_fraction_visible_range": (0.2, 0.25),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            },
            "Education Function": { # Classrooms, libraries
                "LIGHTS_WM2_range": (3.5, 6.0),    # Efficient school lighting
                "PARASITIC_WM2_range": (0.1, 0.15),
                "tD_range": (1500, 1800),
                "tN_range": (50, 100),
                "lights_fraction_radiant_range": (0.6, 0.7),
                "lights_fraction_visible_range": (0.2, 0.25),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            },
            "Healthcare Function": { # General areas; labs/surgery distinct
                "LIGHTS_WM2_range": (5.0, 9.0),    # Lowered for general patient/corridor areas
                "PARASITIC_WM2_range": (0.15, 0.25),
                "tD_range": (3000, 5000),
                "tN_range": (500, 1000),
                "lights_fraction_radiant_range": (0.6, 0.7),
                "lights_fraction_visible_range": (0.2, 0.25),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            },
            "Meeting Function": {
                "LIGHTS_WM2_range": (5.0, 8.0),
                "PARASITIC_WM2_range": (0.1, 0.15),
                "tD_range": (1800, 2200),
                "tN_range": (200, 300),
                "lights_fraction_radiant_range": (0.6, 0.7),
                "lights_fraction_visible_range": (0.2, 0.25),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            },
            "Sport Function": {
                "LIGHTS_WM2_range": (7.0, 11.0), # Maintained, as sports lighting can be intensive
                "PARASITIC_WM2_range": (0.15, 0.25),
                "tD_range": (2000, 2500),
                "tN_range": (500, 800),
                "lights_fraction_radiant_range": (0.5, 0.6),
                "lights_fraction_visible_range": (0.25, 0.3),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            },
            "Cell Function": {
                "LIGHTS_WM2_range": (4.0, 7.0), # Lowered
                "PARASITIC_WM2_range": (0.1, 0.15),
                "tD_range": (6000, 8000),
                "tN_range": (6000, 8000),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            },
            "Industrial Function": { # General lighting, not process-specific
                "LIGHTS_WM2_range": (5.0, 9.0), # Lowered
                "PARASITIC_WM2_range": (0.1, 0.2),
                "tD_range": (2500, 4000),
                "tN_range": (100, 300),
                "lights_fraction_radiant_range": (0.5, 0.6),
                "lights_fraction_visible_range": (0.25, 0.3),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            },
            "Accommodation Function": { # Guest rooms / dorms
                "LIGHTS_WM2_range": (3.0, 6.0), # Lowered
                "PARASITIC_WM2_range": (0.1, 0.15),
                "tD_range": (1500, 2500),
                "tN_range": (3000, 5000),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            },
            "Other Use Function": {
                "LIGHTS_WM2_range": (5.0, 8.0), # Lowered
                "PARASITIC_WM2_range": (0.1, 0.2),
                "tD_range": (2000, 2500),
                "tN_range": (100, 300),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (0.0, 0.0),
            }
        }
    },
    "post_calibration": {
        # Post-calibration values are highly project-specific and should be
        # determined by actual calibration efforts.
        # The structure from your original file is maintained as a placeholder.
        "Residential": {
            "Corner House": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Apartment": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Terrace or Semi-detached House": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Detached House": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Two-and-a-half-story House": {
                "LIGHTS_WM2_range": (0.0, 0.0),
                "PARASITIC_WM2_range": (0.0, 0.0),
                "tD_range": (0, 0),
                "tN_range": (0, 0),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            }
        },
        "Non-Residential": {
            "Meeting Function": {
                "LIGHTS_WM2_range": (17.0, 17.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (2200, 2200),
                "tN_range": (300, 300),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Healthcare Function": {
                "LIGHTS_WM2_range": (18.0, 18.0),
                "PARASITIC_WM2_range": (0.29, 0.29),
                "tD_range": (4000, 4000),
                "tN_range": (1000, 1000),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Sport Function": {
                "LIGHTS_WM2_range": (17.0, 17.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (2200, 2200),
                "tN_range": (800, 800),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Cell Function": {
                "LIGHTS_WM2_range": (17.0, 17.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (4000, 4000),
                "tN_range": (1000, 1000),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Retail Function": {
                "LIGHTS_WM2_range": (30.0, 30.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (2700, 2700),
                "tN_range": (400, 400),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Industrial Function": {
                "LIGHTS_WM2_range": (17.0, 17.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (2200, 2200),
                "tN_range": (300, 300),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Accommodation Function": {
                "LIGHTS_WM2_range": (17.0, 17.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (4000, 4000),
                "tN_range": (1000, 1000),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Office Function": {
                "LIGHTS_WM2_range": (16.0, 16.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (2200, 2200),
                "tN_range": (300, 300),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Education Function": {
                "LIGHTS_WM2_range": (15.0, 15.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (1600, 1600),
                "tN_range": (300, 300),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            },
            "Other Use Function": {
                "LIGHTS_WM2_range": (16.0, 16.0),
                "PARASITIC_WM2_range": (0.285, 0.285),
                "tD_range": (2200, 2200),
                "tN_range": (300, 300),
                "lights_fraction_radiant_range": (0.7, 0.7),
                "lights_fraction_visible_range": (0.2, 0.2),
                "lights_fraction_replaceable_range": (1.0, 1.0),
                "lights_fraction_return_air_range": (0.0, 0.0),
                "equip_fraction_radiant_range": (0.0, 0.0),
                "equip_fraction_lost_range": (1.0, 1.0),
            }
        }
    }
}
------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\Elec\lighting.py
============================================================
# File: D:\Documents\E_Plus_2030_py\idf_objects\Elec\lighting.py

from .assign_lighting_values import assign_lighting_parameters
from .schedules import create_lighting_schedule, create_parasitic_schedule

def get_building_category_and_subtype(building_row):
    """
    Return (building_category, sub_type) based on ``building_row``.
    It now correctly uses 'residential_type' or 'non_residential_type'
    based on the value of 'building_function', and handles potential float inputs.
    """
    
    print(f"\n--- [DEBUG get_category_subtype] ---")
    
    # Get raw values first for logging their original types
    raw_building_function = building_row.get("building_function")
    raw_residential_type = building_row.get("residential_type")
    raw_non_residential_type = building_row.get("non_residential_type")

    print(f"[DEBUG get_category_subtype] Raw building_row.get('building_function'): '{raw_building_function}' (type: {type(raw_building_function)})")
    print(f"[DEBUG get_category_subtype] Raw building_row.get('residential_type'): '{raw_residential_type}' (type: {type(raw_residential_type)})")
    print(f"[DEBUG get_category_subtype] Raw building_row.get('non_residential_type'): '{raw_non_residential_type}' (type: {type(raw_non_residential_type)})")

    # Convert to string, then strip/lower. Default to "" if key is missing before str().
    building_function_str = str(building_row.get("building_function", ""))
    residential_type_str = str(building_row.get("residential_type", ""))
    non_residential_type_str = str(building_row.get("non_residential_type", ""))

    # Debug after string conversion
    print(f"[DEBUG get_category_subtype] Stringified building_function: '{building_function_str}'")
    print(f"[DEBUG get_category_subtype] Stringified residential_type: '{residential_type_str}'")
    print(f"[DEBUG get_category_subtype] Stringified non_residential_type: '{non_residential_type_str}'")

    building_function_val = building_function_str.strip().lower()
    residential_type_val = residential_type_str.strip() # Specific types should retain their case for lookup
    non_residential_type_val = non_residential_type_str.strip() # Specific types should retain their case
    
    print(f"[DEBUG get_category_subtype] Processed building_function_val (lowercase, stripped): '{building_function_val}'")
    print(f"[DEBUG get_category_subtype] Processed residential_type_val (stripped): '{residential_type_val}'")
    print(f"[DEBUG get_category_subtype] Processed non_residential_type_val (stripped): '{non_residential_type_val}'")

    building_category = None
    sub_type_for_lookup = None
    
    # Check for "empty" or non-informative strings like "nan" or "none" after stripping
    def is_valid_type_string(s):
        if not s: return False
        s_lower = s.lower()
        return s_lower != 'nan' and s_lower != 'none' and s_lower != '<na>' # Common pandas NA string representation

    if building_function_val == "residential":
        if is_valid_type_string(residential_type_val):
            building_category = "Residential"
            sub_type_for_lookup = residential_type_val # Use the value with original casing
            print(f"[DEBUG get_category_subtype] 'building_function' is 'residential'. Using 'residential_type': '{sub_type_for_lookup}' as sub_type.")
        else:
            print(f"[DEBUG get_category_subtype] WARNING: 'building_function' is 'residential' but 'residential_type' ('{residential_type_val}') is empty or non-informative.")
            building_category = "Residential"
            sub_type_for_lookup = "Apartment" # Fallback to a default specific residential type
            print(f"[DEBUG get_category_subtype] Defaulting to category='{building_category}', sub_type='{sub_type_for_lookup}' due to problematic residential_type.")
            
    elif building_function_val == "non_residential":
        if is_valid_type_string(non_residential_type_val):
            building_category = "Non-Residential"
            sub_type_for_lookup = non_residential_type_val # Use the value with original casing
            print(f"[DEBUG get_category_subtype] 'building_function' is 'non_residential'. Using 'non_residential_type': '{sub_type_for_lookup}' as sub_type.")
        else:
            print(f"[DEBUG get_category_subtype] WARNING: 'building_function' is 'non_residential' but 'non_residential_type' ('{non_residential_type_val}') is empty or non-informative.")
            building_category = "Non-Residential"
            sub_type_for_lookup = "Other Use Function" # Fallback to a default specific non-residential type
            print(f"[DEBUG get_category_subtype] Defaulting to category='{building_category}', sub_type='{sub_type_for_lookup}' due to problematic non_residential_type.")
            
    else: 
        # building_function itself might be the specific sub-type, or it's empty/invalid.
        # Use original casing for direct_bldg_func_val before stripping.
        direct_bldg_func_val_str = str(building_row.get("building_function", ""))
        direct_bldg_func_val_stripped = direct_bldg_func_val_str.strip()
        
        print(f"[DEBUG get_category_subtype] 'building_function' ('{direct_bldg_func_val_stripped}') is not 'residential' or 'non_residential'. Attempting direct categorization of this value.")
        
        if not is_valid_type_string(direct_bldg_func_val_stripped):
            print(f"[DEBUG get_category_subtype] Direct 'building_function' ('{direct_bldg_func_val_stripped}') is empty or non-informative. Defaulting to Non-Residential, Other Use Function.")
            building_category = "Non-Residential"
            sub_type_for_lookup = "Other Use Function"
        else:
            sub_type_for_lookup = direct_bldg_func_val_stripped # This is the specific sub-type
            # Define known types here for this fallback path
            known_residential_sub_types = {
                "Apartment", "Corner House", "Detached House",
                "Terrace or Semi-detached House", "Two-and-a-half-story House",
            } # Ensure these match your lookup keys' casing
            known_non_residential_sub_types = {
                "Accommodation Function", "Cell Function", "Education Function",
                "Healthcare Function", "Industrial Function", "Meeting Function",
                "Office Function", "Other Use Function", "Retail Function", "Sport Function",
            } # Ensure these match your lookup keys' casing

            if sub_type_for_lookup in known_residential_sub_types:
                building_category = "Residential"
                print(f"[DEBUG get_category_subtype] Matched direct building_function '{sub_type_for_lookup}' to known_residential_sub_types.")
            elif sub_type_for_lookup in known_non_residential_sub_types:
                building_category = "Non-Residential"
                print(f"[DEBUG get_category_subtype] Matched direct building_function '{sub_type_for_lookup}' to known_non_residential_sub_types.")
            else:
                print(f"[DEBUG get_category_subtype] WARNING: Unknown direct building_function '{sub_type_for_lookup}'. Defaulting category to Non-Residential.")
                building_category = "Non-Residential" # Default for truly unknown specific types

    # Final safety net if logic above somehow fails to set category or sub_type adequately
    if not building_category or not is_valid_type_string(sub_type_for_lookup):
        print(f"[DEBUG get_category_subtype] CRITICAL FALLBACK: Could not determine valid category or sub_type (current sub_type: '{sub_type_for_lookup}'). Defaulting to Non-Residential, Other Use Function.")
        building_category = "Non-Residential"
        sub_type_for_lookup = "Other Use Function"

    print(f"[DEBUG get_category_subtype] Final Determined: building_category='{building_category}', sub_type_for_lookup='{sub_type_for_lookup}'")
    print(f"--- [END DEBUG get_category_subtype] ---")
    return (building_category, sub_type_for_lookup)


# The rest of your Elec/lighting.py file (add_lights_and_parasitics function) remains the same
# as the version I provided in the previous message with its own debug prints.
# Ensure it uses this updated get_building_category_and_subtype function.

def add_lights_and_parasitics(
    idf,
    building_row,
    calibration_stage="pre_calibration",
    strategy="A",
    random_seed=None,
    user_config=None,
    assigned_values_log=None,
    zonelist_name="ALL_ZONES"
):
    """
    1) Determine building_category (Residential/Non-Residential) and sub_type.
    2) Retrieve assigned lighting parameters (including fraction fields).
    3) Create schedules in IDF:
       - A lighting schedule for the LIGHTS object
       - An always-on parasitic schedule for ELECTRICEQUIPMENT
    4) Add LIGHTS and ELECTRICEQUIPMENT objects referencing a ZoneList in the IDF.

    The assigned parameters and final picks are stored in assigned_values_log[ogc_fid]
    if assigned_values_log is provided.
    """

    # 1) Get building_category / sub_type
    building_category, sub_type = get_building_category_and_subtype(building_row) 
    
    # 2) Retrieve lighting parameters
    bldg_id = int(building_row.get("ogc_fid", 0)) 
    print(f"\n--- [DEBUG add_lights_and_parasitics for bldg_id {bldg_id}] ---") 
    print(f"[DEBUG add_lights_and_parasitics] From get_building_category_and_subtype: category='{building_category}', sub_type='{sub_type}'")


    assigned_dict = assign_lighting_parameters( 
        building_id=bldg_id,
        building_category=building_category,
        sub_type=sub_type,
        age_range=building_row.get("age_range", None), 
        calibration_stage=calibration_stage,
        strategy=strategy,
        random_seed=random_seed,
        user_config=user_config,
        assigned_log=assigned_values_log 
    )

    lights_wm2 = assigned_dict["lights_wm2"]["assigned_value"]
    parasitic_wm2 = assigned_dict["parasitic_wm2"]["assigned_value"]
    lights_frac_radiant = assigned_dict["lights_fraction_radiant"]["assigned_value"]
    lights_frac_visible = assigned_dict["lights_fraction_visible"]["assigned_value"]
    lights_frac_replace = assigned_dict["lights_fraction_replaceable"]["assigned_value"]
    lights_frac_return  = assigned_dict["lights_fraction_return_air"]["assigned_value"]

    # Extract fraction parameters for EQUIPMENT
    equip_frac_radiant = assigned_dict["equip_fraction_radiant"]["assigned_value"]
    equip_frac_lost = assigned_dict["equip_fraction_lost"]["assigned_value"]

    lights_sched_name = create_lighting_schedule(
        idf, building_category=building_category, sub_type=sub_type, schedule_name="LightsSchedule"
    )
    paras_sched_name = create_parasitic_schedule(idf, sched_name="ParasiticSchedule")

    lights_obj = idf.newidfobject("LIGHTS")
    lights_obj.Name = f"Lights_{zonelist_name}"
    lights_obj.Zone_or_ZoneList_or_Space_or_SpaceList_Name = zonelist_name
    lights_obj.Schedule_Name = lights_sched_name
    lights_obj.Design_Level_Calculation_Method = "Watts/Area"
    lights_obj.Watts_per_Zone_Floor_Area = lights_wm2
    lights_obj.Fraction_Radiant = lights_frac_radiant
    lights_obj.Fraction_Visible = lights_frac_visible
    lights_obj.Fraction_Replaceable = lights_frac_replace
    if hasattr(lights_obj, "Return_Air_Fraction"):
        lights_obj.Return_Air_Fraction = lights_frac_return

    eq_obj = idf.newidfobject("ELECTRICEQUIPMENT")
    eq_obj.Name = f"Parasitic_{zonelist_name}"
    eq_obj.Zone_or_ZoneList_or_Space_or_SpaceList_Name = zonelist_name
    eq_obj.Schedule_Name = paras_sched_name
    eq_obj.Design_Level_Calculation_Method = "Watts/Area"
    eq_obj.Watts_per_Zone_Floor_Area = parasitic_wm2
    eq_obj.Fraction_Radiant = equip_frac_radiant
    eq_obj.Fraction_Lost = equip_frac_lost
    
    print(f"[DEBUG add_lights_and_parasitics] Successfully created LIGHTS and ELECTRICEQUIPMENT objects for bldg_id {bldg_id}.")
    print(f"--- [END DEBUG add_lights_and_parasitics for bldg_id {bldg_id}] ---")
    return lights_obj, eq_obj
------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\Elec\schedule_def.py
============================================================
# Elec/schedule_def.py

import pandas as pd # Keep import if excel reading functions are used

"""
This file holds:
1) A default SCHEDULE_DEFINITIONS dictionary for lighting usage patterns
   (weekday vs. weekend) for Residential & Non-Residential sub-types.
2) (Optional) Functions to read & apply schedule overrides from Excel.

NOTE (รอบนี้): The non-residential schedules below have been FURTHER REFINED
to represent more energy-conscious operational patterns. These are ILLUSTRATIVE
examples and MUST BE VALIDATED and customized based on specific project
requirements, occupancy data, control strategies, and local standards
(e.g., NTA 8800 usage profiles for the Netherlands).
"""

# 1) Default SCHEDULE Definitions
SCHEDULE_DEFINITIONS = {
    "Residential": {
        # Residential schedules - minor adjustments for potentially lower unoccupied use
        "Corner House": {
            "weekday": [(0, 6, 0.03), (6, 9, 0.25), (9, 17, 0.08), (17, 22, 0.45), (22, 24, 0.03)],
            "weekend": [(0, 7, 0.05), (7, 22, 0.35), (22, 24, 0.05)],
        },
        "Apartment": {
            "weekday": [(0, 6, 0.02), (6, 8, 0.20), (8, 18, 0.05), (18, 23, 0.40), (23, 24, 0.02)],
            "weekend": [(0, 8, 0.04), (8, 22, 0.30), (22, 24, 0.04)],
        },
        "Terrace or Semi-detached House": { # Similar to Corner House
            "weekday": [(0, 6, 0.03), (6, 9, 0.25), (9, 17, 0.08), (17, 22, 0.45), (22, 24, 0.03)],
            "weekend": [(0, 7, 0.05), (7, 22, 0.35), (22, 24, 0.05)],
        },
        "Detached House": {
            "weekday": [(0, 6, 0.04), (6, 9, 0.30), (9, 17, 0.10), (17, 22, 0.50), (22, 24, 0.04)],
            "weekend": [(0, 7, 0.06), (7, 23, 0.40), (23, 24, 0.06)],
        },
        "Two-and-a-half-story House": { # Similar to Detached or Corner House
            "weekday": [(0, 6, 0.03), (6, 9, 0.25), (9, 17, 0.08), (17, 22, 0.45), (22, 24, 0.03)],
            "weekend": [(0, 7, 0.05), (7, 22, 0.35), (22, 24, 0.05)],
        },
    },
    "Non-Residential": {
        "Office Function": { # Assumes good practice, e.g. 8:00-18:00 core hours
            "weekday": [
                (0, 7, 0.02),   # Unoccupied / Cleaning minimal
                (7, 8, 0.15),   # Early arrivals / Setup
                (8, 12, 0.80),  # Morning peak (potentially lower with daylighting)
                (12, 13, 0.30), # Lunch (reduced lighting in some areas)
                (13, 17, 0.80), # Afternoon peak
                (17, 18, 0.25), # Late leavers / Winding down
                (18, 24, 0.02),  # Unoccupied
            ],
            "weekend": [ # Minimal, for security/occasional access
                (0, 24, 0.02),
            ],
        },
        "Retail Function": { # Core hours e.g., 10:00-18:00/19:00
            "weekday": [
                (0, 8, 0.01),   # Closed, security minimal
                (8, 10, 0.20),  # Staff prep, partial lighting
                (10, 18, 0.80), # Open - peak (could be higher for specific display, lower for ambient)
                (18, 19, 0.30), # Closing
                (19, 24, 0.01),  # Closed
            ],
            "weekend": [ # Assuming Saturday is similar to weekday, Sunday potentially shorter/lower
                (0, 9, 0.01),
                (9, 17, 0.75),  # e.g. Sunday hours
                (17, 18, 0.25),
                (18, 24, 0.01),
            ],
        },
        "Education Function": { # Schools/Universities during term
            "weekday": [
                (0, 7, 0.01),   # Closed
                (7, 8, 0.20),   # Staff arrival
                (8, 12, 0.75),  # Morning classes (daylight responsive could lower this)
                (12, 13, 0.25), # Lunch break (some areas lit)
                (13, 16, 0.75), # Afternoon classes
                (16, 18, 0.15), # After school activities / cleaning
                (18, 24, 0.01),  # Closed
            ],
            "weekend": [
                (0, 24, 0.01),  # Mostly closed
            ],
        },
        "Healthcare Function": { # Highly complex; this profile attempts some variation.
                                 # Assumes lower ambient light at night in patient areas/corridors.
            "weekday": [
                (0, 6, 0.25),   # Night (essential + reduced ambient)
                (6, 20, 0.65),  # Daytime operational (average across various spaces)
                (20, 24, 0.30), # Evening/early night
            ],
            "weekend": [ # Similar pattern, potentially slightly less intensive in admin areas
                (0, 6, 0.20),
                (6, 20, 0.60),
                (20, 24, 0.25),
            ],
        },
        "Meeting Function": {
            "weekday": [
                (0, 8, 0.01),
                (8, 9, 0.25),
                (9, 12, 0.70),
                (12, 13, 0.30),
                (13, 17, 0.70),
                (17, 18, 0.20),
                (18, 24, 0.01),
            ],
            "weekend": [
                (0, 24, 0.01),
            ],
        },
        "Sport Function": {
            "weekday": [
                (0, 7, 0.01),
                (7, 16, 0.50), # Daytime use / classes
                (16, 22, 0.80), # Evening peak
                (22, 24, 0.02),
            ],
            "weekend": [
                (0, 8, 0.01),
                (8, 20, 0.70), # Weekend peak
                (20, 24, 0.02),
            ],
        },
        "Cell Function": { # Constant low level for safety/security might be needed
            "weekday": [(0, 24, 0.40)], # Assuming dimmable, efficient, not full blast 24/7
            "weekend": [(0, 24, 0.40)],
        },
        "Industrial Function": { # Assuming single or double shift, not 24/7 production
            "weekday": [
                (0, 6, 0.02),   # Unoccupied
                (6, 18, 0.70),  # Main operational hours (e.g. 1 or 2 shifts)
                (18, 22, 0.10), # Cleaning / end of day
                (22, 24, 0.02),
            ],
            "weekend": [(0, 24, 0.02)], # Mostly off
        },
        "Accommodation Function": { # Hotels: diverse use in rooms, common areas more consistent
            "weekday": [ # Weighted average behavior
                (0, 6, 0.20),   # Night (corridors, some room use)
                (6, 10, 0.40),  # Morning peak
                (10, 17, 0.25), # Daytime (rooms variable, common areas moderate)
                (17, 23, 0.60), # Evening
                (23, 24, 0.20),
            ],
            "weekend": [ # Similar pattern, potentially higher occupancy
                (0, 6, 0.25),
                (6, 11, 0.50),
                (11, 17, 0.35),
                (17, 23, 0.65),
                (23, 24, 0.25),
            ],
        },
        "Other Use Function": {
            "weekday": [
                (0, 7, 0.02),
                (7, 19, 0.50), 
                (19, 24, 0.02),
            ],
            "weekend": [
                (0, 24, 0.05), 
            ],
        },
    },
}

# Functions to read/apply Excel overrides (kept as is)
def read_schedule_overrides_from_excel(excel_path):
    df = pd.read_excel(excel_path)
    required_cols = ["building_category", "sub_type", "day_type", 
                     "start_hour", "end_hour", "fraction_value"]
    for c in required_cols:
        if c not in df.columns:
            raise ValueError(f"Missing column '{c}' in {excel_path}")
    overrides = {}
    for _, row in df.iterrows():
        cat = str(row["building_category"]).strip()
        stype = str(row["sub_type"]).strip()
        dtype = str(row["day_type"]).strip().lower()
        sh = float(row["start_hour"])
        eh = float(row["end_hour"])
        frac = float(row["fraction_value"])
        overrides.setdefault(cat, {}).setdefault(stype, {}).setdefault(dtype, []).append((sh, eh, frac))
    return overrides

def apply_schedule_overrides_to_schedules(base_schedules, overrides):
    for cat, stype_dict in overrides.items():
        base_schedules.setdefault(cat, {})
        for stype, daytypes_dict in stype_dict.items():
            base_schedules[cat].setdefault(stype, {})
            for day_type, blocks_list in daytypes_dict.items():
                base_schedules[cat][stype][day_type] = blocks_list
    return base_schedules
------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\Elec\schedules.py
============================================================
# Elec/schedules.py

from .schedule_def import SCHEDULE_DEFINITIONS

"""
This module creates detailed lighting schedules for weekdays and weekends,
differentiating by building_category (Residential/Non-Residential)
and by sub_type (Apartment, Office Function, etc.).

We have two main functions:
1) create_lighting_schedule(idf, building_category, sub_type, schedule_name)
   - Creates a SCHEDULE:COMPACT with different time blocks for 'WeekDays',
     'Saturday', and 'Sunday' (or 'AllDays' if you prefer).
2) create_parasitic_schedule(idf, sched_name)
   - Creates an always-on (1.0) schedule, typically for parasitic loads.

Important:
- This code assumes you already loaded or potentially overrode
  SCHEDULE_DEFINITIONS in schedule_def.py (for instance, by calling
  `read_schedule_overrides_from_excel()` + `apply_schedule_overrides_to_schedules()`).
- If you want more advanced day-splitting, feel free to expand the logic below.
"""


def create_lighting_schedule(idf, building_category, sub_type, schedule_name="LightsSchedule"):
    """
    Create a SCHEDULE:COMPACT in the IDF using SCHEDULE_DEFINITIONS[building_category][sub_type].
    We define separate blocks for:
      - For: WeekDays
      - For: Saturday
      - For: Sunday

    If the sub_type is missing in SCHEDULE_DEFINITIONS, we fallback to a simple always-0.5 pattern.

    The final IDF object name is `schedule_name`. We return that string for convenience.
    """

    # Attempt to get sub-type dictionary from SCHEDULE_DEFINITIONS
    try:
        sub_dict = SCHEDULE_DEFINITIONS[building_category][sub_type]
    except KeyError:
        # Fallback: If not found, create a simple always-0.5 schedule
        sub_dict = {
            "weekday": [(0, 24, 0.5)],
            "weekend": [(0, 24, 0.5)],
        }

    # Some sub-types might not have a separate weekend pattern. 
    # So ensure we have 'weekday' and 'weekend' keys:
    if "weekday" not in sub_dict:
        sub_dict["weekday"] = [(0, 24, 0.5)]
    if "weekend" not in sub_dict:
        sub_dict["weekend"] = [(0, 24, 0.5)]

    # Create the schedule object
    schedule = idf.newidfobject("SCHEDULE:COMPACT")
    schedule.Name = schedule_name
    schedule.Schedule_Type_Limits_Name = "Fraction"

    # We'll define the entire year with "Through: 12/31" and break it down by day types
    # The pattern is:
    #   Field_1:  "Through: 12/31"
    #   Field_2:  "For: WeekDays"
    #   Field_3+: "Until: HH:MM,<fraction>"
    #
    # Then for Saturday, Sunday, etc.

    field_idx = 1
    setattr(schedule, f"Field_{field_idx}", "Through: 12/31")
    field_idx += 1

    # 1) WeekDays
    setattr(schedule, f"Field_{field_idx}", "For: WeekDays")
    field_idx += 1
    for (start_hour, end_hour, frac) in sub_dict["weekday"]:
        # e.g. "Until: 06:00,0.05"
        setattr(schedule, f"Field_{field_idx}",
                f"Until: {int(end_hour):02d}:00,{frac:.2f}")
        field_idx += 1

    # 2) Saturday
    setattr(schedule, f"Field_{field_idx}", "For: Saturday")
    field_idx += 1
    for (start_hour, end_hour, frac) in sub_dict["weekend"]:
        setattr(schedule, f"Field_{field_idx}",
                f"Until: {int(end_hour):02d}:00,{frac:.2f}")
        field_idx += 1

    # 3) Sunday
    setattr(schedule, f"Field_{field_idx}", "For: Sunday")
    field_idx += 1
    for (start_hour, end_hour, frac) in sub_dict["weekend"]:
        setattr(schedule, f"Field_{field_idx}",
                f"Until: {int(end_hour):02d}:00,{frac:.2f}")
        field_idx += 1

    return schedule.Name


def create_parasitic_schedule(idf, sched_name="ParasiticSchedule"):
    """
    Creates an always-on schedule (1.0) for parasitic loads (24/7).
    """
    schedule = idf.newidfobject("SCHEDULE:COMPACT")
    schedule.Name = sched_name
    schedule.Schedule_Type_Limits_Name = "Fraction"

    # Single block covering all days, 24 hours
    schedule.Field_1 = "Through: 12/31"
    schedule.Field_2 = "For: AllDays"
    schedule.Field_3 = "Until: 24:00,1.0"

    return schedule.Name

------------------------------------------------------------

