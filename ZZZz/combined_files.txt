File: D:\Documents\E_Plus_2030_py\validation\compare_sims_with_measured.py
============================================================
# validation/compare_sims_with_measured.py
import pandas as pd

def load_csv_as_df(real_data_path, sim_data_path):
    """
    Loads real and simulated data from CSV into DataFrames.
    Just a simple utility function, used if needed.
    """
    print(f"[DEBUG] Loading real data from: {real_data_path}")
    print(f"[DEBUG] Loading sim data  from: {sim_data_path}")

    df_real = pd.read_csv(real_data_path)
    df_sim  = pd.read_csv(sim_data_path)

    print("[DEBUG] df_real shape:", df_real.shape)
    print("[DEBUG] df_sim  shape:", df_sim.shape)
    print("[DEBUG] df_real columns:", df_real.columns.to_list())
    print("[DEBUG] df_sim columns: ", df_sim.columns.to_list())
    return df_real, df_sim


def align_data_for_variable(df_real, df_sim, real_building_id, sim_building_id, variable_name):
    """
    Returns aligned arrays of sim vs. obs for a given (real_building_id, sim_building_id, variable).
    - df_real and df_sim should be *already filtered* to the appropriate building + var
      (i.e., df_real_sub, df_sim_sub).
    - This function melts them from wide to long format and merges on 'Date'.

    Returns: (sim_values_array, obs_values_array, merged_dataframe)
    """

    # 1) Filter again for safety, though presumably df_real and df_sim are already subset
    real_sel = df_real[
        (df_real['BuildingID'] == real_building_id) &
        (df_real['VariableName'] == variable_name)
    ]
    sim_sel  = df_sim[
        (df_sim['BuildingID'] == sim_building_id) &
        (df_sim['VariableName'] == variable_name)
    ]

    # Debug prints
    print(f"   > Aligning real Bldg={real_building_id} vs sim Bldg={sim_building_id}, Var={variable_name}")
    print(f"   > real_sel shape={real_sel.shape}, sim_sel shape={sim_sel.shape}")

    # If empty, return empty arrays
    if real_sel.empty or sim_sel.empty:
        return [], [], pd.DataFrame()

    # 2) Melt from wide to long
    real_long = real_sel.melt(
        id_vars=['BuildingID','VariableName'],
        var_name='Date',
        value_name='Value'
    ).dropna(subset=['Value'])

    sim_long = sim_sel.melt(
        id_vars=['BuildingID','VariableName'],
        var_name='Date',
        value_name='Value'
    ).dropna(subset=['Value'])

    # 3) Merge on 'Date'
    merged = pd.merge(
        real_long[['Date','Value']],
        sim_long[['Date','Value']],
        on='Date', how='inner', suffixes=('_obs','_sim')
    )

    # 4) Return arrays plus the merged DataFrame
    return merged['Value_sim'].values, merged['Value_obs'].values, merged

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\validation\main_validation.py
============================================================
# main_validation.py
"""
validation/main_validation.py

This module provides a reusable function `run_validation_process` that:
- Reads user config for validation
- Calls validate_with_ranges(...) from validate_results_custom.py
- Prints and saves a CSV of metrics
- Optionally generates a bar chart (or time-series/scatter) if skip_plots is False

Added Feature:
- Uses config["variables_to_compare"] to restrict which VariableNames to validate.

Dependencies (unchanged):
- validation.compare_sims_with_measured
- validation.metrics
- validation.validate_results_custom (must be updated to accept `variables_to_compare`)
- validation.visualize
"""

import csv
import matplotlib.pyplot as plt

from validation.validate_results_custom import validate_with_ranges

def run_validation_process(config):
    """
    Runs a validation process based on a user config dict.

    Example config structure:
    {
        "real_data_csv": "path/to/real_data.csv",
        "sim_data_csv":  "path/to/sim_data.csv",
        "bldg_ranges":   { "0": [0, 1, 2], "1": [1] },
        "variables_to_compare": [
            "Electricity:Facility [J](Hourly)",
            "Heating:EnergyTransfer [J](Hourly)"
        ],
        "threshold_cv_rmse": 30.0,
        "skip_plots": false,
        "output_csv": "validation_report.csv"
    }
    """

    # 1) Extract config values
    real_data_csv     = config.get("real_data_csv", "")
    sim_data_csv      = config.get("sim_data_csv", "")
    bldg_ranges       = config.get("bldg_ranges", {})
    threshold_cv_rmse = config.get("threshold_cv_rmse", 30.0)
    skip_plots        = config.get("skip_plots", False)
    output_csv        = config.get("output_csv", "validation_report.csv")

    # NEW: A list of variable names to compare
    variables_to_compare = config.get("variables_to_compare", [])

    print(f"[INFO] Starting validation with:")
    print(f"   Real data CSV = {real_data_csv}")
    print(f"   Sim  data CSV = {sim_data_csv}")
    print(f"   Building Ranges = {bldg_ranges}")
    print(f"   Variables to Compare = {variables_to_compare}")
    print(f"   Threshold CV(RMSE) = {threshold_cv_rmse}")
    print(f"   skip_plots = {skip_plots}")
    print(f"   output_csv = {output_csv}")

    # 2) Call validate_with_ranges
    metric_results = validate_with_ranges(
        real_data_path=real_data_csv,
        sim_data_path=sim_data_csv,
        bldg_ranges=bldg_ranges,
        variables_to_compare=variables_to_compare,   # pass in the new argument
        threshold_cv_rmse=threshold_cv_rmse,
        skip_plots=skip_plots
    )

    # 3) Print summary to console
    print("\n=== Validation Summary ===")
    for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
        print(
            f"Real={real_bldg}, Sim={sim_bldg}, Var={var_name} => "
            f"MBE={mvals['MBE']:.2f}, "
            f"CV(RMSE)={mvals['CVRMSE']:.2f}, "
            f"NMBE={mvals['NMBE']:.2f}, "
            f"Pass={mvals['Pass']}"
        )

    # 4) Save metrics to CSV
    print(f"\n[INFO] Saving metrics to {output_csv}")
    with open(output_csv, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["RealBldg", "SimBldg", "VariableName", "MBE", "CVRMSE", "NMBE", "Pass"])
        for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
            writer.writerow([
                real_bldg,
                sim_bldg,
                var_name,
                f"{mvals['MBE']:.2f}",
                f"{mvals['CVRMSE']:.2f}",
                f"{mvals['NMBE']:.2f}",
                mvals['Pass']
            ])

    # 5) Check for calibration triggers if CV(RMSE) fails
    print("\n=== Checking for Calibration Needs ===")
    for (real_bldg, sim_bldg, var_name), mvals in metric_results.items():
        if not mvals['Pass']:
            print(
                f"[CALIBRATION] RealBldg={real_bldg}, SimBldg={sim_bldg}, Var={var_name}: "
                f"CV(RMSE)={mvals['CVRMSE']:.2f}% > threshold => Trigger calibration steps..."
            )

    # 6) Optional bar chart: CV(RMSE) for each (RealBldg, SimBldg, Var)
    #    We'll define an inline function here or import from visualize.
    bar_chart_metrics_for_triple(metric_results, title="CV(RMSE) Validation (Per Real vs. Sim)")

def bar_chart_metrics_for_triple(metric_dict, title="Validation Metrics"):
    """
    Create a bar chart of CV(RMSE) for each (RealBldg, SimBldg, Var).
    Bars are green if pass, red if fail.
    """
    if not metric_dict:
        print("[DEBUG] No metrics to plot - metric_dict is empty.")
        return

    labels = []
    cvrmse_values = []
    pass_status = []

    for (real_bldg, sim_bldg, var_name), mvals in metric_dict.items():
        label = f"R{real_bldg}-S{sim_bldg}-{var_name}"
        labels.append(label)
        cvrmse_values.append(mvals['CVRMSE'])
        pass_status.append(mvals['Pass'])

    x = range(len(labels))

    plt.figure(figsize=(12, 6))
    bars = plt.bar(x, cvrmse_values, alpha=0.7)

    for i, bar in enumerate(bars):
        bar.set_color('green' if pass_status[i] else 'red')

    plt.xticks(list(x), labels, rotation=45, ha='right')
    plt.ylabel("CV(RMSE) (%)")
    plt.title(title)
    if cvrmse_values:
        plt.ylim(0, max(cvrmse_values)*1.1)
    plt.tight_layout()
    plt.show()

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\validation\metrics.py
============================================================
# validation/metrics.py
import numpy as np

def mean_bias_error(sim_values, obs_values):
    """
    MBE = ( sum(obs_i - sim_i) / sum(obs_i) ) * 100
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    denominator = np.sum(obs)
    if denominator == 0:
        return float('nan')
    mbe = (np.sum(obs - sim) / denominator) * 100.0
    return mbe

def cv_rmse(sim_values, obs_values):
    """
    CV(RMSE) = ( RMSE / mean(obs) ) * 100
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    obs_mean = np.mean(obs)
    if obs_mean == 0:
        return float('nan')
    mse = np.mean((obs - sim)**2)
    rmse = np.sqrt(mse)
    return (rmse / obs_mean) * 100.0

def nmbe(sim_values, obs_values):
    """
    NMBE = 100 * ( sum(obs_i - sim_i) / (n * mean(obs)) )
    """
    sim = np.array(sim_values, dtype=float)
    obs = np.array(obs_values, dtype=float)
    n = len(sim)
    obs_mean = np.mean(obs)
    if obs_mean == 0:
        return float('nan')
    nmbe_val = 100.0 * (np.sum(obs - sim) / (n * obs_mean))
    return nmbe_val

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\validation\validate_results_custom.py
============================================================
# validation/validate_results_custom.py

import pandas as pd

from validation.compare_sims_with_measured import align_data_for_variable
from validation.metrics import mean_bias_error, cv_rmse, nmbe
from validation.visualize import (
    plot_time_series_comparison,
    scatter_plot_comparison,
)

def validate_with_ranges(
    real_data_path,
    sim_data_path,
    bldg_ranges,
    variables_to_compare=None,
    threshold_cv_rmse=30.0,
    skip_plots=False
):
    """
    Compare real vs sim data for specified building mappings and variable names.

    :param real_data_path: Path to the CSV file with real data
    :param sim_data_path: Path to the CSV file with sim data
    :param bldg_ranges: dict mapping real_bldg (string) -> list of sim_bldgs. 
                       e.g. {"0": [0, 1, 2]}, or {"4136730": ["4136730"]}
    :param variables_to_compare: list of variable names (strings) to be validated.
    :param threshold_cv_rmse: pass/fail threshold for CV(RMSE) in percent
    :param skip_plots: if True, disable time-series and scatter plots
    :return: a dict of metrics keyed by (real_bldg, sim_bldg, variable_name)
    """

    if variables_to_compare is None:
        # If none provided, default to empty => no variables will be compared
        variables_to_compare = []

    # 1) Load the CSVs
    df_real = pd.read_csv(real_data_path)
    df_sim  = pd.read_csv(sim_data_path)

    # 2) Clean up any trailing whitespace in VariableName
    df_real["VariableName"] = df_real["VariableName"].astype(str).str.strip()
    df_sim["VariableName"]  = df_sim["VariableName"].astype(str).str.strip()

    # 3) Initialize a results dictionary
    results = {}

    # 4) Keep track of missing variables for debug
    missing_in_real = []
    missing_in_sim  = []

    # 5) Iterate over building mappings
    for real_bldg_str, sim_bldg_list in bldg_ranges.items():
        # Convert the real building ID from string to int
        # (If your CSV has building IDs as int64, this ensures a match)
        try:
            real_bldg = int(real_bldg_str)
        except ValueError:
            print(f"[WARN] Could not convert real building '{real_bldg_str}' to int; skipping.")
            continue

        # Subset real data for this real_bldg
        df_real_sub = df_real[df_real["BuildingID"] == real_bldg]
        if df_real_sub.empty:
            print(f"[WARN] No real data for building {real_bldg}")
            continue

        for sb in sim_bldg_list:
            # If the sim building is a string, also convert it to int
            try:
                sim_bldg = int(sb)
            except ValueError:
                print(f"[WARN] Could not convert sim building '{sb}' to int; skipping.")
                continue

            # Subset sim data for this sim_bldg
            df_sim_sub = df_sim[df_sim["BuildingID"] == sim_bldg]
            if df_sim_sub.empty:
                print(f"[WARN] No sim data for building {sim_bldg}")
                continue

            # 6) Loop over user-specified variables
            for var_name in variables_to_compare:
                # Check presence in real data
                if var_name not in df_real_sub["VariableName"].unique():
                    missing_in_real.append((real_bldg, var_name))
                    continue

                # Check presence in sim data
                if var_name not in df_sim_sub["VariableName"].unique():
                    missing_in_sim.append((sim_bldg, var_name))
                    continue

                # 7) Align data
                sim_vals, obs_vals, merged_df = align_data_for_variable(
                    df_real_sub,
                    df_sim_sub,
                    real_bldg,
                    sim_bldg,
                    var_name
                )

                # If no overlap or empty arrays, skip
                if len(sim_vals) == 0 or len(obs_vals) == 0:
                    print(f"[WARN] No overlap in dates for RealBldg={real_bldg}, SimBldg={sim_bldg}, Var={var_name}")
                    continue

                # 8) Compute metrics
                this_mbe   = mean_bias_error(sim_vals, obs_vals)
                this_cvrmse = cv_rmse(sim_vals, obs_vals)
                this_nmbe  = nmbe(sim_vals, obs_vals)

                pass_fail = False
                if this_cvrmse is not None and not (this_cvrmse is float('nan')):
                    pass_fail = (this_cvrmse < threshold_cv_rmse)

                # 9) Store results
                results[(real_bldg, sim_bldg, var_name)] = {
                    "MBE":    this_mbe,
                    "CVRMSE": this_cvrmse,
                    "NMBE":   this_nmbe,
                    "Pass":   pass_fail
                }

                # 10) Optionally plot
                if not skip_plots:
                    label_for_plot = f"{real_bldg}_VS_{sim_bldg}"
                    plot_time_series_comparison(merged_df, label_for_plot, var_name)
                    scatter_plot_comparison(merged_df, label_for_plot, var_name)

    # 11) Print missing variable info
    if missing_in_real:
        print("\n[INFO] Variables missing in REAL data for these (Building, Var):")
        unique_missing_real = set(missing_in_real)
        for (bldg, var) in unique_missing_real:
            print(f"   - RealBldg={bldg}, Var={var}")

    if missing_in_sim:
        print("\n[INFO] Variables missing in SIM data for these (Building, Var):")
        unique_missing_sim = set(missing_in_sim)
        for (bldg, var) in unique_missing_sim:
            print(f"   - SimBldg={bldg}, Var={var}")

    # Return the final dictionary of metrics
    return results

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\validation\visualize.py
============================================================
# validation/visualize.py
import matplotlib.pyplot as plt

def plot_time_series_comparison(merged_df, building_id, variable_name):
    """
    Creates a simple line plot comparing sim vs. obs over time 
    (e.g., 01-Jan, 02-Jan, etc.).
    merged_df has columns: Date, Value_obs, Value_sim
    """
    if merged_df.empty:
        print(f"[DEBUG] No data to plot for Bldg={building_id}, Var={variable_name}")
        return

    x_vals = merged_df['Date']  # might be strings like '01-Jan'
    obs_vals = merged_df['Value_obs']
    sim_vals = merged_df['Value_sim']

    plt.figure(figsize=(10,6))
    plt.plot(x_vals, obs_vals, 'o-', label='Observed')
    plt.plot(x_vals, sim_vals, 's-', label='Simulated')

    plt.title(f"Building {building_id} - {variable_name}")
    plt.xlabel("Date")
    plt.ylabel("Value")
    plt.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def scatter_plot_comparison(merged_df, building_id, variable_name):
    """
    Creates a scatter plot of Observed vs. Simulated for a quick correlation check.
    """
    if merged_df.empty:
        print(f"[DEBUG] No data to plot scatter for Bldg={building_id}, Var={variable_name}")
        return

    obs_vals = merged_df['Value_obs']
    sim_vals = merged_df['Value_sim']

    plt.figure(figsize=(6,6))
    plt.scatter(obs_vals, sim_vals, alpha=0.7)
    # 1:1 line
    mn, mx = min(obs_vals.min(), sim_vals.min()), max(obs_vals.max(), sim_vals.max())
    plt.plot([mn, mx], [mn, mx], color='red', linestyle='--', label='1:1 line')

    plt.title(f"Scatter Comparison: Bldg={building_id}, Var={variable_name}")
    plt.xlabel("Observed")
    plt.ylabel("Simulated")
    plt.legend()
    plt.tight_layout()
    plt.show()

def bar_chart_metrics(metric_dict, title="Validation Metrics"):
    """
    Suppose metric_dict is e.g.:
      {
        (0, 'Cooling'): {'MBE': 2.3, 'CVRMSE': 18.5, 'NMBE': -0.4, 'Pass': True},
        (0, 'Heating'): { ... },
        (1, 'Cooling'): { ... },
        ...
      }
    We'll create a bar chart of CV(RMSE) across all keys.
    """
    import numpy as np

    if not metric_dict:
        print("[DEBUG] No metrics to plot - metric_dict is empty.")
        return

    labels = []
    cvrmse_values = []
    pass_status = []

    for (b_id, var), mvals in metric_dict.items():
        label = f"B{b_id}-{var}"
        labels.append(label)
        cvrmse_values.append(mvals['CVRMSE'])
        pass_status.append(mvals['Pass'])

    x = range(len(labels))

    plt.figure(figsize=(10,5))
    bars = plt.bar(x, cvrmse_values, color='blue', alpha=0.6)

    # Color code pass/fail if you want:
    for i, bar in enumerate(bars):
        if pass_status[i]:
            bar.set_color('green')
        else:
            bar.set_color('red')

    plt.xticks(list(x), labels, rotation=45, ha='right')
    plt.ylabel("CV(RMSE) (%)")
    plt.title(title)

    if cvrmse_values:
        plt.ylim(0, max(cvrmse_values)*1.1)
    plt.tight_layout()
    plt.show()

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\orchestrator.py
============================================================
"""
orchestrator.py

Orchestrates the entire EnergyPlus workflow using a job-specific subfolder
for config files and a job-specific folder in /output for results.

Steps:
  1. Retrieve 'job_id' from job_config (set by job_manager or app).
  2. Form an output directory: <OUTPUT_DIR>/<job_id>.
  3. Load main_config.json from user_configs/<job_id>.
  4. Merge with posted_data["main_config"] if present.
  5. Apply Excel overrides, JSON overrides, create IDFs, run sims, etc.
  6. If scenario modification is enabled, override paths so scenario IDFs/results
     stay in the same job folder, then run scenario-based modifications.
  7. Perform structuring (e.g., flatten assigned CSVs) if requested.
  8. Perform global validation, sensitivity, surrogate, calibration if requested;
     patch any relative CSV paths to be inside the job folder (unless "data/").
  9. Zip & email final results if mail_user.json is present.
  10. Respect any cancel_event from job_manager.
"""

import os
import json
import logging
import threading
import time
from contextlib import contextmanager
import pandas as pd

# Splitting / deep-merge
from splitter import deep_merge_dicts

# DB loading if needed
from database_handler import load_buildings_from_db

# Excel overrides
from excel_overrides import (
    override_dhw_lookup_from_excel_file,
    override_epw_lookup_from_excel_file,
    override_lighting_lookup_from_excel_file,
    override_hvac_lookup_from_excel_file,
    override_vent_lookup_from_excel_file
)

# Fenestration config
from idf_objects.fenez.fenez_config_manager import build_fenez_config


# IDF creation
import idf_creation
from idf_creation import create_idfs_for_all_buildings

# Scenario modification
from main_modifi import run_modification_workflow

# Validation
from validation.main_validation import run_validation_process

# Sensitivity / Surrogate / Calibration
from cal.unified_sensitivity import run_sensitivity_analysis
from cal.unified_surrogate import (
    load_scenario_params as sur_load_scenario_params,
    pivot_scenario_params,
    load_sim_results,
    aggregate_results,
    merge_params_with_results,
    build_and_save_surrogate
)
from cal.unified_calibration import run_unified_calibration

# Zip & email
from zip_and_mail import zip_user_output, send_results_email

from cleanup_old_jobs import cleanup_old_results


class WorkflowCanceled(Exception):
    """Custom exception used to stop the workflow if a cancel_event is set."""
    pass


@contextmanager
def step_timer(logger, name: str):
    """Context manager to log step durations."""
    logger.info(f"[STEP] Starting {name} ...")
    start = time.perf_counter()
    try:
        yield
    finally:
        elapsed = time.perf_counter() - start
        logger.info(f"[STEP] Finished {name} in {elapsed:.2f} seconds.")


def orchestrate_workflow(job_config: dict, cancel_event: threading.Event = None):
    """
    Orchestrates the entire E+ workflow using a job-specific subfolder for config JSON,
    plus a job-specific output folder for results.

    Args:
        job_config (dict): includes:
            {
              "job_id": "<unique_id_for_this_job>",
              "job_subfolder": "user_configs/<job_id>",
              "posted_data": {...} (optional),
              ...
            }
        cancel_event (threading.Event): If set, we gracefully exit early.

    Raises:
        WorkflowCanceled if cancel_event is set mid-way.

    Returns:
        None (logs extensively, optionally zips/emails final results).
    """
    logger = logging.getLogger(__name__)
    logger.info("=== Starting orchestrate_workflow ===")
    overall_start = time.perf_counter()

    # -------------------------------------------------------------------------
    # 0) Identify job_id, define check_canceled
    # -------------------------------------------------------------------------
    job_id = job_config.get("job_id", "unknown_job_id")
    logger.info(f"[INFO] Orchestrator for job_id={job_id}")

    def check_canceled():
        """Raise WorkflowCanceled if cancel_event is set."""
        if cancel_event and cancel_event.is_set():
            logger.warning("=== CANCEL event detected. Stopping workflow. ===")
            raise WorkflowCanceled("Workflow was canceled by user request.")


    # -------------------------------------------------------------------------
    # 12) Helper to handle patching CSVs that are "relative" but not "data/".
    # -------------------------------------------------------------------------
    def patch_if_relative(csv_path: str):
        """
        1) If absolute, return as-is.
        2) If starts with 'data/', interpret as /usr/src/app/data/... (no job folder).
        3) Else, join with job_output_dir.
        """
        if not csv_path:
            return csv_path
        if os.path.isabs(csv_path):
            return csv_path
        if csv_path.startswith("data/"):
            return os.path.join("/usr/src/app", csv_path)
        return os.path.join(job_output_dir, csv_path)





    # -------------------------------------------------------------------------
    # 1) Identify the user_configs folder (where main_config.json resides)
    # -------------------------------------------------------------------------
    user_configs_folder = job_config.get("job_subfolder")
    if not user_configs_folder or not os.path.isdir(user_configs_folder):
        logger.error(f"[ERROR] job_subfolder not found or invalid => {user_configs_folder}")
        return

    # -------------------------------------------------------------------------
    # 2) Build an output directory for this job under OUTPUT_DIR
    #    e.g. /usr/src/app/output/<job_id>
    # -------------------------------------------------------------------------
    env_out_dir = os.environ.get("OUTPUT_DIR", "/usr/src/app/output")
    job_output_dir = os.path.join(env_out_dir, job_id)
    os.makedirs(job_output_dir, exist_ok=True)
    logger.info(f"[INFO] Using job-specific output folder: {job_output_dir}")

    # -------------------------------------------------------------------------
    # 3) Load main_config.json from user_configs/<job_id>
    # -------------------------------------------------------------------------
    main_config_path = os.path.join(user_configs_folder, "main_config.json")
    if not os.path.isfile(main_config_path):
        logger.error(f"[ERROR] Cannot find main_config.json at {main_config_path}")
        return

    with open(main_config_path, "r") as f:
        existing_config_raw = json.load(f)
    main_config = existing_config_raw.get("main_config", {})
    logger.info(f"[INFO] Loaded existing main_config from {main_config_path}.")

    # Merge posted_data["main_config"] if present
    posted_data = job_config.get("posted_data", {})
    if "main_config" in posted_data:
        logger.info("[INFO] Deep merging posted_data['main_config'] into main_config.")
        deep_merge_dicts(main_config, posted_data["main_config"])
        # optionally re-save
        with open(main_config_path, "w") as f:
            json.dump({"main_config": main_config}, f, indent=2)

    # -------------------------------------------------------------------------
    # 4) Extract sub-sections from main_config
    # -------------------------------------------------------------------------
    check_canceled()
    paths_dict       = main_config.get("paths", {})
    excel_flags      = main_config.get("excel_overrides", {})
    user_flags       = main_config.get("user_config_overrides", {})
    def_dicts        = main_config.get("default_dicts", {})
    structuring_cfg  = main_config.get("structuring", {})
    modification_cfg = main_config.get("modification", {})
    validation_cfg   = main_config.get("validation", {})
    sens_cfg         = main_config.get("sensitivity", {})
    sur_cfg          = main_config.get("surrogate", {})
    cal_cfg          = main_config.get("calibration", {})

    # IDF creation block
    idf_cfg = main_config.get("idf_creation", {})
    perform_idf_creation = idf_cfg.get("perform_idf_creation", False)
    scenario             = idf_cfg.get("scenario", "scenario1")
    calibration_stage    = idf_cfg.get("calibration_stage", "pre_calibration")
    strategy             = idf_cfg.get("strategy", "B")
    random_seed          = idf_cfg.get("random_seed", 42)
    run_simulations      = idf_cfg.get("run_simulations", True)
    simulate_config      = idf_cfg.get("simulate_config", {})
    post_process         = idf_cfg.get("post_process", True)
    post_process_config  = idf_cfg.get("post_process_config", {})
    output_definitions   = idf_cfg.get("output_definitions", {})
    use_database         = main_config.get("use_database", False)
    db_filter            = main_config.get("db_filter", {})
    filter_by            = main_config.get("filter_by")  # if using DB

    # Summarize which major steps will run
    steps_to_run = []
    if perform_idf_creation:
        steps_to_run.append("IDF creation")
        if run_simulations:
            steps_to_run.append("simulations")
    if structuring_cfg.get("perform_structuring", False):
        steps_to_run.append("structuring")
    if modification_cfg.get("perform_modification", False):
        steps_to_run.append("modification")
    if main_config.get("validation_base", {}).get("perform_validation", False):
        steps_to_run.append("base validation")
    if main_config.get("validation_scenarios", {}).get("perform_validation", False):
        steps_to_run.append("scenario validation")
    if sens_cfg.get("perform_sensitivity", False):
        steps_to_run.append("sensitivity analysis")
    if sur_cfg.get("perform_surrogate", False):
        steps_to_run.append("surrogate modeling")
    if cal_cfg.get("perform_calibration", False):
        steps_to_run.append("calibration")

    if steps_to_run:
        logger.info("[INFO] Steps to execute: " + ", ".join(steps_to_run))
    else:
        logger.info("[INFO] No major steps are enabled in configuration.")

    # -------------------------------------------------------------------------
    # 5) Possibly override idf_creation.idf_config from env, then force IDFs
    #    to go in <job_output_dir>/output_IDFs
    # -------------------------------------------------------------------------
    check_canceled()

    env_idd_path = os.environ.get("IDD_PATH")
    if env_idd_path:
        idf_creation.idf_config["iddfile"] = env_idd_path
    env_base_idf = os.environ.get("BASE_IDF_PATH")
    if env_base_idf:
        idf_creation.idf_config["idf_file_path"] = env_base_idf

    job_idf_dir = os.path.join(job_output_dir, "output_IDFs")
    os.makedirs(job_idf_dir, exist_ok=True)
    idf_creation.idf_config["output_dir"] = job_idf_dir

    # If user explicitly set these in main_config, override again
    if "iddfile" in idf_cfg:
        idf_creation.idf_config["iddfile"] = idf_cfg["iddfile"]
    if "idf_file_path" in idf_cfg:
        idf_creation.idf_config["idf_file_path"] = idf_cfg["idf_file_path"]

    if "output_idf_dir" in idf_cfg:
        subfolder = idf_cfg["output_idf_dir"]  # e.g. "output_IDFs"
        full_dir = os.path.join(job_output_dir, subfolder)
        idf_creation.idf_config["output_dir"] = full_dir
    else:
        idf_creation.idf_config["output_dir"] = os.path.join(job_output_dir, "output_IDFs")

    # -------------------------------------------------------------------------
    # 6) Setup default dictionaries
    # -------------------------------------------------------------------------
    base_res_data    = def_dicts.get("res_data", {})
    base_nonres_data = def_dicts.get("nonres_data", {})
    dhw_lookup       = def_dicts.get("dhw", {})
    epw_lookup       = def_dicts.get("epw", [])
    lighting_lookup  = def_dicts.get("lighting", {})
    hvac_lookup      = def_dicts.get("hvac", {})
    vent_lookup      = def_dicts.get("vent", {})

    # -------------------------------------------------------------------------
    # 7) Apply Excel overrides if flags are set
    # -------------------------------------------------------------------------
    check_canceled()

    updated_res_data, updated_nonres_data = build_fenez_config(
        base_res_data=base_res_data,
        base_nonres_data=base_nonres_data,
        excel_path=paths_dict.get("fenez_excel", ""),
        do_excel_override=excel_flags.get("override_fenez_excel", False),
        user_fenez_overrides=[]
    )

    if excel_flags.get("override_dhw_excel", False):
        dhw_lookup = override_dhw_lookup_from_excel_file(
            dhw_excel_path=paths_dict.get("dhw_excel", ""),
            default_dhw_lookup=dhw_lookup,
            override_dhw_flag=True
        )

    if excel_flags.get("override_epw_excel", False):
        epw_lookup = override_epw_lookup_from_excel_file(
            epw_excel_path=paths_dict.get("epw_excel", ""),
            epw_lookup=epw_lookup,
            override_epw_flag=True
        )

    if excel_flags.get("override_lighting_excel", False):
        lighting_lookup = override_lighting_lookup_from_excel_file(
            lighting_excel_path=paths_dict.get("lighting_excel", ""),
            lighting_lookup=lighting_lookup,
            override_lighting_flag=True
        )

    if excel_flags.get("override_hvac_excel", False):
        hvac_lookup = override_hvac_lookup_from_excel_file(
            hvac_excel_path=paths_dict.get("hvac_excel", ""),
            hvac_lookup=hvac_lookup,
            override_hvac_flag=True
        )

    if excel_flags.get("override_vent_excel", False):
        vent_lookup = override_vent_lookup_from_excel_file(
            vent_excel_path=paths_dict.get("vent_excel", ""),
            vent_lookup=vent_lookup,
            override_vent_flag=True
        )

    # -------------------------------------------------------------------------
    # 8) JSON overrides from user_configs/<job_id> if user_flags are set
    # -------------------------------------------------------------------------
    check_canceled()

    def safe_load_subjson(fname, key):
        """
        Loads user_configs/<job_id>/fname if it exists, returns data.get(key).
        """
        full_path = os.path.join(user_configs_folder, fname)
        if os.path.isfile(full_path):
            try:
                with open(full_path, "r") as ff:
                    data = json.load(ff)
                return data.get(key)
            except Exception as e:
                logger.error(f"[ERROR] loading {fname} => {e}")
        return None

    # Fenestration
    user_fenez_data = []
    if user_flags.get("override_fenez_json", False):
        loaded = safe_load_subjson("fenestration.json", "fenestration")
        if loaded:
            user_fenez_data = loaded

    updated_res_data, updated_nonres_data = build_fenez_config(
        base_res_data=updated_res_data,
        base_nonres_data=updated_nonres_data,
        excel_path="",
        do_excel_override=False,
        user_fenez_overrides=user_fenez_data
    )

    # DHW
    user_config_dhw = None
    if user_flags.get("override_dhw_json", False):
        user_config_dhw = safe_load_subjson("dhw.json", "dhw")

    # EPW
    user_config_epw = []
    if user_flags.get("override_epw_json", False):
        e = safe_load_subjson("epw.json", "epw")
        if e:
            user_config_epw = e

    # Lighting
    user_config_lighting = None
    if user_flags.get("override_lighting_json", False):
        user_config_lighting = safe_load_subjson("lighting.json", "lighting")

    # HVAC
    user_config_hvac = None
    if user_flags.get("override_hvac_json", False):
        user_config_hvac = safe_load_subjson("hvac.json", "hvac")

    # Vent
    user_config_vent = []
    if user_flags.get("override_vent_json", False):
        v = safe_load_subjson("vent.json", "vent")
        if v:
            user_config_vent = v

    # Geometry
    geom_data = {}
    if user_flags.get("override_geometry_json", False):
        g = safe_load_subjson("geometry.json", "geometry")
        if g:
            geom_data["geometry"] = g

    # Shading
    shading_data = {}
    if user_flags.get("override_shading_json", False):
        s = safe_load_subjson("shading.json", "shading")
        if s:
            shading_data["shading"] = s

    # -------------------------------------------------------------------------
    # 9) IDF creation
    # -------------------------------------------------------------------------
    check_canceled()
    df_buildings = pd.DataFrame()

    if perform_idf_creation:
        logger.info("[INFO] IDF creation is ENABLED.")
        with step_timer(logger, "IDF creation and simulations"):
            # a) Load building data
            if use_database:
                logger.info("[INFO] Loading building data from DB.")
                if not filter_by:
                    raise ValueError("[ERROR] 'filter_by' must be specified when 'use_database' is True.")
                df_buildings = load_buildings_from_db(db_filter, filter_by)

                # Optionally save the raw DB buildings
                extracted_csv_path = os.path.join(job_output_dir, "extracted_buildings.csv")
                df_buildings.to_csv(extracted_csv_path, index=False)
                logger.info(f"[INFO] Saved extracted buildings to {extracted_csv_path}")

            else:
                bldg_data_path = paths_dict.get("building_data", "")
                if os.path.isfile(bldg_data_path):
                    df_buildings = pd.read_csv(bldg_data_path)
                else:
                    logger.warning(f"[WARN] building_data CSV not found => {bldg_data_path}")

            logger.info(f"[INFO] Number of buildings to simulate: {len(df_buildings)}")

            # b) Create IDFs & (optionally) run sims in job folder
            df_buildings = create_idfs_for_all_buildings(
                df_buildings=df_buildings,
                scenario=scenario,
                calibration_stage=calibration_stage,
                strategy=strategy,
                random_seed=random_seed,
                user_config_geom=geom_data.get("geometry", []),
                user_config_lighting=user_config_lighting,
                user_config_dhw=user_config_dhw,
                res_data=updated_res_data,
                nonres_data=updated_nonres_data,
                user_config_hvac=user_config_hvac,
                user_config_vent=user_config_vent,
                user_config_epw=user_config_epw,
                output_definitions=output_definitions,
                run_simulations=run_simulations,
                simulate_config=simulate_config,
                post_process=post_process,
                post_process_config=post_process_config,
                logs_base_dir=job_output_dir
            )

            # === Store the mapping (ogc_fid -> idf_name) so we can look it up later ===
            idf_map_csv = os.path.join(job_output_dir, "extracted_idf_buildings.csv")
            df_buildings.to_csv(idf_map_csv, index=False)
            logger.info(f"[INFO] Wrote building -> IDF map to {idf_map_csv}")

    else:
        logger.info("[INFO] Skipping IDF creation.")

    # -------------------------------------------------------------------------
    # 10) Perform structuring if requested
    # -------------------------------------------------------------------------
    check_canceled()
    if structuring_cfg.get("perform_structuring", False):
        with step_timer(logger, "structuring"):
            logger.info("[INFO] Performing structuring ...")

            # --- Fenestration -------------------------------------------------
            from idf_objects.structuring.fenestration_structuring import transform_fenez_log_to_structured_with_ranges
            fenez_conf = structuring_cfg.get("fenestration", {})
            fenez_in = fenez_conf.get("csv_in", "assigned/assigned_fenez_params.csv")
            fenez_out = fenez_conf.get("csv_out", "assigned/structured_fenez_params.csv")
            if not os.path.isabs(fenez_in):
                fenez_in = os.path.join(job_output_dir, fenez_in)
            if not os.path.isabs(fenez_out):
                fenez_out = os.path.join(job_output_dir, fenez_out)
            if os.path.isfile(fenez_in):
                transform_fenez_log_to_structured_with_ranges(csv_input=fenez_in, csv_output=fenez_out)
            else:
                logger.warning(f"[STRUCTURING] Fenestration input CSV not found => {fenez_in}")

            # --- DHW ---------------------------------------------------------
            from idf_objects.structuring.dhw_structuring import transform_dhw_log_to_structured
            dhw_conf = structuring_cfg.get("dhw", {})
            dhw_in = dhw_conf.get("csv_in", "assigned/assigned_dhw_params.csv")
            dhw_out = dhw_conf.get("csv_out", "assigned/structured_dhw_params.csv")
            if not os.path.isabs(dhw_in):
                dhw_in = os.path.join(job_output_dir, dhw_in)
            if not os.path.isabs(dhw_out):
                dhw_out = os.path.join(job_output_dir, dhw_out)
            if os.path.isfile(dhw_in):
                transform_dhw_log_to_structured(dhw_in, dhw_out)
            else:
                logger.warning(f"[STRUCTURING] DHW input CSV not found => {dhw_in}")


            # NEW:--- Shading ----------------------------------------------------
            from idf_objects.structuring.shading_structuring import transform_shading_log_to_structured
            shading_conf = structuring_cfg.get("shading", {})
            user_shading_rules = safe_load_subjson("shading.json", "shading") or []
            
            if shading_conf:
                shading_in = patch_if_relative(shading_conf.get("csv_in"))
                shading_out = patch_if_relative(shading_conf.get("csv_out"))

                transform_shading_log_to_structured(
                    csv_input=shading_in,
                    csv_output=shading_out,
                    user_shading_rules=user_shading_rules
                )
            else:
                logger.warning("[STRUCTURING] 'shading' configuration not found in structuring settings.")


            # --- Equipment --------------------------------------------------
            from idf_objects.structuring.equipment_structuring import transform_equipment_log_to_structured
            equip_conf = structuring_cfg.get("equipment", {})
            user_equip_rules = safe_load_subjson("equipment.json", "equipment") or []
            
            if equip_conf:
                equip_in = patch_if_relative(equip_conf.get("csv_in"))
                equip_out = patch_if_relative(equip_conf.get("csv_out"))

                transform_equipment_log_to_structured(
                    csv_input=equip_in,
                    csv_output=equip_out,
                    user_equipment_rules=user_equip_rules
                )
            else:
                logger.warning("[STRUCTURING] 'equipment' configuration not found in structuring settings.")



            # --- Zone Sizing ------------------------------------------------
            from idf_objects.structuring.zone_sizing_structuring import transform_zone_sizing_log_to_structured
            sizing_conf = structuring_cfg.get("zone_sizing", {})
            user_sizing_rules = safe_load_subjson("zone_sizing.json", "zone_sizing") or []
            
            if sizing_conf:
                sizing_in = patch_if_relative(sizing_conf.get("csv_in"))
                sizing_out = patch_if_relative(sizing_conf.get("csv_out"))

                transform_zone_sizing_log_to_structured(
                    csv_input=sizing_in,
                    csv_output=sizing_out,
                    user_sizing_rules=user_sizing_rules
                )
            else:
                logger.warning("[STRUCTURING] 'zone_sizing' configuration not found.")



            # --- HVAC flatten -----------------------------------------------
            from idf_objects.structuring.flatten_hvac import flatten_hvac_data, parse_assigned_value as parse_hvac
            hvac_conf = structuring_cfg.get("hvac", {})
            hvac_in = hvac_conf.get("csv_in", "assigned/assigned_hvac_params.csv")
            hvac_bld = hvac_conf.get("build_out", "assigned/assigned_hvac_building.csv")
            hvac_zone = hvac_conf.get("zone_out", "assigned/assigned_hvac_zones.csv")
            if not os.path.isabs(hvac_in):
                hvac_in = os.path.join(job_output_dir, hvac_in)
            if not os.path.isabs(hvac_bld):
                hvac_bld = os.path.join(job_output_dir, hvac_bld)
            if not os.path.isabs(hvac_zone):
                hvac_zone = os.path.join(job_output_dir, hvac_zone)
            if os.path.isfile(hvac_in):
                df_hvac = pd.read_csv(hvac_in)
                if "assigned_value" in df_hvac.columns:
                    df_hvac["assigned_value"] = df_hvac["assigned_value"].apply(parse_hvac)
                    flatten_hvac_data(
                        df_input=df_hvac,
                        out_build_csv=hvac_bld,
                        out_zone_csv=hvac_zone,
                    )
                else:
                    logger.warning(
                        f"[STRUCTURING] 'assigned_value' column missing in {hvac_in}. Skipping HVAC flatten."
                    )
            else:
                logger.warning(f"[STRUCTURING] HVAC input CSV not found => {hvac_in}")

            # --- Vent flatten -----------------------------------------------
            from idf_objects.structuring.flatten_assigned_vent import flatten_ventilation_data, parse_assigned_value as parse_vent
            vent_conf = structuring_cfg.get("vent", {})
            vent_in = vent_conf.get("csv_in", "assigned/assigned_ventilation.csv")
            vent_bld = vent_conf.get("build_out", "assigned/assigned_vent_building.csv")
            vent_zone = vent_conf.get("zone_out", "assigned/assigned_vent_zones.csv")
            if not os.path.isabs(vent_in):
                vent_in = os.path.join(job_output_dir, vent_in)
            if not os.path.isabs(vent_bld):
                vent_bld = os.path.join(job_output_dir, vent_bld)
            if not os.path.isabs(vent_zone):
                vent_zone = os.path.join(job_output_dir, vent_zone)
            if os.path.isfile(vent_in):
                df_vent = pd.read_csv(vent_in)
                if "assigned_value" in df_vent.columns:
                    df_vent["assigned_value"] = df_vent["assigned_value"].apply(parse_vent)
                    flatten_ventilation_data(
                        df_input=df_vent,
                        out_build_csv=vent_bld,
                        out_zone_csv=vent_zone,
                    )
                else:
                    logger.warning(
                        f"[STRUCTURING] 'assigned_value' column missing in {vent_in}. Skipping ventilation flatten."
                    )
            else:
                logger.warning(f"[STRUCTURING] Vent input CSV not found => {vent_in}")
    else:
        logger.info("[INFO] Skipping structuring.")

    # -------------------------------------------------------------------------
    # 11) Scenario Modification
    # -------------------------------------------------------------------------
    check_canceled()
    if modification_cfg.get("perform_modification", False):
        with step_timer(logger, "modification"):
            logger.info("[INFO] Scenario modification is ENABLED.")

            mod_cfg = modification_cfg["modify_config"]

            # 1) Ensure scenario IDFs go to <job_output_dir>/scenario_idfs
            scenario_idf_dir = os.path.join(job_output_dir, "scenario_idfs")
            os.makedirs(scenario_idf_dir, exist_ok=True)
            mod_cfg["output_idf_dir"] = scenario_idf_dir

            # 2) Ensure scenario sims => <job_output_dir>/Sim_Results/Scenarios
            if "simulation_config" in mod_cfg:
                sim_out = os.path.join(job_output_dir, "Sim_Results", "Scenarios")
                os.makedirs(sim_out, exist_ok=True)
                mod_cfg["simulation_config"]["output_dir"] = sim_out

            # 3) Post-process => <job_output_dir>/results_scenarioes
            if "post_process_config" in mod_cfg:
                ppcfg = mod_cfg["post_process_config"]
                as_is_csv = os.path.join(job_output_dir, "results_scenarioes", "merged_as_is_scenarios.csv")
                daily_csv = os.path.join(job_output_dir, "results_scenarioes", "merged_daily_mean_scenarios.csv")
                os.makedirs(os.path.dirname(as_is_csv), exist_ok=True)
                os.makedirs(os.path.dirname(daily_csv), exist_ok=True)
                ppcfg["output_csv_as_is"] = as_is_csv
                ppcfg["output_csv_daily_mean"] = daily_csv

            # 4) Fix assigned_csv paths
            assigned_csv_dict = mod_cfg.get("assigned_csv", {})
            for key, rel_path in assigned_csv_dict.items():
                assigned_csv_dict[key] = os.path.join(job_output_dir, rel_path)

            # 5) Fix scenario_csv paths
            scenario_csv_dict = mod_cfg.get("scenario_csv", {})
            for key, rel_path in scenario_csv_dict.items():
                scenario_csv_dict[key] = os.path.join(job_output_dir, rel_path)

            # ----------------------------------------------------------------------
            # NEW LOGIC: pick the base_idf_path from building_id automatically
            # ----------------------------------------------------------------------
            # The user sets "building_id" in the config, e.g. 20233330
            building_id = mod_cfg["building_id"]

            # We need the CSV that was saved right after create_idfs_for_all_buildings(...)
            idf_map_csv = os.path.join(job_output_dir, "extracted_idf_buildings.csv")
            if not os.path.isfile(idf_map_csv):
                raise FileNotFoundError(
                    f"Cannot find building->IDF map CSV at {idf_map_csv}. "
                    f"Did you skip 'perform_idf_creation'?"
                )

        # Read the mapping: each row has "ogc_fid" and "idf_name"
            df_idf_map = pd.read_csv(idf_map_csv)
            row_match = df_idf_map.loc[df_idf_map["ogc_fid"] == building_id]

            if row_match.empty:
                raise ValueError(
                    f"No building found for building_id={building_id} in {idf_map_csv}"
                )

        # e.g. "building_0.idf", "building_16.idf", "building_16_ba62d0.idf", etc.
            idf_filename = row_match.iloc[0]["idf_name"]

        # Build the full path to that IDF in output_IDFs
            base_idf_path = os.path.join(job_output_dir, "output_IDFs", idf_filename)
            mod_cfg["base_idf_path"] = base_idf_path
            logger.info(f"[INFO] Auto-selected base IDF => {base_idf_path}")
        # ----------------------------------------------------------------------

            # Finally, run the scenario workflow
            run_modification_workflow(mod_cfg)
    else:
        logger.info("[INFO] Skipping scenario modification.")


    # -------------------------------------------------------------------------
    # 12) Helper to handle patching CSVs that are "relative" but not "data/".
    # -------------------------------------------------------------------------
    def patch_if_relative(csv_path: str):
        """
        1) If absolute, return as-is.
        2) If starts with 'data/', interpret as /usr/src/app/data/... (no job folder).
        3) Else, join with job_output_dir.
        """
        if not csv_path:
            return csv_path
        if os.path.isabs(csv_path):
            return csv_path
        if csv_path.startswith("data/"):
            return os.path.join("/usr/src/app", csv_path)
        return os.path.join(job_output_dir, csv_path)

    # -------------------------------------------------------------------------
    # 13) Global Validation
    # -------------------------------------------------------------------------
        # (A) Validation - BASE
    # -------------------------------------------------------------------------
    check_canceled()
    base_validation_cfg = main_config.get("validation_base", {})
    if base_validation_cfg.get("perform_validation", False):
        with step_timer(logger, "base validation"):
            logger.info("[INFO] BASE Validation is ENABLED.")
            val_conf = base_validation_cfg["config"]

            # Patch relative paths
            sim_csv = val_conf.get("sim_data_csv")
            if sim_csv:
                val_conf["sim_data_csv"] = patch_if_relative(sim_csv)

            real_csv = val_conf.get("real_data_csv")
            if real_csv:
                val_conf["real_data_csv"] = patch_if_relative(real_csv)

            out_csv = val_conf.get("output_csv")
            if out_csv:
                val_conf["output_csv"] = patch_if_relative(out_csv)

            # Now run the validation
            run_validation_process(val_conf)
    else:
        logger.info("[INFO] Skipping BASE validation or not requested.")

    # (B) Validation - SCENARIOS
    # -------------------------------------------------------------------------
    check_canceled()
    scenario_validation_cfg = main_config.get("validation_scenarios", {})
    if scenario_validation_cfg.get("perform_validation", False):
        with step_timer(logger, "scenario validation"):
            logger.info("[INFO] SCENARIO Validation is ENABLED.")
            val_conf = scenario_validation_cfg["config"]

            # Patch relative paths
            sim_csv = val_conf.get("sim_data_csv")
            if sim_csv:
                val_conf["sim_data_csv"] = patch_if_relative(sim_csv)

            real_csv = val_conf.get("real_data_csv")
            if real_csv:
                val_conf["real_data_csv"] = patch_if_relative(real_csv)

            out_csv = val_conf.get("output_csv")
            if out_csv:
                val_conf["output_csv"] = patch_if_relative(out_csv)

            # Now run the validation
            run_validation_process(val_conf)
    else:
        logger.info("[INFO] Skipping SCENARIO validation or not requested.")


    # -------------------------------------------------------------------------
    # 14) Sensitivity Analysis
    # -------------------------------------------------------------------------
    check_canceled()
    if sens_cfg.get("perform_sensitivity", False):
        with step_timer(logger, "sensitivity analysis"):
            logger.info("[INFO] Sensitivity Analysis is ENABLED.")

            scenario_folder = sens_cfg.get("scenario_folder", "")
            sens_cfg["scenario_folder"] = patch_if_relative(scenario_folder)

            results_csv = sens_cfg.get("results_csv", "")
            sens_cfg["results_csv"] = patch_if_relative(results_csv)

            out_csv = sens_cfg.get("output_csv", "sensitivity_output.csv")
            sens_cfg["output_csv"] = patch_if_relative(out_csv)

            run_sensitivity_analysis(
                scenario_folder=sens_cfg["scenario_folder"],
                method=sens_cfg["method"],
                results_csv=sens_cfg.get("results_csv", ""),
                target_variable=sens_cfg.get("target_variable", []),
                output_csv=sens_cfg.get("output_csv", "sensitivity_output.csv"),
                n_morris_trajectories=sens_cfg.get("n_morris_trajectories", 10),
                num_levels=sens_cfg.get("num_levels", 4),
                n_sobol_samples=sens_cfg.get("n_sobol_samples", 128)
            )
    else:
        logger.info("[INFO] Skipping sensitivity analysis.")

    # -------------------------------------------------------------------------
    # 15) Surrogate Modeling
    # -------------------------------------------------------------------------
    check_canceled()
    if sur_cfg.get("perform_surrogate", False):
        with step_timer(logger, "surrogate modeling"):
            logger.info("[INFO] Surrogate Modeling is ENABLED.")

            scenario_folder = sur_cfg.get("scenario_folder", "")
            sur_cfg["scenario_folder"] = patch_if_relative(scenario_folder)

            results_csv = sur_cfg.get("results_csv", "")
            sur_cfg["results_csv"] = patch_if_relative(results_csv)

            model_out = sur_cfg.get("model_out", "")
            sur_cfg["model_out"] = patch_if_relative(model_out)

            cols_out = sur_cfg.get("cols_out", "")
            sur_cfg["cols_out"] = patch_if_relative(cols_out)

            target_var = sur_cfg["target_variable"]
            test_size  = sur_cfg["test_size"]

            df_scen = sur_load_scenario_params(sur_cfg["scenario_folder"])
            pivot_df = pivot_scenario_params(df_scen)

            df_sim = load_sim_results(sur_cfg["results_csv"])
            df_agg = aggregate_results(df_sim)
            merged_df = merge_params_with_results(pivot_df, df_agg, target_var)

            rf_model, trained_cols = build_and_save_surrogate(
                df_data=merged_df,
                target_col=target_var,
                model_out_path=sur_cfg["model_out"],
                columns_out_path=sur_cfg["cols_out"],
                test_size=test_size,
                random_state=42
            )
            if rf_model:
                logger.info("[INFO] Surrogate model built & saved.")
            else:
                logger.warning("[WARN] Surrogate modeling failed or insufficient data.")
    else:
        logger.info("[INFO] Skipping surrogate modeling.")

    # -------------------------------------------------------------------------
    # 16) Calibration
    # -------------------------------------------------------------------------
    check_canceled()
    if cal_cfg.get("perform_calibration", False):
        with step_timer(logger, "calibration"):
            logger.info("[INFO] Calibration is ENABLED.")

            scen_folder = cal_cfg.get("scenario_folder", "")
            cal_cfg["scenario_folder"] = patch_if_relative(scen_folder)

            real_csv = cal_cfg.get("real_data_csv", "")
            cal_cfg["real_data_csv"] = patch_if_relative(real_csv)

            sur_model_path = cal_cfg.get("surrogate_model_path", "")
            cal_cfg["surrogate_model_path"] = patch_if_relative(sur_model_path)

            sur_cols_path = cal_cfg.get("surrogate_columns_path", "")
            cal_cfg["surrogate_columns_path"] = patch_if_relative(sur_cols_path)

            hist_csv = cal_cfg.get("output_history_csv", "")
            cal_cfg["output_history_csv"] = patch_if_relative(hist_csv)

            best_params_folder = cal_cfg.get("best_params_folder", "")
            cal_cfg["best_params_folder"] = patch_if_relative(best_params_folder)

            run_unified_calibration(cal_cfg)
    else:
        logger.info("[INFO] Skipping calibration.")

    # -------------------------------------------------------------------------
    # 17) Zip & Email final results, if mail_user.json present
    # -------------------------------------------------------------------------
    try:
        with step_timer(logger, "zipping and email"):
            mail_user_path = os.path.join(user_configs_folder, "mail_user.json")
            mail_info = {}
            if os.path.isfile(mail_user_path):
                with open(mail_user_path, "r") as f:
                    mail_info = json.load(f)

                mail_user_list = mail_info.get("mail_user", [])
                if len(mail_user_list) > 0:
                    first_user = mail_user_list[0]
                    recipient_email = first_user.get("email", "")
                    if recipient_email:
                        zip_path = zip_user_output(job_output_dir)
                        send_results_email(zip_path, recipient_email)
                        logger.info(f"[INFO] Emailed zip {zip_path} to {recipient_email}")
                    else:
                        logger.warning("[WARN] mail_user.json => missing 'email'")
                else:
                    logger.warning("[WARN] mail_user.json => 'mail_user' list is empty.")
            else:
                logger.info("[INFO] No mail_user.json found, skipping email.")
    except Exception as e:
        logger.error(f"[ERROR] Zipping/Emailing results failed => {e}")

    # -------------------------------------------------------------------------
    # LAST STEP: (Optional) Call the cleanup function
    # -------------------------------------------------------------------------
    try:
        cleanup_old_results()  # This will remove any job folder older than MAX_AGE_HOURS
    except Exception as e:
        logger.error(f"[CLEANUP ERROR] => {e}")

    total_time = time.perf_counter() - overall_start
    logger.info(f"=== End of orchestrate_workflow (took {total_time:.2f} seconds) ===")

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\combined.json
============================================================
{
  "dhw": [
    {
      "building_id": 413673000,
      "param_name": "occupant_density_m2_per_person",
      "min_val": 127.0,
      "max_val": 233.0
    },
    {
      "building_id": 413673000,
      "param_name": "liters_per_person_per_day",
      "fixed_value": 145.0
    },
    {
      "building_function": "residential00",
      "age_range": "1992-2005",
      "param_name": "setpoint_c",
      "min_val": 58.0,
      "max_val": 60.0
    },
    {
      "building_function": "non_residential000",
      "param_name": "occupant_density_m2_per_person",
      "min_val": 12.0,
      "max_val": 18.0
    }
  ],
  "epw": [
    {
      "building_id": 413673000,
      "fixed_epw_path": "data/weather/2050.epw"
    },
    {
      "desired_year": 2050,
      "override_year_to": 2020
    }
  ],
  "zone_sizing": [
    {
      "param_name": "cooling_supply_air_temp",
      "min_val": 12.0,
      "max_val": 15.0
    },
    {
      "param_name": "heating_supply_air_temp",
      "min_val": 40.0,
      "max_val": 50.0
    },
    {
      "param_name": "cooling_supply_air_hr",
      "min_val": 0.008,
      "max_val": 0.010
    },
    {
      "param_name": "heating_supply_air_hr",
      "min_val": 0.003,
      "max_val": 0.005
    },
    {
      "param_name": "cooling_design_air_flow_method",
      "choices": [
        "Flow/Zone",
        "DesignDay",
        "DesignDayWithLimit"
      ]
    }
  ],
  "equipment": [
    {
      "param_name": "equip_wm2",
      "min_val": 3.0,
      "max_val": 7.0
    },
    {
      "param_name": "tD",
      "description": "Schedule value for day occupancy (W)",
      "min_val": 400.0,
      "max_val": 800.0
    },
    {
      "param_name": "tN",
      "description": "Schedule value for night occupancy (W)",
      "min_val": 150.0,
      "max_val": 350.0
    }
  ],
  "shading": [
    {
      "param_name": "slat_angle_deg",
      "min_val": 30.0,
      "max_val": 60.0
    },
    {
      "param_name": "slat_beam_solar_reflectance",
      "min_val": 0.6,
      "max_val": 0.8
    },
    {
      "param_name": "blind_to_glass_distance",
      "fixed_value": 0.075
    },
    {
      "param_name": "slat_width",
      "min_val": 0.020,
      "max_val": 0.030
    }
  ],
  "mail_user": [
    {
      "email": "amin.jalilzade1@gmail.com"
    }
  ],
  "fenestration": [
    {
      "building_id": 413673000,
      "building_function": "residential",
      "building_type": "Two-and-a-half-story House",
      "age_range": "1992-2005",
      "scenario": "scenario1",
      "param_name": "wwr",
      "min_val": 0.025,
      "max_val": 0.03
    },
    {
      "building_function": "non_residential0",
      "age_range": "2015 and later",
      "scenario": "scenario1",
      "param_name": "roof_R_value",
      "fixed_value": 3.0
    }
  ],
  "geometry": [
    {
      "building_id": 413673,
      "param_name": "perimeter_depth",
      "min_val": 3.5,
      "max_val": 4.0,
      "fixed_value": true
    },
    {
      "building_id": 4136733,
      "param_name": "has_core",
      "fixed_value": true
    },
    {
      "building_id": 4136737,
      "param_name": "has_core",
      "fixed_value": false
    },
    {
      "building_type": "Meeting Function",
      "param_name": "has_core",
      "fixed_value": true
    },
    {
      "building_id": 4136738,
      "param_name": "has_core",
      "fixed_value": false
    }
  ],
  "hvac": [
    {
      "building_id": 413673000,
      "param_name": "heating_day_setpoint",
      "min_val": 10.0,
      "max_val": 11.0
    },
    {
      "building_function": "residential0",
      "param_name": "cooling_day_setpoint",
      "fixed_value": 25.6
    },
    {
      "scenario": "scenario10",
      "age_range": "2015 and later",
      "param_name": "max_heating_supply_air_temp",
      "min_val": 48.6,
      "max_val": 50.0
    }
  ],
  "lighting": [
    {
      "building_id": 413673000,
      "param_name": "lights_wm2",
      "min_val": 18.0,
      "max_val": 20.0
    },
    {
      "building_type": "Residential0",
      "param_name": "tN",
      "min_val": 10999,
      "max_val": 11999
    },
    {
      "building_id": 4136731,
      "building_type": "non_residential",
      "param_name": "parasitic_wm2",
      "min_val": 0.28,
      "max_val": 0.3
    }
  ],
  "main_config": {
    "paths": {
      "building_data": "data/df_buildings.csv",
      "fenez_excel": "excel_data/envelop.xlsx",
      "dhw_excel": "excel_data/dhw_overrides.xlsx",
      "epw_excel": "excel_data/epw_overrides.xlsx",
      "lighting_excel": "excel_data/lighting_overrides.xlsx",
      "hvac_excel": "excel_data/hvac_overrides.xlsx",
      "vent_excel": "excel_data/vent_overrides.xlsx"
    },
    "use_database": false,
    "filter_by": "meestvoorkomendepostcode",
    "db_filter": {
      "meestvoorkomendepostcode": [
        "3066HG"
      ],
      "pand_id": [
        "0383100000001369",
        "0383100000001370",
        "5473VX"
      ],
      "pand_ids": [
        "XYZ123",
        "XYZ999"
      ],
      "bbox_xy": [
        120000.0,
        487000.0,
        121000.0,
        488000.0
      ],
      "bbox_latlon": [
        51.873,
        5.589,
        51.878,
        5.6
      ]
    },
    "excel_overrides": {
      "override_fenez_excel": false,
      "override_dhw_excel": false,
      "override_epw_excel": false,
      "override_lighting_excel": false,
      "override_hvac_excel": false,
      "override_vent_excel": false
    },
    "user_config_overrides": {
      "override_fenez_json": true,
      "override_dhw_json": true,
      "override_epw_json": true,
      "override_lighting_json": true,
      "override_hvac_json": true,
      "override_vent_json": true,
      "override_geometry_json": true,
      "override_shading_json": false
    },
    "idf_creation": {
      "perform_idf_creation": true,
      "scenario": "scenario1",
      "calibration_stage": "pre_calibration",
      "strategy": "B",
      "random_seed": 42,
      "iddfile": "EnergyPlus/Energy+.idd",
      "idf_file_path": "EnergyPlus/Minimal.idf",
      "output_idf_dir": "output_IDFs",
      "run_simulations": true,
      "simulate_config": {
        "num_workers": 4,
        "ep_force_overwrite": true
      },
      "post_process": true,
      "post_process_config": {
        "base_output_dir": "Sim_Results",
        "outputs": [
          {
            "convert_to_daily": true,
            "convert_to_monthly": false,
            "aggregator": "none",
            "output_csv": "output/results/merged_as_is.csv"
          },
          {
            "convert_to_daily": true,
            "convert_to_monthly": false,
            "aggregator": "mean",
            "output_csv": "output/results/merged_daily_mean.csv"
          },
          {
            "convert_to_daily": true,
            "convert_to_monthly": true,
            "aggregator": "mean",
            "output_csv": "output/results/merged_monthly_mean.csv"
          }
        ]
      },
      "output_definitions": {
        "desired_variables": [
          "Facility Total Electric Demand Power",
          "Zone Air Temperature",
          "Boiler Heating Energy",
          "Water Heater Heating Energy"
        ],
        "desired_meters": [
          "Electricity:Facility",
          "Heating:EnergyTransfer",
          "Cooling:EnergyTransfer"
        ],
        "override_variable_frequency": "Daily",
        "override_meter_frequency": "Daily",
        "include_tables": true,
        "include_summary": true
      }
    },
    "structuring": {
      "perform_structuring": true,
      "dhw": {
        "csv_in": "assigned/assigned_dhw_params.csv",
        "csv_out": "assigned/structured_dhw_params.csv"
      },
      "fenestration": {
        "csv_in": "assigned/assigned_fenez_params.csv",
        "csv_out": "assigned/structured_fenez_params.csv"
      },
      "hvac": {
        "csv_in": "assigned/assigned_hvac_params.csv",
        "build_out": "assigned/assigned_hvac_building.csv",
        "zone_out": "assigned/assigned_hvac_zones.csv"
      },
      "vent": {
        "csv_in": "assigned/assigned_ventilation.csv",
        "build_out": "assigned/assigned_vent_building.csv",
        "zone_out": "assigned/assigned_vent_zones.csv"
      },
      "shading": {
        "csv_in": "assigned/assigned_shading_params.csv",
        "csv_out": "assigned/structured_shading_params.csv"
      },
      "equipment": {
        "csv_in": "assigned/assigned_equipment.csv",
        "csv_out": "assigned/structured_equipment.csv"
      },
      "zone_sizing": {
        "csv_in": "assigned/assigned_zone_sizing_outdoor_air.csv",
        "csv_out": "assigned/structured_zone_sizing.csv"
      }
    },
    "modification": {
      "perform_modification": true,
      "modify_config": {
        "idd_path": "EnergyPlus/Energy+.idd",
        "assigned_csv": {
          "hvac_building": "assigned/assigned_hvac_building.csv",
          "hvac_zones": "assigned/assigned_hvac_zones.csv",
          "dhw": "assigned/assigned_dhw_params.csv",
          "vent_build": "assigned/assigned_vent_building.csv",
          "vent_zones": "assigned/assigned_vent_zones.csv",
          "elec": "assigned/assigned_lighting.csv",
          "fenez": "assigned/structured_fenez_params.csv",
          "shading": "assigned/structured_shading_params.csv",
          "equip": "assigned/structured_equipment.csv",
          "zone_sizing": "assigned/structured_zone_sizing.csv"
        },
        "scenario_csv": {
          "hvac": "scenarios/scenario_params_hvac.csv",
          "dhw": "scenarios/scenario_params_dhw.csv",
          "vent": "scenarios/scenario_params_vent.csv",
          "elec": "scenarios/scenario_params_elec.csv",
          "fenez": "scenarios/scenario_params_fenez.csv",
          "shading": "scenarios/scenario_params_shading.csv",
          "equip": "scenarios/scenario_params_equipment.csv",
          "zone_sizing": "scenarios/scenario_params_zone_sizing.csv"
        },
        "output_idf_dir": "scenario_idfs",
        "building_id": 4136733,
        "num_scenarios": 5,
        "picking_method": "random_uniform",
        "picking_scale_factor": 0.5,
        "run_simulations": true,
        "simulation_config": {
          "num_workers": 4,
          "output_dir": "Sim_Results/Scenarios"
        },
        "perform_post_process": true,
        "post_process_config": {
          "output_csv_as_is": "results_scenarioes/merged_as_is_scenarios.csv",
          "output_csv_daily_mean": "results_scenarioes/merged_daily_mean_scenarios.csv"
        },
        "perform_validation": false,
        "validation_config": {
          "real_data_csv": "data/mock_merged_daily_mean.csv",
          "sim_data_csv": "results/merged_daily_mean.csv",
          "bldg_ranges": {
            "0": [
              0,
              1,
              2
            ]
          },
          "variables_to_compare": [
            "Electricity:Facility [J](Hourly)",
            "Heating:EnergyTransfer [J](Hourly)",
            "Cooling:EnergyTransfer [J](Hourly)"
          ],
          "threshold_cv_rmse": 30.0,
          "skip_plots": true,
          "output_csv": "scenario_validation_report.csv"
        }
      }
    },
    "validation_base": {
      "perform_validation": false,
      "config": {
        "real_data_csv": "data/mock_merged_daily_mean.csv",
        "sim_data_csv": "results/merged_daily_mean.csv",
        "bldg_ranges": {
          "0": [
            0,
            1,
            2,
            3
          ]
        },
        "variables_to_compare": [
          "Electricity:Facility [J](Hourly)",
          "Heating:EnergyTransfer [J](Hourly)",
          "Cooling:EnergyTransfer [J](Hourly)"
        ],
        "threshold_cv_rmse": 30.0,
        "skip_plots": true,
        "output_csv": "validation_report_base.csv"
      }
    },
    "validation_scenarios": {
      "perform_validation": false,
      "config": {
        "real_data_csv": "data/mock_merged_daily_mean.csv",
        "sim_data_csv": "results_scenarioes/merged_daily_mean_scenarios.csv",
        "bldg_ranges": {
          "0": [
            0,
            1,
            2
          ]
        },
        "variables_to_compare": [
          "Electricity:Facility [J](Hourly)",
          "Heating:EnergyTransfer [J](Hourly)",
          "Cooling:EnergyTransfer [J](Hourly)"
        ],
        "threshold_cv_rmse": 30.0,
        "skip_plots": true,
        "output_csv": "validation_report_scenarios.csv"
      }
    },
    "sensitivity": {
      "perform_sensitivity": true,
      "scenario_folder": "scenarios",
      "method": "morris",
      "results_csv": "results_scenarioes/merged_daily_mean_scenarios.csv",
      "target_variable": [
        "Heating:EnergyTransfer [J](Hourly)",
        "Cooling:EnergyTransfer [J](Hourly)",
        "Electricity:Facility [J](Hourly)"
      ],
      "output_csv": "multi_corr_sensitivity.csv",
      "n_morris_trajectories": 10,
      "num_levels": 4
    },
    "surrogate": {
      "perform_surrogate": true,
      "scenario_folder": "scenarios",
      "results_csv": "results_scenarioes/merged_daily_mean_scenarios.csv",
      "target_variable": "Heating:EnergyTransfer [J](Hourly)",
      "model_out": "heating_surrogate_model.joblib",
      "cols_out": "heating_surrogate_columns.joblib",
      "test_size": 0.3
    },
    "calibration": {
      "perform_calibration": true,
      "scenario_folder": "scenarios",
      "scenario_files": [
        "scenario_params_dhw.csv",
        "scenario_params_elec.csv"
      ],
      "subset_sensitivity_csv": "multi_corr_sensitivity.csv",
      "top_n_params": 10,
      "method": "ga",
      "use_surrogate": true,
      "real_data_csv": "data/mock_merged_daily_mean.csv",
      "surrogate_model_path": "heating_surrogate_model.joblib",
      "surrogate_columns_path": "heating_surrogate_columns.joblib",
      "calibrate_min_max": true,
      "ga_pop_size": 10,
      "ga_generations": 5,
      "ga_crossover_prob": 0.7,
      "ga_mutation_prob": 0.2,
      "bayes_n_calls": 15,
      "random_n_iter": 20,
      "output_history_csv": "calibration_history.csv",
      "best_params_folder": "calibrated",
      "history_folder": "calibrated"
    }
  },
  "shading_tree": [
    {
      "building_id": 413673000,
      "param_name": "top_n_buildings",
      "fixed_value": 5
    },
    {
      "building_function": "residential",
      "param_name": "summer_value",
      "min_val": 0.4,
      "max_val": 0.6
    },
    {
      "param_name": "top_n_trees",
      "fixed_value": 3
    }
  ],
  "vent": [
    {
      "building_id": 413673000,
      "param_name": "infiltration_base",
      "min_val": 100.3,
      "max_val": 100.4
    },
    {
      "building_function": "residential",
      "age_range": "1992-2005",
      "param_name": "year_factor",
      "min_val": 21.4,
      "max_val": 21.5
    },
    {
      "building_id": 4136731,
      "param_name": "system_type",
      "fixed_value": "D"
    },
    {
      "building_id": 4136731,
      "param_name": "fan_pressure",
      "min_val": 100,
      "max_val": 120
    }
  ]
}
------------------------------------------------------------

