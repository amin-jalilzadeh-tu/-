File: D:\Documents\E_Plus_2030_py\idf_objects\structuring\dhw_structuring.py
============================================================
"""
dhw_structuring.py

Transforms the "assigned_dhw_params.csv" file into a structured CSV, merging
range data (e.g. "R_value_range") with the final assigned values. Also
captures E+ object type/name if present.

Usage (standalone):
    python dhw_structuring.py

Or import and call "transform_dhw_log_to_structured(...)" from your main code.
"""

import pandas as pd
import ast
import os

def transform_dhw_log_to_structured(
    csv_input="output/assigned/assigned_dhw_params.csv",
    csv_output="output/assigned/structured_dhw_params.csv",
):
    """
    Reads the 'flat' DHW CSV with columns (ogc_fid, param_name, assigned_value).
    Produces a 'structured' CSV with columns:
       ogc_fid, sub_key, eplus_object_type, eplus_object_name,
       param_name, param_value, param_min, param_max

    Key logic:
      - If param_name ends with "_range", parse min/max from assigned_value
        and store them in memory.
      - If param_name is the same as the range version minus "_range",
        unify them in one row => param_value + param_min + param_max.
      - If param_name includes '.obj_type' or '.Name', we store them
        so we can fill eplus_object_type/eplus_object_name in final row.
    """

    df = pd.read_csv(csv_input)

    # We'll keep data in a nested dictionary:
    # final_dict[(ogc_fid, sub_key, base_param)] = {
    #    "value": <float or str>,
    #    "min": <float or None>,
    #    "max": <float or None>,
    #    "obj_type": <str or None>,
    #    "obj_name": <str or None>
    # }
    final_dict = {}

    def get_subdict(fid, s_key, base_param):
        if (fid, s_key, base_param) not in final_dict:
            final_dict[(fid, s_key, base_param)] = {
                "value": None,
                "min": None,
                "max": None,
                "obj_type": None,
                "obj_name": None
            }
        return final_dict[(fid, s_key, base_param)]

    for i, row in df.iterrows():
        # Must have these columns
        if "ogc_fid" not in row or "param_name" not in row or "assigned_value" not in row:
            continue

        ogc_fid = row["ogc_fid"]
        param_name = str(row["param_name"])
        assigned_value = row["assigned_value"]

        # If you only want to transform "dhw_" lines, you could do:
        # if not param_name.startswith("dhw_"):
        #     continue

        # Attempt sub_key parse. If we see "dhw_waterheater.obj_type" => sub_key="dhw_waterheater", field="obj_type"
        # If param_name has no dot => sub_key="dhw_top" or something default
        sub_key = "dhw_top"
        field = param_name
        if '.' in param_name:
            parts = param_name.split('.', 1)
            sub_key, field = parts[0], parts[1]
        # e.g. sub_key="dhw_waterheater", field="obj_type"

        if field.endswith("_range"):
            # e.g. "setpoint_c_range"
            base_param = field[:-6]  # remove "_range"
            subd = get_subdict(ogc_fid, sub_key, base_param)

            # parse assigned_value => (minVal, maxVal)
            try:
                tval = ast.literal_eval(str(assigned_value))
                if isinstance(tval, (list, tuple)) and len(tval) == 2:
                    subd["min"], subd["max"] = tval
            except:
                pass

        elif field in ("obj_type", "Name"):
            # E+ object pointer
            # We'll store them in base_param="EPOBJ"
            base_param = "EPOBJ"
            subd = get_subdict(ogc_fid, sub_key, base_param)

            if field == "obj_type":
                subd["obj_type"] = assigned_value
            else:  # "Name"
                subd["obj_name"] = assigned_value

        else:
            # normal param => e.g. "setpoint_c"
            base_param = field
            subd = get_subdict(ogc_fid, sub_key, base_param)
            subd["value"] = assigned_value

    # Now we have a dict that merges range with final value, object type, etc.
    # We'll produce final rows with columns we want:
    structured_rows = []
    for (fid, s_key, base_param), valdict in final_dict.items():
        # If base_param == "EPOBJ", that means it's the object reference (obj_type, obj_name)
        # We'll handle them below if you want them as separate param rows or
        # or you can attach them to everything else. Let's do the approach
        # where we have "param_name" = "obj_type", "param_name" = "Name" as separate lines
        # or you can skip them as normal param lines. We'll do a combination approach.

        if base_param == "EPOBJ":
            # object-level
            # param row for obj_type
            if valdict["obj_type"] is not None:
                structured_rows.append({
                    "ogc_fid": fid,
                    "sub_key": s_key,
                    "eplus_object_type": valdict["obj_type"],
                    "eplus_object_name": valdict["obj_name"],
                    "param_name": "obj_type",
                    "param_value": valdict["obj_type"],
                    "param_min": None,
                    "param_max": None
                })
            # param row for Name
            if valdict["obj_name"] is not None:
                structured_rows.append({
                    "ogc_fid": fid,
                    "sub_key": s_key,
                    "eplus_object_type": valdict["obj_type"],
                    "eplus_object_name": valdict["obj_name"],
                    "param_name": "Name",
                    "param_value": valdict["obj_name"],
                    "param_min": None,
                    "param_max": None
                })
        else:
            # normal param => occupant_density, setpoint_c, etc.
            param_val = valdict["value"]
            param_min = valdict["min"]
            param_max = valdict["max"]

            # we might want to parse them as floats
            def try_float(x):
                try:
                    return float(x)
                except:
                    return x

            param_val = try_float(param_val)
            param_min = try_float(param_min)
            param_max = try_float(param_max)

            # find if there's an "EPOBJ" for this sub_key => attach eplus_object_type/eplus_object_name
            ep_obj = final_dict.get((fid, s_key, "EPOBJ"), {})
            eplus_type = ep_obj.get("obj_type", None)
            eplus_name = ep_obj.get("obj_name", None)

            structured_rows.append({
                "ogc_fid": fid,
                "sub_key": s_key,
                "eplus_object_type": eplus_type,
                "eplus_object_name": eplus_name,
                "param_name": base_param,
                "param_value": param_val,
                "param_min": param_min,
                "param_max": param_max
            })

    # Convert to DataFrame
    df_struct = pd.DataFrame(structured_rows)

    # Sort if you like
    df_struct.sort_values(by=["ogc_fid", "sub_key", "param_name"], inplace=True)

    # Write
    os.makedirs(os.path.dirname(csv_output), exist_ok=True)
    df_struct.to_csv(csv_output, index=False)
    print(f"[transform_dhw_log_to_structured] => Wrote structured CSV to {csv_output}")


def main():
    """
    Example CLI entry point:
      - Reads 'D:/Documents/E_Plus_2030_py/output/assigned/assigned_dhw_params.csv'
      - Transforms it, merges range fields, extracts E+ object references,
      - Writes 'D:/Documents/E_Plus_2030_py/output/assigned/structured_dhw_params.csv'
    """
    csv_in = r"D:\Documents\E_Plus_2030_py\output\assigned\assigned_dhw_params.csv"
    csv_out = r"D:\Documents\E_Plus_2030_py\output\assigned\structured_dhw_params.csv"

    transform_dhw_log_to_structured(
        csv_input=csv_in,
        csv_output=csv_out
    )

if __name__ == "__main__":
    main()

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\structuring\fenestration_structuring.py
============================================================
"""
fenestration_structuring.py

This module provides a function to transform the flat 'assigned_fenez_params.csv'
into a structured CSV that merges final assigned values with min/max ranges
for each parameter, and associates them with E+ object type/name.

You can run it stand-alone or call it from your main script.

Usage:
    from idf_objects.structuring.fenestration_structuring import transform_fenez_log_to_structured_with_ranges

    transform_fenez_log_to_structured_with_ranges(
        csv_input="output/assigned/assigned_fenez_params.csv",
        csv_output="output/assigned/structured_fenez_params.csv"
    )
"""

import pandas as pd
import ast  # For safely parsing "(4.0, 5.0)" as a Python tuple

def transform_fenez_log_to_structured_with_ranges(
    csv_input="output/assigned/assigned_fenez_params.csv",
    csv_output="output/assigned/structured_fenez_params.csv",
):
    """
    Reads the 'flat' fenestration/material CSV (with param_name & assigned_value),
    and outputs a 'structured' CSV that:

      - Merges final assigned value + min/max range into one row per parameter.
      - Does NOT skip params that have empty or None values.
      - Always includes a row for any param that appears in the CSV, even if
        there's no final value or no range.

    Final columns in the output CSV:
        ogc_fid, sub_key, eplus_object_type, eplus_object_name,
        param_name, param_value, param_min, param_max

    - "sub_key" is something like "windows_opq" or "exterior_wall_win",
      derived from e.g. "fenez_exterior_wall_opq.Thickness".
    - "eplus_object_type" and "eplus_object_name" come from lines like 
      "fenez_exterior_wall_opq.obj_type" and "fenez_exterior_wall_opq.Name".
    - "param_name" is the base parameter (like "Thickness"), or just "wwr",
      or "obj_type" if you want to store them as param rows.
    - "param_value" is the final assigned numeric or string value.
    - "param_min" and "param_max" come from lines that end with "_range".
    """

    df = pd.read_csv(csv_input)

    # We'll keep track of data in a nested dict:
    # final_dict[(ogc_fid, sub_key)] = {
    #   "obj_type": <str or None>,
    #   "obj_name": <str or None>,
    #   "params": {
    #       "Thickness": {
    #          "value": <final assigned value or None>,
    #          "min": <float or None>,
    #          "max": <float or None>
    #       },
    #       "Conductivity": {...},
    #       etc.
    #   }
    # }

    final_dict = {}

    def get_subdict(fid, s_key):
        """Helper to retrieve or create the dictionary entry for (fid, s_key)."""
        if (fid, s_key) not in final_dict:
            final_dict[(fid, s_key)] = {
                "obj_type": None,
                "obj_name": None,
                "params": {}
            }
        return final_dict[(fid, s_key)]

    for i, row in df.iterrows():
        # Must have these columns
        if "ogc_fid" not in row or "param_name" not in row or "assigned_value" not in row:
            continue

        ogc_fid = row["ogc_fid"]
        param_name = str(row["param_name"])
        assigned_value = row["assigned_value"]

        # We only transform if param_name starts with "fenez_"
        # (Otherwise, skip non-fenestration logs.)
        if not param_name.startswith("fenez_"):
            continue

        # Remove the "fenez_" prefix => e.g. "doors_opq.Thermal_Resistance_range"
        remainder = param_name[len("fenez_"):]  # e.g. "doors_opq.Thermal_Resistance_range"

        if "." in remainder:
            sub_key, field = remainder.split(".", 1)
        else:
            # e.g. "wwr", "roughness" => treat them as sub_key=<that word>, no field
            sub_key = remainder
            field = None

        # Retrieve or create sub-dict for (ogc_fid, sub_key)
        subd = get_subdict(ogc_fid, sub_key)

        # (A) If this row indicates the E+ object type => e.g. "obj_type"
        if field == "obj_type":
            subd["obj_type"] = assigned_value

        # (B) If this row indicates the E+ object name => e.g. "Name"
        elif field == "Name":
            subd["obj_name"] = assigned_value

        # (C) If the field ends with "_range", parse as (min,max)
        elif field and field.endswith("_range"):
            # e.g. "Thermal_Resistance_range"
            base_param = field.replace("_range", "")  # => "Thermal_Resistance"

            if base_param not in subd["params"]:
                subd["params"][base_param] = {"value": None, "min": None, "max": None}

            # assigned_value might be something like "(4.0, 5.0)" or maybe "None"
            try:
                maybe_tuple = ast.literal_eval(str(assigned_value))
                if isinstance(maybe_tuple, (list, tuple)) and len(maybe_tuple) == 2:
                    min_val, max_val = maybe_tuple
                    subd["params"][base_param]["min"] = min_val
                    subd["params"][base_param]["max"] = max_val
            except:
                pass  # If parse fails or it's "None", we leave them as None

        # (D) If it's a 'normal' field => param_name like "Thermal_Resistance" or "wwr"
        else:
            if field is None:
                # e.g. remainder="wwr". We'll store param_name = "wwr"
                p_name = sub_key  # "wwr"
                if p_name not in subd["params"]:
                    subd["params"][p_name] = {"value": None, "min": None, "max": None}
                subd["params"][p_name]["value"] = assigned_value
            else:
                # e.g. field="Thermal_Resistance", assigned_value=4.23
                if field not in subd["params"]:
                    subd["params"][field] = {"value": None, "min": None, "max": None}
                subd["params"][field]["value"] = assigned_value

    # Now finalize. We'll produce a row for **every** param in subd["params"].
    structured_rows = []
    for (fid, s_key), info in final_dict.items():
        obj_type = info["obj_type"]
        obj_name = info["obj_name"]
        params = info["params"]  # e.g. { "Thickness": {"value":..., "min":..., "max":...} }

        if not params:
            # If no params => skip. (Or you can make a row with param_name="(none)".)
            continue

        for p_name, pvals in params.items():
            param_value = pvals["value"]
            param_min   = pvals["min"]
            param_max   = pvals["max"]

            structured_rows.append({
                "ogc_fid":            fid,
                "sub_key":            s_key,
                "eplus_object_type":  obj_type,
                "eplus_object_name":  obj_name,
                "param_name":         p_name,
                "param_value":        param_value,
                "param_min":          param_min,
                "param_max":          param_max
            })

    # Convert to DataFrame
    df_out = pd.DataFrame(structured_rows)

    # Attempt to convert param_value, param_min, param_max to float if possible
    def try_float(x):
        try:
            return float(x)
        except:
            return x

    for col in ["param_value", "param_min", "param_max"]:
        df_out[col] = df_out[col].apply(try_float)

    # Save
    df_out.to_csv(csv_output, index=False)
    print(f"[transform_fenez_log_to_structured_with_ranges] => wrote: {csv_output}")


if __name__ == "__main__":
    # Example direct CLI usage:
    transform_fenez_log_to_structured_with_ranges(
        csv_input="output/assigned/assigned_fenez_params.csv",
        csv_output="output/assigned/structured_fenez_params.csv"
    )



------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\structuring\flatten_assigned_vent.py
============================================================
"""
flatten_assigned_vent.py

Transforms the "assigned_ventilation.csv" file (which has [ogc_fid, param_name, assigned_value])
into two structured CSVs:
  1) assigned_vent_building.csv
  2) assigned_vent_zones.csv

Usage:
    python flatten_assigned_vent.py
or
    from idf_objects.structuring.flatten_assigned_vent import main
    main()
"""

import pandas as pd
import ast
import os

def parse_assigned_value(value_str):
    """
    Safely convert the string in 'assigned_value' into a Python dict,
    e.g. literal_eval("{'infiltration_base': 1.23}")
    """
    try:
        return ast.literal_eval(str(value_str))
    except (SyntaxError, ValueError):
        return {}

def flatten_ventilation_data(df_input, out_build_csv, out_zone_csv):
    """
    Takes a DataFrame with columns [ogc_fid, param_name, assigned_value].
    Splits it into two DataFrames:
      1) building-level (flattening 'building_params')
      2) zone-level (flattening 'zones').

    Then writes them to CSV (out_build_csv, out_zone_csv).

    :param df_input: pd.DataFrame
        Must contain columns => "ogc_fid", "param_name", "assigned_value"
        where assigned_value is already a dict (not a raw string).
    :param out_build_csv: str
        File path for building-level CSV output.
    :param out_zone_csv: str
        File path for zone-level CSV output.
    """
    building_rows = []
    zone_rows = []

    for idx, row in df_input.iterrows():
        bldg_id = row.get("ogc_fid")
        param_name = row.get("param_name")
        assigned_val = row.get("assigned_value", {})

        # param_name might be "building_params" or "zones" based on your code's structure
        if param_name == "building_params":
            # assigned_val is a dict => e.g. {"infiltration_base": 1.23, "fan_pressure": 30, ...}
            for k, v in assigned_val.items():
                building_rows.append({
                    "ogc_fid": bldg_id,
                    "param_name": k,
                    "param_value": v
                })

        elif param_name == "zones":
            # assigned_val is a dict: { "Zone1": {...}, "Zone2": {...}, ... }
            for zone_name, zone_dict in assigned_val.items():
                # zone_dict might be => {"vent_mech": True, "vent_flow_rate": 150.0, ...}
                for zparam_name, zparam_val in zone_dict.items():
                    zone_rows.append({
                        "ogc_fid": bldg_id,
                        "zone_name": zone_name,
                        "param_name": zparam_name,
                        "param_value": zparam_val
                    })

        else:
            # If there's something else or unknown param_name, we ignore or handle differently
            pass

    # Convert to DataFrame
    df_build = pd.DataFrame(building_rows)
    df_zone = pd.DataFrame(zone_rows)

    # If they're empty, columns might not exist => ensure minimal columns
    if not df_build.empty:
        df_build = df_build[["ogc_fid", "param_name", "param_value"]]
    if not df_zone.empty:
        df_zone = df_zone[["ogc_fid", "zone_name", "param_name", "param_value"]]

    # Write them to CSV
    os.makedirs(os.path.dirname(out_build_csv), exist_ok=True)
    df_build.to_csv(out_build_csv, index=False)

    os.makedirs(os.path.dirname(out_zone_csv), exist_ok=True)
    df_zone.to_csv(out_zone_csv, index=False)

    print(f"[INFO] Wrote building-level picks to {out_build_csv} ({len(df_build)} rows).")
    print(f"[INFO] Wrote zone-level picks to {out_zone_csv} ({len(df_zone)} rows).")


def main():
    """
    Example CLI entry point:
      - Reads 'D:/Documents/E_Plus_2030_py/output/assigned/assigned_ventilation.csv'
      - Parses 'assigned_value' into dict
      - Writes building-level & zone-level CSVs
    """
    # 1) Path to your original CSV
    csv_in = r"D:\Documents\E_Plus_2030_py\output\assigned\assigned_ventilation.csv"

    # 2) Paths for output
    csv_build_out = r"D:\Documents\E_Plus_2030_py\output\assigned\assigned_vent_building.csv"
    csv_zone_out = r"D:\Documents\E_Plus_2030_py\output\assigned\assigned_vent_zones.csv"

    # 3) Read the CSV
    df_assigned = pd.read_csv(csv_in)

    # 4) Convert 'assigned_value' from string to dict
    df_assigned["assigned_value"] = df_assigned["assigned_value"].apply(parse_assigned_value)

    # 5) Flatten
    flatten_ventilation_data(
        df_input=df_assigned,
        out_build_csv=csv_build_out,
        out_zone_csv=csv_zone_out
    )


if __name__ == "__main__":
    main()

------------------------------------------------------------

File: D:\Documents\E_Plus_2030_py\idf_objects\structuring\flatten_hvac.py
============================================================
"""
flatten_hvac.py

Transforms the "assigned_hvac_params.csv" file (with columns [ogc_fid, param_name, assigned_value])
into two structured CSVs:
  1) assigned_hvac_building.csv
  2) assigned_hvac_zones.csv

Usage (standalone):
    python flatten_hvac.py

Or import and call 'main()' or the lower-level functions.
"""

import pandas as pd
import ast
import os

def parse_assigned_value(value_str):
    """
    Safely convert the string in 'assigned_value' into a Python dict.
    Uses ast.literal_eval to parse e.g.:
      "{'heating_day_setpoint': 20.28, 'cooling_day_setpoint': 24.55, ...}"
    into a real Python dictionary.
    """
    try:
        return ast.literal_eval(str(value_str))
    except (SyntaxError, ValueError):
        return {}

def flatten_hvac_data(df_input, out_build_csv, out_zone_csv):
    """
    Takes a DataFrame with columns [ogc_fid, param_name, assigned_value].
    Splits it into two DataFrames:
      1) building-level (where param_name == "hvac_params")
      2) zone-level (where param_name == "zones").

    Then writes them to CSV (out_build_csv, out_zone_csv).

    :param df_input: pd.DataFrame
        Must contain columns => "ogc_fid", "param_name", "assigned_value"
        where assigned_value is a dict (not raw text).
    :param out_build_csv: str
        File path for building-level CSV output.
    :param out_zone_csv: str
        File path for zone-level CSV output.
    """

    building_rows = []
    zone_rows = []

    for idx, row in df_input.iterrows():
        bldg_id = row.get("ogc_fid")
        param_name = row.get("param_name")
        assigned_val = row.get("assigned_value", {})

        if param_name == "hvac_params":
            # assigned_val is a dict, e.g.:
            # {
            #   "heating_day_setpoint": 20.28,
            #   "cooling_day_setpoint": 24.55,
            #   "schedule_details": {...},
            #   ...
            # }
            for k, v in assigned_val.items():
                building_rows.append({
                    "ogc_fid": bldg_id,
                    "param_name": k,
                    "param_value": v
                })

        elif param_name == "zones":
            # assigned_val is a dict => { zoneName: {...}, zoneName2: {...}, ... }
            # e.g. { "Zone1": {"hvac_object_name": "Ideal1", "cooling_setpoint": 25}, ... }
            for zone_name, zone_dict in assigned_val.items():
                for zparam, zval in zone_dict.items():
                    zone_rows.append({
                        "ogc_fid": bldg_id,
                        "zone_name": zone_name,
                        "param_name": zparam,
                        "param_value": zval
                    })

        else:
            # If there's any other param_name, skip or handle differently
            pass

    # Convert to DataFrames
    df_build = pd.DataFrame(building_rows)
    df_zone = pd.DataFrame(zone_rows)

    # Reorder columns or ensure they exist
    if not df_build.empty:
        df_build = df_build[["ogc_fid", "param_name", "param_value"]]
    if not df_zone.empty:
        df_zone = df_zone[["ogc_fid", "zone_name", "param_name", "param_value"]]

    # Write to CSV
    os.makedirs(os.path.dirname(out_build_csv), exist_ok=True)
    df_build.to_csv(out_build_csv, index=False)

    os.makedirs(os.path.dirname(out_zone_csv), exist_ok=True)
    df_zone.to_csv(out_zone_csv, index=False)

    print(f"[INFO] Wrote building-level picks to {out_build_csv} ({len(df_build)} rows).")
    print(f"[INFO] Wrote zone-level picks to {out_zone_csv} ({len(df_zone)} rows).")


def main():
    """
    Example CLI entry point:
      - Reads 'D:/Documents/E_Plus_2030_py/output/assigned/assigned_hvac_params.csv'
      - Parses 'assigned_value' into dict
      - Writes building-level & zone-level CSVs
    """
    # 1) Path to your original HVAC CSV file
    csv_in = r"D:\Documents\E_Plus_2030_py\output\assigned\assigned_hvac_params.csv"

    # 2) Paths for output CSVs
    csv_build_out = r"D:\Documents\E_Plus_2030_py\output\assigned\assigned_hvac_building.csv"
    csv_zone_out  = r"D:\Documents\E_Plus_2030_py\output\assigned\assigned_hvac_zones.csv"

    # 3) Load the CSV
    df_assigned = pd.read_csv(csv_in)

    # 4) Convert assigned_value from string to dict
    df_assigned["assigned_value"] = df_assigned["assigned_value"].apply(parse_assigned_value)

    # 5) Flatten
    flatten_hvac_data(
        df_input=df_assigned,
        out_build_csv=csv_build_out,
        out_zone_csv=csv_zone_out
    )


if __name__ == "__main__":
    main()

------------------------------------------------------------

