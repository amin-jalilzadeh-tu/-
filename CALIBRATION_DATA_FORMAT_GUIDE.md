# Calibration System Data Format Guide

## Overview

The unified calibration system in `cal/unified_calibration.py` can accept data in multiple formats, not just CSV. This guide explains how to use the existing system with data that's already available in the project.

## Data Formats Accepted

### 1. CSV Format (Default)

The calibration system expects CSV files with the following structure for real/measured data:

```csv
BuildingID,VariableName,01/01 00:00:00,01/01 01:00:00,...
4136737,Heating:EnergyTransfer [J](Hourly),1230000,1450000,...
4136737,Electricity:Facility [J](Hourly),765000,892000,...
```

Key columns:
- `BuildingID`: Building identifier
- `VariableName`: EnergyPlus variable name
- Time columns: Format "MM/DD HH:MM:SS"

### 2. Parquet Format Support

While the current implementation loads CSV by default, the system can be extended to support parquet files:

1. **Validation Data Loader** (`validation/Archieve 2/validation_data_loader.py`) already supports parquet:
   ```python
   if path.suffix.lower() == '.parquet':
       df = pd.read_parquet(path)
   ```

2. **Available Parquet Data**:
   - Validation data: `data/test_validation_data/*.parquet`
   - Time series data: `data/parsed_data/sql_results/timeseries/aggregated/daily/*.parquet`
   - Parameter matrix: `parsed_data/analysis_ready/parameter_matrix.parquet`

## Using Existing Data

### Option 1: Convert Parquet to CSV

Use the provided utility `cal/parquet_to_calibration_csv.py`:

```python
from cal.parquet_to_calibration_csv import convert_parquet_to_calibration_csv

# Convert validation data
convert_parquet_to_calibration_csv(
    parquet_file="data/test_validation_data/measured_data_simple.parquet",
    output_csv="data/calibration_real_data.csv"
)
```

### Option 2: Modify Load Function

The calibration system's `load_real_data_once` function can be extended to support parquet:

```python
def load_real_data_once(real_data_path: str, time_aggregation: str = 'sum'):
    global REAL_DATA_DICT, REAL_DATA_DF
    if REAL_DATA_DF is None:
        path = Path(real_data_path)
        
        # Support both CSV and Parquet
        if path.suffix.lower() == '.csv':
            REAL_DATA_DF = pd.read_csv(real_data_path)
        elif path.suffix.lower() == '.parquet':
            REAL_DATA_DF = pd.read_parquet(real_data_path)
            # Convert if needed using validation data loader logic
```

### Option 3: Use Existing Scenario Files

The system already looks for scenario parameter files in these locations:
- `output/{job_id}/scenarios/scenario_params_*.csv`
- Generated by sensitivity analysis or modification steps

## Configuration Examples

### Basic Configuration with CSV
```json
{
    "scenario_folder": "output/job_id/scenarios",
    "real_data_csv": "data/calibration_real_data.csv",
    "use_surrogate": true,
    "surrogate_model_path": "models/heating_surrogate.joblib",
    "target_variable": "Heating:EnergyTransfer [J](Hourly)"
}
```

### Enhanced Multi-Objective Configuration
```json
{
    "scenario_folder": "output/job_id/scenarios",
    "real_data_csv": "data/calibration_real_data.csv",
    "method": "nsga2",
    "objectives": [
        {
            "target_variable": "Heating:EnergyTransfer [J](Hourly)",
            "metric": "rmse",
            "weight": 1.0
        },
        {
            "target_variable": "Electricity:Facility [J](Hourly)",
            "metric": "mae",
            "weight": 0.8
        }
    ]
}
```

## Where Data is Located

1. **Scenario Parameters** (Required for calibration):
   - Location: `output/{job_id}/scenarios/scenario_params_*.csv`
   - Generated by: Sensitivity analysis, auto-generation utilities
   
2. **Real/Measured Data**:
   - Test data: `data/test_validation_data/*.parquet`
   - Aggregated results: `data/parsed_data/sql_results/timeseries/aggregated/`
   
3. **Parameter Matrices**:
   - Location: `parsed_data/analysis_ready/parameter_matrix.parquet`
   - Contains: Building parameters extracted from IDF files

4. **Surrogate Models**:
   - Location: Specified in configuration
   - Format: Joblib files containing trained models

## Recommendations

1. **Use the conversion utility** to convert existing parquet data to CSV format
2. **Auto-generate scenario files** using `auto_generate_scenarios.py` if missing
3. **Check data alignment** between real and simulated data variable names
4. **Verify time formats** match between data sources

## Variable Name Mapping

Common mappings between data sources:
- `Total Electricity` → `Electricity:Facility [J](Hourly)`
- `Heating Energy` → `Heating:EnergyTransfer [J](Hourly)`
- `Cooling Energy` → `Cooling:EnergyTransfer [J](Hourly)`

The system handles unit conversions automatically (e.g., kWh to J).