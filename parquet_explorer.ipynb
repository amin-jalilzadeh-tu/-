{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b023d6",
   "metadata": {},
   "source": [
    "## Parquet Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88eb4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Processed: schedules\\all_schedules.parquet (4 rows sampled from 39)\n",
      "âœ“ Processed: summary_metrics\\building_metrics.parquet (3 rows sampled from 3)\n",
      "âœ“ Processed: summary_metrics\\zone_metrics.parquet (3 rows sampled from 3)\n",
      "âœ“ Processed: timeseries\\aggregated\\daily\\hvac_daily.parquet (3 rows sampled from 30375)\n",
      "âœ“ Processed: timeseries\\aggregated\\daily\\ventilation_daily.parquet (4 rows sampled from 46116)\n",
      "âœ“ Processed: timeseries\\aggregated\\daily\\zones_daily.parquet (3 rows sampled from 156282)\n",
      "âœ“ Processed: timeseries\\aggregated\\monthly\\hvac_monthly.parquet (4 rows sampled from 1079)\n",
      "âœ“ Processed: timeseries\\aggregated\\monthly\\ventilation_monthly.parquet (4 rows sampled from 1638)\n",
      "âœ“ Processed: timeseries\\aggregated\\monthly\\zones_monthly.parquet (3 rows sampled from 5551)\n",
      "âœ“ Processed: timeseries\\hourly\\hvac_2013.parquet (3 rows sampled from 701895)\n",
      "âœ“ Processed: timeseries\\hourly\\ventilation_2013.parquet (4 rows sampled from 1103760)\n",
      "âœ“ Processed: timeseries\\hourly\\zones_2013.parquet (4 rows sampled from 3740520)\n",
      "\n",
      "âœ… Done! Results saved to: d:\\Documents\\daily\\E_Plus_2040_py\\parquet_samples_20250619_161456.txt\n",
      "ðŸ“Š Total files processed: 12\n",
      "\n",
      "ðŸ“„ Preview of output file:\n",
      "--------------------------------------------------\n",
      "Parquet Files Random Sample Report\n",
      "Generated on: 2025-06-19 16:14:56\n",
      "Root directory: D:\\Documents\\daily\\E_Plus_2040_py\\output\\49caf4d5-5dc1-411e-911b-462cf44bfb51\\parsed_data\\sql_results\n",
      "Total files processed: 12\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "File: schedules\\all_schedules.parquet\n",
      "Total rows: 39, Sampled: 4 rows\n",
      "================================================================================\n",
      "\n",
      "    ScheduleIndex                      ScheduleName ScheduleType  ScheduleMinimum  ScheduleMaximum building_id\n",
      "38             13                     ALWAYSONSCHED     FRACTION           1.0000           1.0000     4136738\n",
      "10             11  VENTSCHED_TWOANDAHALFSTORY_HOUSE     FRACTION           0.3174           0.9219     4136733\n",
      "36             11        VENTSCHED_MEETING_FUNCTION     FRACTION           0.0529           0.9157     4136738\n",
      "3               4                     EQUIPSCHEDULE     FRACTION           0.0000           0.5000     4136733\n",
      "\n",
      "================================================================================\n",
      "File: summary_metrics\\building_metrics.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Set the root directory path\n",
    "root_dir = r\"D:\\Documents\\daily\\E_Plus_2040_py\\output\\49caf4d5-5dc1-411e-911b-462cf44bfb51\\parsed_data\\sql_results\"\n",
    "\n",
    "# Initialize lists to store data\n",
    "all_samples = []\n",
    "file_info = []\n",
    "\n",
    "# Walk through all directories and subdirectories\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.parquet'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            relative_path = os.path.relpath(file_path, root_dir)\n",
    "            \n",
    "            try:\n",
    "                # Read the parquet file\n",
    "                df = pd.read_parquet(file_path)\n",
    "                \n",
    "                # Get the number of rows in the file\n",
    "                total_rows = len(df)\n",
    "                \n",
    "                if total_rows > 0:\n",
    "                    # Randomly sample 3-4 rows\n",
    "                    sample_size = random.randint(3, 4)\n",
    "                    sample_size = min(sample_size, total_rows)  # Don't sample more than available\n",
    "                    \n",
    "                    # Random sampling\n",
    "                    sampled_df = df.sample(n=sample_size, random_state=None)\n",
    "                    \n",
    "                    # Add file information\n",
    "                    all_samples.append(f\"\\n{'='*80}\")\n",
    "                    all_samples.append(f\"File: {relative_path}\")\n",
    "                    all_samples.append(f\"Total rows: {total_rows}, Sampled: {sample_size} rows\")\n",
    "                    all_samples.append(f\"{'='*80}\\n\")\n",
    "                    \n",
    "                    # Convert sampled data to string\n",
    "                    sample_str = sampled_df.to_string()\n",
    "                    all_samples.append(sample_str)\n",
    "                    \n",
    "                    # Store file info for summary\n",
    "                    file_info.append({\n",
    "                        'file': relative_path,\n",
    "                        'total_rows': total_rows,\n",
    "                        'sampled_rows': sample_size\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"âœ“ Processed: {relative_path} ({sample_size} rows sampled from {total_rows})\")\n",
    "                else:\n",
    "                    print(f\"âš  Skipped: {relative_path} (empty file)\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âœ— Error reading {relative_path}: {str(e)}\")\n",
    "                all_samples.append(f\"\\n{'='*80}\")\n",
    "                all_samples.append(f\"File: {relative_path}\")\n",
    "                all_samples.append(f\"ERROR: {str(e)}\")\n",
    "                all_samples.append(f\"{'='*80}\\n\")\n",
    "\n",
    "# Save results to text file\n",
    "output_filename = f\"parquet_samples_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "output_path = os.path.join(os.getcwd(), output_filename)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    # Write header\n",
    "    f.write(f\"Parquet Files Random Sample Report\\n\")\n",
    "    f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Root directory: {root_dir}\\n\")\n",
    "    f.write(f\"Total files processed: {len(file_info)}\\n\")\n",
    "    f.write(f\"\\n{'='*80}\\n\")\n",
    "    \n",
    "    # Write all samples\n",
    "    f.write('\\n'.join(all_samples))\n",
    "    \n",
    "    # Write summary at the end\n",
    "    f.write(f\"\\n\\n{'='*80}\")\n",
    "    f.write(f\"\\nSUMMARY\")\n",
    "    f.write(f\"\\n{'='*80}\\n\")\n",
    "    for info in file_info:\n",
    "        f.write(f\"{info['file']}: {info['sampled_rows']} rows sampled from {info['total_rows']} total\\n\")\n",
    "\n",
    "print(f\"\\nâœ… Done! Results saved to: {output_path}\")\n",
    "print(f\"ðŸ“Š Total files processed: {len(file_info)}\")\n",
    "\n",
    "# Optional: Display first few lines of the output file\n",
    "print(\"\\nðŸ“„ Preview of output file:\")\n",
    "print(\"-\" * 50)\n",
    "with open(output_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()[:20]\n",
    "    for line in lines:\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f565f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data in: test_validation_data\n",
      "\n",
      "Generating EnergyPlus format data...\n",
      "  Building 4136737\n",
      "  Building 4136738\n",
      "Saved: test_validation_data\\measured_data_energyplus_format.csv (7288 rows)\n",
      "Saved: test_validation_data\\measured_data_energyplus_format.parquet\n",
      "\n",
      "Creating validation configuration...\n",
      "Created validation config: test_validation_data\\validation_config_v2.json\n",
      "\n",
      "============================================================\n",
      "DATA GENERATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Sample data (first 10 rows):\n",
      "   BuildingID                             VariableName    DateTime  \\\n",
      "0     4136737          Electricity:Facility [J](Daily)  2013-01-01   \n",
      "1     4136737                     Electricity:Facility  2013-01-01   \n",
      "2     4136737        Heating:EnergyTransfer [J](Daily)  2013-01-01   \n",
      "3     4136737  Zone Air System Sensible Heating Energy  2013-01-01   \n",
      "4     4136737        Cooling:EnergyTransfer [J](Daily)  2013-01-01   \n",
      "5     4136737  Zone Air System Sensible Cooling Energy  2013-01-01   \n",
      "6     4136737          Electricity:Facility [J](Daily)  2013-01-02   \n",
      "7     4136737                     Electricity:Facility  2013-01-02   \n",
      "8     4136737        Heating:EnergyTransfer [J](Daily)  2013-01-02   \n",
      "9     4136737  Zone Air System Sensible Heating Energy  2013-01-02   \n",
      "\n",
      "          Value Units  \n",
      "0  3.485208e+09     J  \n",
      "1  3.485208e+09     J  \n",
      "2  3.075353e+11     J  \n",
      "3  3.075353e+11     J  \n",
      "4  1.045560e+08     J  \n",
      "5  1.045560e+08     J  \n",
      "6  3.499934e+09     J  \n",
      "7  3.499934e+09     J  \n",
      "8  2.588350e+11     J  \n",
      "9  2.588350e+11     J  \n",
      "\n",
      "Variables in dataset:\n",
      "  - Electricity:Facility [J](Daily): 724 rows\n",
      "  - Electricity:Facility: 724 rows\n",
      "  - Heating:EnergyTransfer [J](Daily): 716 rows\n",
      "  - Zone Air System Sensible Heating Energy: 716 rows\n",
      "  - Cooling:EnergyTransfer [J](Daily): 716 rows\n",
      "  - Zone Air System Sensible Cooling Energy: 716 rows\n",
      "  - Zone Mean Air Temperature [C](Hourly): 1488 rows\n",
      "  - Zone Mean Air Temperature: 1488 rows\n",
      "\n",
      "Test data generation complete!\n",
      "Files created in: d:\\Documents\\daily\\E_Plus_2040_py\\test_validation_data\n"
     ]
    }
   ],
   "source": [
    "# Check what's in the parsed_data directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "parsed_dir = Path(r\"D:\\Documents\\daily\\E_Plus_2040_py\\output\\da237aa0-dc6b-428b-b2f4-06d4e2905ea3\\parsed_data\")  # Update this path\n",
    "\n",
    "# List all parquet files\n",
    "print(\"=== PARSED DATA STRUCTURE ===\")\n",
    "for root, dirs, files in os.walk(parsed_dir):\n",
    "    level = root.replace(str(parsed_dir), '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        if file.endswith('.parquet'):\n",
    "            print(f\"{subindent}{file}\")\n",
    "\n",
    "# Sample category data\n",
    "print(\"\\n=== SAMPLE CATEGORY DATA ===\")\n",
    "category_file = parsed_dir / \"idf_data/by_category/outputs_all.parquet\"\n",
    "if category_file.exists():\n",
    "    df = pd.read_parquet(category_file)\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(df.head())\n",
    "\n",
    "# Sample timeseries data\n",
    "print(\"\\n=== SAMPLE TIMESERIES DATA ===\")\n",
    "ts_files = list((parsed_dir / \"sql_results/timeseries/hourly\").glob(\"*.parquet\"))\n",
    "if ts_files:\n",
    "    df = pd.read_parquet(ts_files[0])\n",
    "    print(f\"File: {ts_files[0].name}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
