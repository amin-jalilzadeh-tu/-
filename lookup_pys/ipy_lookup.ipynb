{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated dhw_lookup.py at: D:\\Documents\\E_Plus_2030_py\\lookup_pys\\dhw_lookup.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import math\n",
    "import os\n",
    "\n",
    "def safe_tuple(val_min, val_max):\n",
    "    \"\"\"\n",
    "    Convert two numeric (or empty/NaN) cells into a (min_val, max_val) tuple.\n",
    "    If they're blank, we return (None, None).\n",
    "    \"\"\"\n",
    "    # If either cell is NaN, treat it as None\n",
    "    if isinstance(val_min, float) and math.isnan(val_min):\n",
    "        val_min = None\n",
    "    if isinstance(val_max, float) and math.isnan(val_max):\n",
    "        val_max = None\n",
    "    return (val_min, val_max)\n",
    "\n",
    "def build_dhw_lookup_dict_from_excel(excel_path):\n",
    "    \"\"\"\n",
    "    Reads the given Excel file with columns like:\n",
    "      calibration_stage, dhw_key,\n",
    "      occupant_density_m2_per_person_min, occupant_density_m2_per_person_max,\n",
    "      liters_per_person_per_day_min, liters_per_person_per_day_max,\n",
    "      default_tank_volume_liters_min, default_tank_volume_liters_max,\n",
    "      default_heater_capacity_w_min, default_heater_capacity_w_max,\n",
    "      setpoint_c_min, setpoint_c_max,\n",
    "      usage_split_factor_min, usage_split_factor_max,\n",
    "      peak_hours_min, peak_hours_max,\n",
    "      sched_morning_min, sched_morning_max,\n",
    "      sched_peak_min, sched_peak_max,\n",
    "      sched_afternoon_min, sched_afternoon_max,\n",
    "      sched_evening_min, sched_evening_max\n",
    "\n",
    "    Returns a dictionary structured like:\n",
    "      dhw_lookup = {\n",
    "        \"TABLE_13_1_KWH_PER_M2\": {...},  # We'll hard-code or skip\n",
    "        \"pre_calibration\": {\n",
    "           \"Corner House\": {\n",
    "              \"occupant_density_m2_per_person_range\": (..),\n",
    "              \"liters_per_person_per_day_range\": (..),\n",
    "              ...\n",
    "           },\n",
    "           ...\n",
    "        },\n",
    "        \"post_calibration\": {\n",
    "           ...\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    # Initialize the main dict\n",
    "    dhw_lookup = {}\n",
    "\n",
    "    # Optionally define or skip the TABLE_13_1_KWH_PER_M2 here:\n",
    "    dhw_lookup[\"TABLE_13_1_KWH_PER_M2\"] = {\n",
    "        \"Meeting Function\":       2.8,\n",
    "        \"Office Function\":        1.4,\n",
    "        \"Retail Function\":        1.4,\n",
    "        \"Healthcare Function\":    15.3,\n",
    "        \"Education Function\":     1.4,\n",
    "        \"Sport Function\":         12.5,\n",
    "        \"Cell Function\":          4.2,\n",
    "        \"Industrial Function\":    1.2,\n",
    "        \"Accommodation Function\": 12.5,\n",
    "        \"Other Use Function\":     2.4\n",
    "    }\n",
    "\n",
    "    # Build up the \"pre_calibration\"/\"post_calibration\" entries\n",
    "    for _, row in df.iterrows():\n",
    "        stage = str(row[\"calibration_stage\"]).strip()\n",
    "        dhw_key = str(row[\"dhw_key\"]).strip()\n",
    "\n",
    "        # Ensure stage dict exists\n",
    "        if stage not in dhw_lookup:\n",
    "            dhw_lookup[stage] = {}\n",
    "\n",
    "        # Ensure dhw_key dict exists under this stage\n",
    "        if dhw_key not in dhw_lookup[stage]:\n",
    "            dhw_lookup[stage][dhw_key] = {}\n",
    "\n",
    "        # occupant_density\n",
    "        dhw_lookup[stage][dhw_key][\"occupant_density_m2_per_person_range\"] = \\\n",
    "            safe_tuple(row[\"occupant_density_m2_per_person_min\"],\n",
    "                       row[\"occupant_density_m2_per_person_max\"])\n",
    "\n",
    "        # liters_per_person_per_day\n",
    "        dhw_lookup[stage][dhw_key][\"liters_per_person_per_day_range\"] = \\\n",
    "            safe_tuple(row[\"liters_per_person_per_day_min\"],\n",
    "                       row[\"liters_per_person_per_day_max\"])\n",
    "\n",
    "        # default_tank_volume_liters\n",
    "        dhw_lookup[stage][dhw_key][\"default_tank_volume_liters_range\"] = \\\n",
    "            safe_tuple(row[\"default_tank_volume_liters_min\"],\n",
    "                       row[\"default_tank_volume_liters_max\"])\n",
    "\n",
    "        # default_heater_capacity_w\n",
    "        dhw_lookup[stage][dhw_key][\"default_heater_capacity_w_range\"] = \\\n",
    "            safe_tuple(row[\"default_heater_capacity_w_min\"],\n",
    "                       row[\"default_heater_capacity_w_max\"])\n",
    "\n",
    "        # setpoint_c\n",
    "        dhw_lookup[stage][dhw_key][\"setpoint_c_range\"] = \\\n",
    "            safe_tuple(row[\"setpoint_c_min\"], row[\"setpoint_c_max\"])\n",
    "\n",
    "        # usage_split_factor\n",
    "        dhw_lookup[stage][dhw_key][\"usage_split_factor_range\"] = \\\n",
    "            safe_tuple(row[\"usage_split_factor_min\"],\n",
    "                       row[\"usage_split_factor_max\"])\n",
    "\n",
    "        # peak_hours\n",
    "        dhw_lookup[stage][dhw_key][\"peak_hours_range\"] = \\\n",
    "            safe_tuple(row[\"peak_hours_min\"], row[\"peak_hours_max\"])\n",
    "\n",
    "        # sched_morning\n",
    "        dhw_lookup[stage][dhw_key][\"sched_morning_range\"] = \\\n",
    "            safe_tuple(row[\"sched_morning_min\"],\n",
    "                       row[\"sched_morning_max\"])\n",
    "\n",
    "        # sched_peak\n",
    "        dhw_lookup[stage][dhw_key][\"sched_peak_range\"] = \\\n",
    "            safe_tuple(row[\"sched_peak_min\"],\n",
    "                       row[\"sched_peak_max\"])\n",
    "\n",
    "        # sched_afternoon\n",
    "        dhw_lookup[stage][dhw_key][\"sched_afternoon_range\"] = \\\n",
    "            safe_tuple(row[\"sched_afternoon_min\"],\n",
    "                       row[\"sched_afternoon_max\"])\n",
    "\n",
    "        # sched_evening\n",
    "        dhw_lookup[stage][dhw_key][\"sched_evening_range\"] = \\\n",
    "            safe_tuple(row[\"sched_evening_min\"],\n",
    "                       row[\"sched_evening_max\"])\n",
    "\n",
    "    return dhw_lookup\n",
    "\n",
    "def main():\n",
    "    # Path to your Excel file\n",
    "    excel_file = r\"D:\\Documents\\E_Plus_2030_py\\lookup_pys\\dhw_lookup.xlsx\"\n",
    "\n",
    "    # Build the dictionary\n",
    "    dhw_dict = build_dhw_lookup_dict_from_excel(excel_file)\n",
    "\n",
    "    # Construct the path where we want to write the new \"dhw_lookup.py\"\n",
    "    out_path = os.path.join(\n",
    "        os.path.dirname(excel_file),  # same folder\n",
    "        \"dhw_lookup.py\"               # output filename\n",
    "    )\n",
    "\n",
    "    # Write the dictionary as a .py file\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Auto-generated from Excel\\n\\n\")\n",
    "        f.write(\"dhw_lookup = \")\n",
    "        f.write(pprint.pformat(dhw_dict, sort_dicts=False))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    print(f\"Generated dhw_lookup.py at: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: D:\\Documents\\E_Plus_2030_py\\lookup_pys\\lighting_lookup.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import ast\n",
    "import os\n",
    "\n",
    "def parse_tuple_string(s):\n",
    "    \"\"\"\n",
    "    Given a string like '(0.0, 0.0)', '(2100, 2300)',\n",
    "    parse it into a real Python tuple of floats or ints.\n",
    "\n",
    "    We'll use ast.literal_eval to safely parse the string.\n",
    "    If the string is empty or invalid, return None or (None, None).\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return (None, None)\n",
    "    try:\n",
    "        # e.g. s = \"(0.0, 0.0)\" => ast.literal_eval -> (0.0, 0.0)\n",
    "        val = ast.literal_eval(s.strip())\n",
    "        # Ensure it's a tuple\n",
    "        if isinstance(val, tuple) and len(val) == 2:\n",
    "            return val\n",
    "        else:\n",
    "            # If it's not a 2-element tuple, just return as-is or (None, None)\n",
    "            return (None, None)\n",
    "    except:\n",
    "        return (None, None)\n",
    "\n",
    "def main():\n",
    "    # 1) Path to your Excel file\n",
    "    excel_file = r\"D:\\Documents\\E_Plus_2030_py\\lookup_pys\\lighting_lookup.xlsx\"\n",
    "\n",
    "    # 2) Read the Excel into a pandas DataFrame\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # 3) Prepare the final dictionary\n",
    "    lighting_lookup = {}\n",
    "\n",
    "    # 4) Iterate each row to build the nested dict\n",
    "    for _, row in df.iterrows():\n",
    "        stage = str(row[\"Calibration Stage\"]).strip()        # e.g. \"Pre-calibration\"\n",
    "        category = str(row[\"Category\"]).strip()              # e.g. \"Residential\" or \"Non-Residential\"\n",
    "        subtype = str(row[\"Sub-Type/Function\"]).strip()      # e.g. \"Corner House\", \"Meeting Function\"\n",
    "\n",
    "        # Convert the stage to lowercase with underscores if desired\n",
    "        # e.g. \"Pre-calibration\" => \"pre_calibration\"\n",
    "        # or you can preserve as-is. Let's do the typical approach:\n",
    "        stage_key = stage.lower().replace(\"-\", \"_\")\n",
    "\n",
    "        # Ensure top-level key exists\n",
    "        if stage_key not in lighting_lookup:\n",
    "            lighting_lookup[stage_key] = {}\n",
    "\n",
    "        # Ensure category key exists\n",
    "        if category not in lighting_lookup[stage_key]:\n",
    "            lighting_lookup[stage_key][category] = {}\n",
    "\n",
    "        # Now parse each parameter column\n",
    "        lights_wm2        = parse_tuple_string(row[\"LIGHTS_WM2_range\"])\n",
    "        parasitic_wm2     = parse_tuple_string(row[\"PARASITIC_WM2_range\"])\n",
    "        td_range          = parse_tuple_string(row[\"tD_range\"])\n",
    "        tn_range          = parse_tuple_string(row[\"tN_range\"])\n",
    "        frac_rad_lights   = parse_tuple_string(row[\"lights_fraction_radiant_range\"])\n",
    "        frac_vis_lights   = parse_tuple_string(row[\"lights_fraction_visible_range\"])\n",
    "        frac_repl_lights  = parse_tuple_string(row[\"lights_fraction_replaceable_range\"])\n",
    "        frac_rad_equip    = parse_tuple_string(row[\"equip_fraction_radiant_range\"])\n",
    "        frac_lost_equip   = parse_tuple_string(row[\"equip_fraction_lost_range\"])\n",
    "\n",
    "        # Insert into the dictionary\n",
    "        lighting_lookup[stage_key][category][subtype] = {\n",
    "            \"LIGHTS_WM2_range\": lights_wm2,\n",
    "            \"PARASITIC_WM2_range\": parasitic_wm2,\n",
    "            \"tD_range\": td_range,\n",
    "            \"tN_range\": tn_range,\n",
    "            \"lights_fraction_radiant_range\": frac_rad_lights,\n",
    "            \"lights_fraction_visible_range\": frac_vis_lights,\n",
    "            \"lights_fraction_replaceable_range\": frac_repl_lights,\n",
    "            \"equip_fraction_radiant_range\": frac_rad_equip,\n",
    "            \"equip_fraction_lost_range\": frac_lost_equip,\n",
    "        }\n",
    "\n",
    "    # 5) Write out to a .py file (same folder as the Excel)\n",
    "    out_path = os.path.join(\n",
    "        os.path.dirname(excel_file),\n",
    "        \"lighting_lookup.py\"\n",
    "    )\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        # Possibly add a docstring or header\n",
    "        f.write(\"# Auto-generated from lighting_lookup.xlsx\\n\\n\")\n",
    "        f.write(\"lighting_lookup = \")\n",
    "        f.write(pprint.pformat(lighting_lookup, sort_dicts=False))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    print(f\"Created: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created hvac_lookup.py at: D:\\Documents\\E_Plus_2030_py\\lookup_pys\\hvac_lookup.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "def parse_tuple_string(s):\n",
    "    \"\"\"\n",
    "    Convert a string like '(20.0, 21.0)' into a real tuple (20.0, 21.0).\n",
    "    If s is empty or invalid, return (None, None).\n",
    "    \"\"\"\n",
    "    if not s or not isinstance(s, str) or not s.strip():\n",
    "        return (None, None)\n",
    "    try:\n",
    "        return ast.literal_eval(s.strip())  # safely parse to tuple\n",
    "    except:\n",
    "        return (None, None)\n",
    "\n",
    "def parse_schedule_details(s):\n",
    "    \"\"\"\n",
    "    Convert a string like:\n",
    "      'day_start=07:00; day_end=23:00; occ: weekday=FullOccupancy, weekend=FullOccupancy'\n",
    "    or\n",
    "      'wd_start=08:00; wd_end=22:00; we_start=08:00; we_end=18:00; occ: wd=MeetingFunction_Weekday, we=MeetingFunction_Weekend'\n",
    "    into a dict like:\n",
    "      {\n",
    "        \"day_start\": \"07:00\",\n",
    "        \"day_end\": \"23:00\",\n",
    "        \"occupancy_schedule\": { \"weekday\": \"FullOccupancy\", \"weekend\": \"FullOccupancy\" }\n",
    "      }\n",
    "    or for the wd_/we_ patterns:\n",
    "      {\n",
    "        \"weekday_day_start\": \"08:00\",\n",
    "        \"weekday_day_end\":   \"22:00\",\n",
    "        \"weekend_day_start\": \"08:00\",\n",
    "        \"weekend_day_end\":   \"18:00\",\n",
    "        \"occupancy_schedule\": {\n",
    "          \"weekday\": \"MeetingFunction_Weekday\",\n",
    "          \"weekend\": \"MeetingFunction_Weekend\"\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    details = {}\n",
    "    occupancy = {}\n",
    "    # Example tokens: [\"day_start=07:00\", \"day_end=23:00\", \"occ: weekday=FullOccupancy, weekend=FullOccupancy\"]\n",
    "    # or [\"wd_start=08:00\", \"wd_end=22:00\", \"we_start=08:00\", \"we_end=18:00\", \"occ: wd=MeetingFunction_Weekday, we=MeetingFunction_Weekend\"]\n",
    "    parts = s.split(\";\")\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        # e.g. \"day_start=07:00\" or \"occ: weekday=FullOccupancy, weekend=FullOccupancy\"\n",
    "        if not part:\n",
    "            continue\n",
    "\n",
    "        if part.startswith(\"occ:\"):\n",
    "            # parse occupancy references => \"occ: wd=..., we=...\"\n",
    "            # remove \"occ:\"\n",
    "            occ_str = part[4:].strip()  # e.g. \"weekday=FullOccupancy, weekend=FullOccupancy\"\n",
    "            # split by comma to get each\n",
    "            occ_items = occ_str.split(\",\")\n",
    "            for oitem in occ_items:\n",
    "                oitem = oitem.strip()\n",
    "                # e.g. \"weekday=FullOccupancy\" or \"wd=MeetingFunction_Weekday\"\n",
    "                if \"=\" in oitem:\n",
    "                    key, val = oitem.split(\"=\", 1)\n",
    "                    key = key.strip()\n",
    "                    val = val.strip()\n",
    "                    # unify \"weekday\"/\"wd\" => \"weekday\", \"weekend\"/\"we\" => \"weekend\"\n",
    "                    if key in [\"wd\", \"weekday\"]:\n",
    "                        occupancy[\"weekday\"] = val\n",
    "                    elif key in [\"we\", \"weekend\"]:\n",
    "                        occupancy[\"weekend\"] = val\n",
    "        else:\n",
    "            # parse key=val\n",
    "            if \"=\" in part:\n",
    "                key, val = part.split(\"=\", 1)\n",
    "                key = key.strip()\n",
    "                val = val.strip()\n",
    "                # check if it's day_start / wd_start etc.\n",
    "                # We'll unify them to the hvac_lookup.py style:\n",
    "                if key == \"day_start\":\n",
    "                    details[\"day_start\"] = val\n",
    "                elif key == \"day_end\":\n",
    "                    details[\"day_end\"] = val\n",
    "                elif key == \"wd_start\":\n",
    "                    details[\"weekday_day_start\"] = val\n",
    "                elif key == \"wd_end\":\n",
    "                    details[\"weekday_day_end\"] = val\n",
    "                elif key == \"we_start\":\n",
    "                    details[\"weekend_day_start\"] = val\n",
    "                elif key == \"we_end\":\n",
    "                    details[\"weekend_day_end\"] = val\n",
    "                else:\n",
    "                    # fallback: store directly if you want\n",
    "                    # e.g. details[\"something\"] = val\n",
    "                    details[key] = val\n",
    "\n",
    "    # attach occupancy sub-dict if present\n",
    "    if occupancy:\n",
    "        details[\"occupancy_schedule\"] = occupancy\n",
    "\n",
    "    return details\n",
    "\n",
    "def main():\n",
    "    excel_file = r\"D:\\Documents\\E_Plus_2030_py\\lookup_pys\\hvac_lookup.xlsx\"\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # final structure\n",
    "    hvac_lookup = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # 1) Read columns\n",
    "        calib_stage = str(row[\"Calib Stage\"]).strip()       # e.g. \"pre_calibration\"\n",
    "        scenario    = str(row[\"Scenario\"]).strip()          # e.g. \"scenario1\"\n",
    "        build_func  = str(row[\"Build Func\"]).strip()        # e.g. \"residential\" or \"non_residential\"\n",
    "        subtype     = str(row[\"Subtype\"]).strip()           # e.g. \"Corner House\", \"Meeting Function\"\n",
    "        age_range   = str(row[\"Age Range\"]).strip()         # e.g. \"2015 and later\"\n",
    "\n",
    "        # parse tuple columns\n",
    "        hd_day   = parse_tuple_string(row[\"heating_day_setpoint_range\"])\n",
    "        hd_night = parse_tuple_string(row[\"heating_night_setpoint_range\"])\n",
    "        cd_day   = parse_tuple_string(row[\"cooling_day_setpoint_range\"])\n",
    "        cd_night = parse_tuple_string(row[\"cooling_night_setpoint_range\"])\n",
    "        max_ht   = parse_tuple_string(row[\"max_heating_supply_air_temp_range\"])\n",
    "        min_cl   = parse_tuple_string(row[\"min_cooling_supply_air_temp_range\"])\n",
    "\n",
    "        # schedule details\n",
    "        sched_str = row[\"schedule_details\"] if isinstance(row[\"schedule_details\"], str) else \"\"\n",
    "        sched_dict = parse_schedule_details(sched_str)\n",
    "\n",
    "        # 2) Ensure the nested keys exist\n",
    "        if calib_stage not in hvac_lookup:\n",
    "            hvac_lookup[calib_stage] = {}\n",
    "        if scenario not in hvac_lookup[calib_stage]:\n",
    "            hvac_lookup[calib_stage][scenario] = {}\n",
    "        if build_func not in hvac_lookup[calib_stage][scenario]:\n",
    "            hvac_lookup[calib_stage][scenario][build_func] = {}\n",
    "        if subtype not in hvac_lookup[calib_stage][scenario][build_func]:\n",
    "            hvac_lookup[calib_stage][scenario][build_func][subtype] = {}\n",
    "\n",
    "        # 3) Insert the final dictionary under hvac_lookup[calib_stage][scenario][build_func][subtype][age_range]\n",
    "        hvac_lookup[calib_stage][scenario][build_func][subtype][age_range] = {\n",
    "            \"heating_day_setpoint_range\": hd_day,\n",
    "            \"heating_night_setpoint_range\": hd_night,\n",
    "            \"cooling_day_setpoint_range\": cd_day,\n",
    "            \"cooling_night_setpoint_range\": cd_night,\n",
    "            \"max_heating_supply_air_temp_range\": max_ht,\n",
    "            \"min_cooling_supply_air_temp_range\": min_cl,\n",
    "            \"schedule_details\": sched_dict\n",
    "        }\n",
    "\n",
    "    # write out hvac_lookup.py\n",
    "    out_path = os.path.join(os.path.dirname(excel_file), \"hvac_lookup.py\")\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Auto-generated from hvac_lookup.xlsx\\n\\n\")\n",
    "        f.write(\"hvac_lookup = \")\n",
    "        f.write(pprint.pformat(hvac_lookup, sort_dicts=False))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    print(f\"Created hvac_lookup.py at: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created materials_lookup.py at: D:\\Documents\\E_Plus_2030_py\\lookup_pys\\materials_lookup.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import pprint\n",
    "import math\n",
    "\n",
    "def parse_tuple_or_none(val):\n",
    "    \"\"\"\n",
    "    If 'val' is a string like '(0.12, 0.15)', parse into a tuple (0.12, 0.15).\n",
    "    If empty or invalid, return None.\n",
    "    \"\"\"\n",
    "    if not val or not isinstance(val, str) or not val.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return ast.literal_eval(val.strip())  # safely parse the string\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_float_or_none(val):\n",
    "    \"\"\"\n",
    "    Convert the cell to float if possible. If blank or NaN, return None.\n",
    "    \"\"\"\n",
    "    if val is None or (isinstance(val, float) and math.isnan(val)):\n",
    "        return None\n",
    "    try:\n",
    "        return float(val)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Path to your materials Excel file\n",
    "    excel_file = r\"D:\\Documents\\E_Plus_2030_py\\lookup_pys\\materials.xlsx\"\n",
    "\n",
    "    # Read the Excel\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # We'll build this final dictionary:\n",
    "    material_lookup = {}\n",
    "\n",
    "    # Iterate rows\n",
    "    for _, row in df.iterrows():\n",
    "        # \"Key\" is the main dictionary key\n",
    "        key = str(row[\"Key\"]).strip()\n",
    "        if not key:  # skip blank \"Key\" rows\n",
    "            continue\n",
    "\n",
    "        # Start building the sub-dict\n",
    "        mat_dict = {}\n",
    "\n",
    "        # For each column, if the cell is not blank, store it\n",
    "        # in a manner matching your original materials_lookup.py.\n",
    "\n",
    "        # 1) Straight string columns\n",
    "        if pd.notna(row.get(\"Obj Type\", None)):\n",
    "            mat_dict[\"obj_type\"] = str(row[\"Obj Type\"]).strip()\n",
    "        if pd.notna(row.get(\"Name\", None)):\n",
    "            mat_dict[\"Name\"] = str(row[\"Name\"]).strip()\n",
    "        if pd.notna(row.get(\"Description\", None)):\n",
    "            desc = str(row[\"Description\"]).strip()\n",
    "            if desc:\n",
    "                mat_dict[\"Description\"] = desc\n",
    "        if pd.notna(row.get(\"Roughness\", None)):\n",
    "            mat_dict[\"Roughness\"] = str(row[\"Roughness\"]).strip()\n",
    "        if pd.notna(row.get(\"Optical_Data_Type\", None)):\n",
    "            mat_dict[\"Optical_Data_Type\"] = str(row[\"Optical_Data_Type\"]).strip()\n",
    "        if pd.notna(row.get(\"Solar_Diffusing\", None)):\n",
    "            mat_dict[\"Solar_Diffusing\"] = str(row[\"Solar_Diffusing\"]).strip()\n",
    "\n",
    "        # 2) Range columns (parse tuple if present)\n",
    "        thickness_range = parse_tuple_or_none(row.get(\"Thickness_range\", None))\n",
    "        if thickness_range is not None:\n",
    "            mat_dict[\"Thickness_range\"] = thickness_range\n",
    "\n",
    "        conductivity_range = parse_tuple_or_none(row.get(\"Conductivity_range\", None))\n",
    "        if conductivity_range is not None:\n",
    "            mat_dict[\"Conductivity_range\"] = conductivity_range\n",
    "\n",
    "        density_range = parse_tuple_or_none(row.get(\"Density_range\", None))\n",
    "        if density_range is not None:\n",
    "            mat_dict[\"Density_range\"] = density_range\n",
    "\n",
    "        specific_heat_range = parse_tuple_or_none(row.get(\"Specific_Heat_range\", None))\n",
    "        if specific_heat_range is not None:\n",
    "            mat_dict[\"Specific_Heat_range\"] = specific_heat_range\n",
    "\n",
    "        thermal_abs_range = parse_tuple_or_none(row.get(\"Thermal_Absorptance_range\", None))\n",
    "        if thermal_abs_range is not None:\n",
    "            mat_dict[\"Thermal_Absorptance_range\"] = thermal_abs_range\n",
    "\n",
    "        solar_abs_range = parse_tuple_or_none(row.get(\"Solar_Absorptance_range\", None))\n",
    "        if solar_abs_range is not None:\n",
    "            mat_dict[\"Solar_Absorptance_range\"] = solar_abs_range\n",
    "\n",
    "        visible_abs_range = parse_tuple_or_none(row.get(\"Visible_Absorptance_range\", None))\n",
    "        if visible_abs_range is not None:\n",
    "            mat_dict[\"Visible_Absorptance_range\"] = visible_abs_range\n",
    "\n",
    "        thermal_res_range = parse_tuple_or_none(row.get(\"Thermal_Resistance_range\", None))\n",
    "        if thermal_res_range is not None:\n",
    "            mat_dict[\"Thermal_Resistance_range\"] = thermal_res_range\n",
    "\n",
    "        solar_trans_range = parse_tuple_or_none(row.get(\"Solar_Transmittance_range\", None))\n",
    "        if solar_trans_range is not None:\n",
    "            mat_dict[\"Solar_Transmittance_range\"] = solar_trans_range\n",
    "\n",
    "        fsolrefl_range = parse_tuple_or_none(row.get(\"Front_Solar_Reflectance_range\", None))\n",
    "        if fsolrefl_range is not None:\n",
    "            mat_dict[\"Front_Solar_Reflectance_range\"] = fsolrefl_range\n",
    "\n",
    "        bsolrefl_range = parse_tuple_or_none(row.get(\"Back_Solar_Reflectance_range\", None))\n",
    "        if bsolrefl_range is not None:\n",
    "            mat_dict[\"Back_Solar_Reflectance_range\"] = bsolrefl_range\n",
    "\n",
    "        vis_trans_range = parse_tuple_or_none(row.get(\"Visible_Transmittance_range\", None))\n",
    "        if vis_trans_range is not None:\n",
    "            mat_dict[\"Visible_Transmittance_range\"] = vis_trans_range\n",
    "\n",
    "        fvisrefl_range = parse_tuple_or_none(row.get(\"Front_Visible_Reflectance_range\", None))\n",
    "        if fvisrefl_range is not None:\n",
    "            mat_dict[\"Front_Visible_Reflectance_range\"] = fvisrefl_range\n",
    "\n",
    "        bvisrefl_range = parse_tuple_or_none(row.get(\"Back_Visible_Reflectance_range\", None))\n",
    "        if bvisrefl_range is not None:\n",
    "            mat_dict[\"Back_Visible_Reflectance_range\"] = bvisrefl_range\n",
    "\n",
    "        fir_emiss_range = parse_tuple_or_none(row.get(\"Front_IR_Emissivity_range\", None))\n",
    "        if fir_emiss_range is not None:\n",
    "            mat_dict[\"Front_IR_Emissivity_range\"] = fir_emiss_range\n",
    "\n",
    "        bir_emiss_range = parse_tuple_or_none(row.get(\"Back_IR_Emissivity_range\", None))\n",
    "        if bir_emiss_range is not None:\n",
    "            mat_dict[\"Back_IR_Emissivity_range\"] = bir_emiss_range\n",
    "\n",
    "        dirt_corr_range = parse_tuple_or_none(row.get(\"Dirt_Correction_Factor_range\", None))\n",
    "        if dirt_corr_range is not None:\n",
    "            mat_dict[\"Dirt_Correction_Factor_range\"] = dirt_corr_range\n",
    "\n",
    "        # 3) Float columns (like IR_Transmittance)\n",
    "        ir_trans = parse_float_or_none(row.get(\"IR_Transmittance\", None))\n",
    "        if ir_trans is not None:\n",
    "            mat_dict[\"IR_Transmittance\"] = ir_trans\n",
    "\n",
    "        # 4) If \"obj_type\" was never set (blank in Excel), fallback to \"MATERIAL\"\n",
    "        if \"obj_type\" not in mat_dict:\n",
    "            mat_dict[\"obj_type\"] = \"MATERIAL\"\n",
    "\n",
    "        # 5) Insert into final dictionary\n",
    "        material_lookup[key] = mat_dict\n",
    "\n",
    "    # Write out materials_lookup.py\n",
    "    out_path = os.path.join(os.path.dirname(excel_file), \"materials_lookup.py\")\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Auto-generated from materials.xlsx\\n\\n\")\n",
    "        f.write('\"\"\"\\nmaterials_lookup.py\\n\\n')\n",
    "        f.write('Defines a dictionary `material_lookup` from your Excel table.\\n\"\"\"\\n\\n')\n",
    "        f.write(\"material_lookup = \")\n",
    "        f.write(pprint.pformat(material_lookup, sort_dicts=False))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    print(f\"Created materials_lookup.py at: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ventilation_lookup.py at: D:\\Documents\\E_Plus_2030_py\\lookup_pys\\ventilation_lookup.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pprint\n",
    "import math\n",
    "\n",
    "def float_or_none(val):\n",
    "    \"\"\"Convert val to float if possible, else None.\"\"\"\n",
    "    if val is None or (isinstance(val, float) and math.isnan(val)):\n",
    "        return None\n",
    "    try:\n",
    "        return float(val)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    excel_path = r\"D:\\Documents\\E_Plus_2030_py\\lookup_pys\\Vent_lookup.xlsx\"\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    ventilation_lookup = {}\n",
    "\n",
    "    # We'll group all rows by (scenario, calibration) because each block\n",
    "    # builds a subdict with infiltration ranges, year_factor, system_control, etc.\n",
    "    grouped = df.groupby([\"Scenario\", \"Calibration\"], dropna=False)\n",
    "\n",
    "    for (scenario, calibration), group_df in grouped:\n",
    "        scenario = str(scenario).strip()\n",
    "        calibration_stage = str(calibration).strip()\n",
    "\n",
    "        # Ensure top-level keys exist\n",
    "        if scenario not in ventilation_lookup:\n",
    "            ventilation_lookup[scenario] = {}\n",
    "        if calibration_stage not in ventilation_lookup[scenario]:\n",
    "            # Initialize the sub-structure\n",
    "            ventilation_lookup[scenario][calibration_stage] = {\n",
    "                \"residential_infiltration_range\": {},\n",
    "                \"non_res_infiltration_range\": {},\n",
    "                \"year_factor_range\": {},\n",
    "                \"system_control_range_res\": {},\n",
    "                \"system_control_range_nonres\": {},\n",
    "                \"fan_pressure_range\": {},  # e.g. \"res_mech\", \"nonres_intake\", ...\n",
    "                \"hrv_sensible_eff_range\": (None, None),\n",
    "                \"system_type_map\": {\n",
    "                    \"residential\": {},\n",
    "                    \"non_residential\": {}\n",
    "                }\n",
    "            }\n",
    "\n",
    "        subdict = ventilation_lookup[scenario][calibration_stage]\n",
    "        # Quick references\n",
    "        res_infil = subdict[\"residential_infiltration_range\"]\n",
    "        nonres_infil = subdict[\"non_res_infiltration_range\"]\n",
    "        year_factor = subdict[\"year_factor_range\"]\n",
    "        ctrl_res = subdict[\"system_control_range_res\"]\n",
    "        ctrl_nonres = subdict[\"system_control_range_nonres\"]\n",
    "        fanp = subdict[\"fan_pressure_range\"]\n",
    "        # HRV tuple: we'll store min & max as we go, or just pick last\n",
    "        hrv_min, hrv_max = subdict[\"hrv_sensible_eff_range\"]\n",
    "        # system_type_map\n",
    "        sys_map_res = subdict[\"system_type_map\"][\"residential\"]\n",
    "        sys_map_nonres = subdict[\"system_type_map\"][\"non_residential\"]\n",
    "\n",
    "        for _, row in group_df.iterrows():\n",
    "            category = str(row[\"Category\"]).strip()  # \"residential\" or \"non_residential\"\n",
    "            year_range = str(row[\"Year Range\"]).strip()  # e.g. \"< 1945\"\n",
    "            bldg_type = str(row[\"Building/Function Type\"]).strip()  # e.g. \"Corner House\", \"Meeting Function\"\n",
    "\n",
    "            # infiltration\n",
    "            inf_min = float_or_none(row[\"Inf Min\"])\n",
    "            inf_max = float_or_none(row[\"Inf Max\"])\n",
    "\n",
    "            # year factor\n",
    "            yfac_min = float_or_none(row[\"Year Fac Min\"])\n",
    "            yfac_max = float_or_none(row[\"Year Fac Max\"])\n",
    "\n",
    "            # system letter\n",
    "            sys_letter = str(row[\"System Ctrl Letter\"]).strip() if not pd.isna(row[\"System Ctrl Letter\"]) else \"\"\n",
    "\n",
    "            # system ctrl min/max\n",
    "            sys_ctrl_min = float_or_none(row[\"Sys Ctrl Min\"])\n",
    "            sys_ctrl_max = float_or_none(row[\"Sys Ctrl Max\"])\n",
    "\n",
    "            # fan pressures\n",
    "            f_res_mech = float_or_none(row[\"FanP Res Mech\"])\n",
    "            f_nonres_intake = float_or_none(row[\"FanP Nonres Intake\"])\n",
    "            f_nonres_exhaust = float_or_none(row[\"FanP Nonres Exhaust\"])\n",
    "\n",
    "            # HRV\n",
    "            hrv_lo = float_or_none(row[\"HRV Min\"])\n",
    "            hrv_hi = float_or_none(row[\"HRV Max\"])\n",
    "\n",
    "            # 1) Infiltration\n",
    "            if inf_min is not None and inf_max is not None:\n",
    "                if category == \"residential\":\n",
    "                    res_infil[bldg_type] = (inf_min, inf_max)\n",
    "                else:\n",
    "                    nonres_infil[bldg_type] = (inf_min, inf_max)\n",
    "\n",
    "            # 2) Year factor range\n",
    "            # We store for all rows, but typically it's the same for same year_range.\n",
    "            if yfac_min is not None and yfac_max is not None:\n",
    "                # If year_range not in year_factor yet, store it:\n",
    "                # or you can check for consistency\n",
    "                if year_range not in year_factor:\n",
    "                    year_factor[year_range] = (yfac_min, yfac_max)\n",
    "                else:\n",
    "                    # optionally check if it's the same\n",
    "                    pass\n",
    "\n",
    "            # 3) system_type_map => system_letter\n",
    "            if sys_letter:\n",
    "                # e.g. system_type_map[\"residential\"][\"< 1945\"][\"Corner House\"] = \"A\"\n",
    "                if category == \"residential\":\n",
    "                    if year_range not in sys_map_res:\n",
    "                        sys_map_res[year_range] = {}\n",
    "                    sys_map_res[year_range][bldg_type] = sys_letter\n",
    "                else:\n",
    "                    if year_range not in sys_map_nonres:\n",
    "                        sys_map_nonres[year_range] = {}\n",
    "                    sys_map_nonres[year_range][bldg_type] = sys_letter\n",
    "\n",
    "            # 4) system_control_range_[res/nonres]\n",
    "            # if we have a system letter + sys_ctrl_min/max => we store f_ctrl_range\n",
    "            if sys_letter and sys_ctrl_min is not None and sys_ctrl_max is not None:\n",
    "                if category == \"residential\":\n",
    "                    if sys_letter not in ctrl_res:\n",
    "                        ctrl_res[sys_letter] = {\"f_ctrl_range\": (sys_ctrl_min, sys_ctrl_max)}\n",
    "                    else:\n",
    "                        # Could unify minmax or just overwrite\n",
    "                        pass\n",
    "                else:\n",
    "                    if sys_letter not in ctrl_nonres:\n",
    "                        ctrl_nonres[sys_letter] = {\"f_ctrl_range\": (sys_ctrl_min, sys_ctrl_max)}\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "            # 5) fan_pressure_range\n",
    "            # We see from example dictionary that there's just a single dict like:\n",
    "            # fan_pressure_range = {\"res_mech\": (40, 60), \"nonres_intake\": (90, 110), ...}\n",
    "            # If row has \"FanP Res Mech\" => store in \"res_mech\"\n",
    "            if f_res_mech is not None:\n",
    "                fanp[\"res_mech\"] = (f_res_mech, f_res_mech)\n",
    "            if f_nonres_intake is not None:\n",
    "                fanp[\"nonres_intake\"] = (f_nonres_intake, f_nonres_intake)\n",
    "            if f_nonres_exhaust is not None:\n",
    "                fanp[\"nonres_exhaust\"] = (f_nonres_exhaust, f_nonres_exhaust)\n",
    "\n",
    "            # 6) HRV => store min, max\n",
    "            # We'll unify across rows. Often it's the same in every row, but let's do min-of-min, max-of-max\n",
    "            if hrv_lo is not None and hrv_hi is not None:\n",
    "                if hrv_min is None or hrv_max is None:\n",
    "                    # first time\n",
    "                    hrv_min, hrv_max = (hrv_lo, hrv_hi)\n",
    "                else:\n",
    "                    # unify\n",
    "                    new_min = min(hrv_min, hrv_lo)\n",
    "                    new_max = max(hrv_max, hrv_hi)\n",
    "                    hrv_min, hrv_max = (new_min, new_max)\n",
    "\n",
    "        # after processing all rows in this group, store final hrv\n",
    "        subdict[\"hrv_sensible_eff_range\"] = (hrv_min, hrv_max)\n",
    "\n",
    "    # Write out ventilation_lookup.py\n",
    "    out_path = os.path.join(os.path.dirname(excel_path), \"ventilation_lookup.py\")\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Auto-generated from Vent_lookup.xlsx\\n\\n\")\n",
    "        f.write('\"\"\"\\nventilation_lookup.py\\nLarge nested dict from Excel.\\n\"\"\"\\n\\n')\n",
    "        f.write(\"ventilation_lookup = \")\n",
    "        f.write(pprint.pformat(ventilation_lookup, sort_dicts=False))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    print(f\"Created ventilation_lookup.py at: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def clean_numeric(val):\n",
    "    \"\"\"\n",
    "    Convert Excel cell values (possibly '-', NaN, float, etc.)\n",
    "    into either a float or None.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    if isinstance(val, str) and val.strip() == '-':\n",
    "        return None\n",
    "    try:\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def generate_material_data(df, is_residential=True):\n",
    "    \"\"\"\n",
    "    Given a dataframe (either residential or non-residential)\n",
    "    return a dictionary that matches the desired structure.\n",
    "    \n",
    "    For residential:\n",
    "        key = (building_type, year_range, scenario, calibration_stage)\n",
    "    For non-residential:\n",
    "        key = (building_type, year_range, scenario, calibration_stage)\n",
    "        \n",
    "    The returned dictionary will look like:\n",
    "    \n",
    "    {\n",
    "      (key_tuple): {\n",
    "         \"roughness\": str,\n",
    "         \"wwr_range\": (float or None, float or None),\n",
    "         \"material_opaque_lookup\": str,\n",
    "         \"material_window_lookup\": str,\n",
    "         \"doors\": {\n",
    "             \"area_m2\": float or None,\n",
    "             \"R_value_range\": (float or None, float or None),\n",
    "             \"U_value_range\": (float or None, float or None),\n",
    "             \"material_opaque_lookup\": str,\n",
    "             \"material_window_lookup\": str\n",
    "         },\n",
    "         \"exterior_wall\": { ... },\n",
    "         ...\n",
    "      },\n",
    "      ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Columns we expect:\n",
    "    # building_function, building_type, year_range, scenario, calibration_stage, element,\n",
    "    # area_m2, R_value_min, R_value_max, U_value_min, U_value_max,\n",
    "    # roughness, material_opaque_lookup, material_window_lookup, min_wwr, max_wwr\n",
    "    #\n",
    "    # For grouping keys:\n",
    "    #   residential -> (building_type, year_range, scenario, calibration_stage)\n",
    "    #   non-residential -> same grouping if you want the first item to be building_type from the column.\n",
    "    \n",
    "    # Decide grouping columns based on your logic:\n",
    "    if is_residential:\n",
    "        grouping_cols = [\"building_type\", \"year_range\", \"scenario\", \"calibration_stage\"]\n",
    "    else:\n",
    "        # In your examples, \"Accommodation Function\" was the building_type in the dictionary key.\n",
    "        # But your sheet might have building_type or building_function swapped.\n",
    "        # Adjust if needed. For example, if your file uses:\n",
    "        #   building_function = Non-Residential\n",
    "        #   building_type = Accommodation Function\n",
    "        # we group on (building_type, year_range, scenario, calibration_stage)\n",
    "        grouping_cols = [\"building_type\", \"year_range\", \"scenario\", \"calibration_stage\"]\n",
    "    \n",
    "    # Dictionary to fill\n",
    "    materials_data = {}\n",
    "    \n",
    "    # Group the dataframe by the chosen columns\n",
    "    grouped = df.groupby(grouping_cols)\n",
    "    \n",
    "    for group_key, subdf in grouped:\n",
    "        # Convert group_key to the tuple we want\n",
    "        # e.g. ('Apartment', '1946-1964', 'scenario1', 'post_calibration')\n",
    "        dict_key = tuple(group_key)\n",
    "        \n",
    "        # We'll pick the first row in this group for top-level info\n",
    "        first_row = subdf.iloc[0]\n",
    "        \n",
    "        roughness = str(first_row[\"roughness\"]) if not pd.isna(first_row[\"roughness\"]) else \"\"\n",
    "        mat_opaque_top = str(first_row[\"material_opaque_lookup\"]) if not pd.isna(first_row[\"material_opaque_lookup\"]) else \"\"\n",
    "        mat_window_top = str(first_row[\"material_window_lookup\"]) if not pd.isna(first_row[\"material_window_lookup\"]) else \"\"\n",
    "        \n",
    "        wwr_min = clean_numeric(first_row[\"min_wwr\"])\n",
    "        wwr_max = clean_numeric(first_row[\"max_wwr\"])\n",
    "        \n",
    "        # Start building the dictionary for this group\n",
    "        materials_data[dict_key] = {\n",
    "            \"roughness\": roughness,\n",
    "            \"wwr_range\": (wwr_min, wwr_max),\n",
    "            \"material_opaque_lookup\": mat_opaque_top,\n",
    "            \"material_window_lookup\": mat_window_top\n",
    "        }\n",
    "        \n",
    "        # For each element in subdf, populate sub-dict\n",
    "        # e.g. doors, windows, exterior_wall, etc.\n",
    "        for _, row in subdf.iterrows():\n",
    "            element_name = str(row[\"element\"]).strip()\n",
    "            \n",
    "            area_m2 = clean_numeric(row[\"area_m2\"])\n",
    "            R_value_min = clean_numeric(row[\"R_value_min\"])\n",
    "            R_value_max = clean_numeric(row[\"R_value_max\"])\n",
    "            U_value_min = clean_numeric(row[\"U_value_min\"])\n",
    "            U_value_max = clean_numeric(row[\"U_value_max\"])\n",
    "            \n",
    "            mat_opaque = str(row[\"material_opaque_lookup\"]) if not pd.isna(row[\"material_opaque_lookup\"]) else \"\"\n",
    "            mat_window = str(row[\"material_window_lookup\"]) if not pd.isna(row[\"material_window_lookup\"]) else \"\"\n",
    "            \n",
    "            # Create sub-dict for the element\n",
    "            element_dict = {\n",
    "                \"area_m2\": area_m2,\n",
    "                \"R_value_range\": (R_value_min, R_value_max),\n",
    "                \"U_value_range\": (U_value_min, U_value_max),\n",
    "                \"material_opaque_lookup\": mat_opaque,\n",
    "                \"material_window_lookup\": mat_window\n",
    "            }\n",
    "            \n",
    "            # Insert into the group dictionary\n",
    "            materials_data[dict_key][element_name] = element_dict\n",
    "    \n",
    "    return materials_data\n",
    "\n",
    "def dict_to_python_file(dictionary_data, variable_name, output_path):\n",
    "    \"\"\"\n",
    "    Write the given dictionary (of dictionaries) to a .py file\n",
    "    in a nicely formatted way that recreates the structure.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"{variable_name} = {{\\n\")\n",
    "        \n",
    "        # Sort keys (optional, for consistent output)\n",
    "        for k in sorted(dictionary_data.keys()):\n",
    "            f.write(f\"    {k}: {{\\n\")\n",
    "            \n",
    "            group_dict = dictionary_data[k]\n",
    "            \n",
    "            # We'll separate out the \"standard\" top-level keys from the elements\n",
    "            # standard top-level: roughness, wwr_range, material_opaque_lookup, material_window_lookup\n",
    "            top_keys = [\"roughness\", \"wwr_range\", \"material_opaque_lookup\", \"material_window_lookup\"]\n",
    "            elements = {}\n",
    "            \n",
    "            # Print top-level items first\n",
    "            for top_k in top_keys:\n",
    "                val = group_dict.get(top_k, None)\n",
    "                if isinstance(val, str):\n",
    "                    f.write(f'        \"{top_k}\": \"{val}\",\\n')\n",
    "                else:\n",
    "                    f.write(f'        \"{top_k}\": {val},\\n')\n",
    "            \n",
    "            # Then print the building elements (doors, windows, etc.)\n",
    "            # anything else in group_dict that is not in top_keys\n",
    "            element_keys = [ek for ek in group_dict.keys() if ek not in top_keys]\n",
    "            for element_key in element_keys:\n",
    "                elem_data = group_dict[element_key]\n",
    "                f.write(f'        \"{element_key}\": {{\\n')\n",
    "                # Now inside each element dict\n",
    "                for sub_k, sub_v in elem_data.items():\n",
    "                    if isinstance(sub_v, str):\n",
    "                        f.write(f'            \"{sub_k}\": \"{sub_v}\",\\n')\n",
    "                    else:\n",
    "                        f.write(f'            \"{sub_k}\": {sub_v},\\n')\n",
    "                f.write(\"        },\\n\")\n",
    "            \n",
    "            f.write(\"    },\\n\")\n",
    "        \n",
    "        f.write(\"}\\n\")\n",
    "\n",
    "def main():\n",
    "    # Adjust paths as needed\n",
    "    res_excel = r\"D:\\Documents\\E_Plus_2030_py\\lookup_pys\\envelop_res5.xlsx\"\n",
    "    nonres_excel = r\"D:\\Documents\\E_Plus_2030_py\\lookup_pys\\envelop_nonres5.xlsx\"\n",
    "    \n",
    "    out_residential_py = r\"D:\\Documents\\E_Plus_2030_py\\Lookups\\data_materials_residential.py\"\n",
    "    out_nonres_py = r\"D:\\Documents\\E_Plus_2030_py\\Lookups\\data_materials_non_residential.py\"\n",
    "    \n",
    "    # 1. Read data\n",
    "    df_res = pd.read_excel(res_excel)\n",
    "    df_nonres = pd.read_excel(nonres_excel)\n",
    "    \n",
    "    # 2. Generate dictionaries\n",
    "    residential_data = generate_material_data(df_res, is_residential=True)\n",
    "    non_residential_data = generate_material_data(df_nonres, is_residential=False)\n",
    "    \n",
    "    # 3. Write to .py files\n",
    "    dict_to_python_file(\n",
    "        dictionary_data=residential_data,\n",
    "        variable_name=\"residential_materials_data\",\n",
    "        output_path=out_residential_py\n",
    "    )\n",
    "    \n",
    "    dict_to_python_file(\n",
    "        dictionary_data=non_residential_data,\n",
    "        variable_name=\"non_residential_materials_data\",\n",
    "        output_path=out_nonres_py\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDsaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
